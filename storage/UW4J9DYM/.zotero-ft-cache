1
Foundations of Mathematical Neuroscience
Bard Ermentrout Department of Mathematics
University of Pittsburgh
David Terman Department of Mathematics
Ohio State University

i i

i i

2

i i

i i

i i

Contents

Preface

xxv

1 Some basic biology

1

1.1 The brain . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1

1.2 The neuron . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3

1.3 The synapse . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5

2 The Hodgkin-Huxley equations

9

2.1 The resting potential . . . . . . . . . . . . . . . . . . . . . . . . 9

2.2 The Nernst equation . . . . . . . . . . . . . . . . . . . . . . . . 11

2.3 The Goldman-Hodgkin-Katz equation . . . . . . . . . . . . . . . 13

2.4 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16

2.5 Equivalent circuits: the electrical analogue . . . . . . . . . . . . 17

2.6 The membrane time constant . . . . . . . . . . . . . . . . . . . 20

2.7 The cable equation . . . . . . . . . . . . . . . . . . . . . . . . . 21

2.8 The squid action potential . . . . . . . . . . . . . . . . . . . . . 25

2.9 Voltage-gated channels . . . . . . . . . . . . . . . . . . . . . . . 28

2.10 Hodgkin-Huxley model . . . . . . . . . . . . . . . . . . . . . . . 28

2.11 The action potential revisited . . . . . . . . . . . . . . . . . . . 33

2.12 Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36

2.13 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36

3 Dendrites

39

3.1 Multiple compartments . . . . . . . . . . . . . . . . . . . . . . . 39

3.1.1

Homework . . . . . . . . . . . . . . . . . . . . . . . 42

3.2 The cable equation. . . . . . . . . . . . . . . . . . . . . . . . . . 44

3.3 Linear cables with constant diameter. . . . . . . . . . . . . . . . 45

3.3.1

The inﬁnite cable . . . . . . . . . . . . . . . . . . . 45

3.4 Finite and semi-inﬁnite cables. . . . . . . . . . . . . . . . . . . . 47

3.5 Branching and equivalent cylinders. . . . . . . . . . . . . . . . . 49

3.6 An isolated junction . . . . . . . . . . . . . . . . . . . . . . . . . 52

3.7 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53

3.8 Dendrites with active processes . . . . . . . . . . . . . . . . . . 54

3.9 Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56

v

i i

vi

Contents

4 Dynamics

59

4.1 Introduction to dynamical systems . . . . . . . . . . . . . . . . 59

4.2 The Morris-Lecar model . . . . . . . . . . . . . . . . . . . . . . 59

4.3 The phase plane . . . . . . . . . . . . . . . . . . . . . . . . . . . 60

4.4 Bifurcation analysis . . . . . . . . . . . . . . . . . . . . . . . . . 65

4.5 Bifurcation analysis of the Hodgkin-Huxley equations . . . . . . 72

4.6 Reduction of the HH model to a 2-variable model . . . . . . . . 76

4.7 Fitzhugh-Nagumo equations . . . . . . . . . . . . . . . . . . . . 78

4.8 Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79

4.8.1

Exercises . . . . . . . . . . . . . . . . . . . . . . . . 79

5 On the variety of channels.

85

5.1 Channels, channels, channels. . . . . . . . . . . . . . . . . . . . 85

5.1.1

Sodium channels . . . . . . . . . . . . . . . . . . . . 86

5.1.2

Calcium channels . . . . . . . . . . . . . . . . . . . . 87

5.1.3

Voltage-gated potassium channels. . . . . . . . . . . 90

5.1.4

M-current. . . . . . . . . . . . . . . . . . . . . . . . 92

5.1.5

The inward rectiﬁer. . . . . . . . . . . . . . . . . . . 94

5.1.6

Sag . . . . . . . . . . . . . . . . . . . . . . . . . . . 95

5.1.7

Currents and ionic concentrations. . . . . . . . . . . 95

5.1.8

Calcium-dependent channels. . . . . . . . . . . . . . 97

5.1.9

Exercises . . . . . . . . . . . . . . . . . . . . . . . . 101

5.1.10

Projects . . . . . . . . . . . . . . . . . . . . . . . . . 106

6 Bursting Oscillations

109

6.1 Introduction to Bursting . . . . . . . . . . . . . . . . . . . . . . 109

6.2 Square-wave Bursters . . . . . . . . . . . . . . . . . . . . . . . . 111

6.3 Elliptic Bursting . . . . . . . . . . . . . . . . . . . . . . . . . . . 116

6.4 Parabolic Bursting . . . . . . . . . . . . . . . . . . . . . . . . . 119

6.5 Classiﬁcation of Bursters . . . . . . . . . . . . . . . . . . . . . . 122

6.6 Chaotic Dynamics . . . . . . . . . . . . . . . . . . . . . . . . . . 123

6.6.1

Chaos in Square-wave Bursting Models . . . . . . . 123

6.6.2

Symbolic Dynamics . . . . . . . . . . . . . . . . . . 125

6.6.3

Bistability and the Blue-Sky Catastrophe . . . . . . 128

6.7 Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131

6.8 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131

7 Propagating Action potentials.

133

7.1 Traveling waves and homoclinic orbits . . . . . . . . . . . . . . . 134

7.2 Scalar bistable equations. . . . . . . . . . . . . . . . . . . . . . . 136

7.2.1

Numerical shooting. . . . . . . . . . . . . . . . . . . 139

7.3 Singular construction of waves. . . . . . . . . . . . . . . . . . . . 139

7.3.1

Wave trains. . . . . . . . . . . . . . . . . . . . . . . 142

7.4 Dispersion relations . . . . . . . . . . . . . . . . . . . . . . . . . 143

7.4.1

Dispersion kinematics. . . . . . . . . . . . . . . . . . 144

7.5 Morris-Lecar revisited and Shilnikov dynamics . . . . . . . . . . 145

i i

i i

Contents

vii

7.5.1

Class II dynamics . . . . . . . . . . . . . . . . . . . 145

7.5.2

Class I dynamics. . . . . . . . . . . . . . . . . . . . 146

7.6 Stability of the wave. . . . . . . . . . . . . . . . . . . . . . . . . 148

7.6.1

Linearization . . . . . . . . . . . . . . . . . . . . . . 149

7.6.2

The Evan’s Function . . . . . . . . . . . . . . . . . . 150

7.7 Myelinated axons and discrete diﬀusion. . . . . . . . . . . . . . 151

7.8 Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154

7.9 Projects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154

7.10 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155

8 Synaptic channels.

159

8.1 Synaptic dynamics. . . . . . . . . . . . . . . . . . . . . . . . . . 160

8.1.1

Glutamate . . . . . . . . . . . . . . . . . . . . . . . 162

8.1.2

NMDA . . . . . . . . . . . . . . . . . . . . . . . . . 163

8.1.3

GABA . . . . . . . . . . . . . . . . . . . . . . . . . . 163

8.1.4

Gap or electrical junctions. . . . . . . . . . . . . . . 165

8.2 Short term plasticity. . . . . . . . . . . . . . . . . . . . . . . . . 165

8.2.1

Other models. . . . . . . . . . . . . . . . . . . . . . 167

8.3 Exercises. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 168

9 Neural oscillators: Weak coupling

171

9.1 Neural oscillators, phase, and isochrons . . . . . . . . . . . . . . 172

9.1.1

Phase resetting and adjoints. . . . . . . . . . . . . . 174

9.1.2

The adjoint . . . . . . . . . . . . . . . . . . . . . . . 177

9.1.3

Bifurcations and adjoints. . . . . . . . . . . . . . . . 180

9.1.4

Spike-time response curves. . . . . . . . . . . . . . . 185

9.2 Who cares about adjoints? . . . . . . . . . . . . . . . . . . . . . 186

9.2.1

Relationship of the adjoint and the response to inputs.187

9.2.2

Forced oscillators. . . . . . . . . . . . . . . . . . . . 188

9.2.3

Coupled oscillators. . . . . . . . . . . . . . . . . . . 191

9.2.4

Other map models. . . . . . . . . . . . . . . . . . . . 198

9.2.5

Weak coupling. . . . . . . . . . . . . . . . . . . . . . 201

9.2.6

Synaptic coupling near bifurcations. . . . . . . . . . 204

9.2.7

Small central pattern generators. . . . . . . . . . . . 206

9.2.8

Linear arrays of cells. . . . . . . . . . . . . . . . . . 211

9.2.9

Two-dimensional arrays. . . . . . . . . . . . . . . . . 214

9.2.10

All-to-all coupling. . . . . . . . . . . . . . . . . . . . 217

9.3 Pulse-coupled networks: solitary waves . . . . . . . . . . . . . . 221

9.3.1

Integrate-and-ﬁre model. . . . . . . . . . . . . . . . 224

9.3.2

Stability. . . . . . . . . . . . . . . . . . . . . . . . . 226

9.4 Adjoints and weak coupling using XPP . . . . . . . . . . . . . . 227

9.4.1

Averaging . . . . . . . . . . . . . . . . . . . . . . . . 228

9.5 Projects. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 229

9.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233

10 Networks

243

i i

i i

viii

Contents

10.1 10.2 10.3 10.4 10.5
10.6
10.7
10.8
10.9
10.10 10.11 10.12

Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 243

Mathematical Models for Neuronal Networks . . . . . . . . . . . 244

Examples of Firing Patterns . . . . . . . . . . . . . . . . . . . . 247

Singular Construction of the Action Potential . . . . . . . . . . 250

Excitatory Synapses . . . . . . . . . . . . . . . . . . . . . . . . . 255

10.5.1

Synchrony in a Network of Two Mutually Coupled

Neurons . . . . . . . . . . . . . . . . . . . . . . . . . 256

Post-Inhibitory Rebound . . . . . . . . . . . . . . . . . . . . . . 259

10.6.1

Two Mutually Coupled Cells . . . . . . . . . . . . . 259

10.6.2

Clustering . . . . . . . . . . . . . . . . . . . . . . . . 261

10.6.3

Dynamic Clustering . . . . . . . . . . . . . . . . . . 262

Thin Spikes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 264

10.7.1

Existence of Antiphase Oscillations . . . . . . . . . . 265

10.7.2

Stability of Antiphase Oscillations . . . . . . . . . . 267

Almost-Synchronous Solutions . . . . . . . . . . . . . . . . . . . 270

10.8.1

Almost-Synchrony in a Network of Two-Mutually

Coupled Cells . . . . . . . . . . . . . . . . . . . . . . 271

Slow Inhibitory Synapses . . . . . . . . . . . . . . . . . . . . . . 273

10.9.1

Fast/Slow Decomposition . . . . . . . . . . . . . . . 273

10.9.2

Antiphase and Suppressed Solution . . . . . . . . . 274

10.9.3

Synchronous Oscillations With Slow Inhibitory Synapses276

Propagating waves . . . . . . . . . . . . . . . . . . . . . . . . . . 278

Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 281

Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 281

11 Noise.

283

11.1 Stochastic diﬀerential equations. . . . . . . . . . . . . . . . . . . 285

11.1.1

The Wiener process. . . . . . . . . . . . . . . . . . . 285

11.1.2

Stochastic integrals. . . . . . . . . . . . . . . . . . . 286

11.1.3

Change of variables: Ito’s formula. . . . . . . . . . . 287

11.1.4

Fokker-Planck Equation – General Considerations. . 288

11.1.5

Scalar with constant noise . . . . . . . . . . . . . . . 290

11.1.6

First passage times . . . . . . . . . . . . . . . . . . . 292

11.2 Firing rates of scalar neuron models. . . . . . . . . . . . . . . . 295

11.2.1

The Fokker-Planck equation. . . . . . . . . . . . . . 296

11.2.2

First passage times. . . . . . . . . . . . . . . . . . . 299

11.2.3

Interspike intervals . . . . . . . . . . . . . . . . . . . 302

11.2.4

Colored noise. . . . . . . . . . . . . . . . . . . . . . 303

11.2.5

Nonconstant inputs & ﬁltering properties. . . . . . . 304

11.3 Weak noise and moment expansions . . . . . . . . . . . . . . . . 305

11.4 Poisson processes. . . . . . . . . . . . . . . . . . . . . . . . . . . 309

11.4.1

Basic statistics . . . . . . . . . . . . . . . . . . . . . 310

11.4.2

Channel simulations . . . . . . . . . . . . . . . . . . 312

11.4.3

Stochastic spike models: beyond Poisson. . . . . . . 314

11.5 Projects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316

11.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 318

i i

i i

Contents

ix

12 Firing rate models.

325

12.1 A number of derivations. . . . . . . . . . . . . . . . . . . . . . . 326

12.1.1

Heuristic derivation. . . . . . . . . . . . . . . . . . . 326

12.1.2

Derivation from averaging. . . . . . . . . . . . . . . 330

12.1.3

Populations of neurons. . . . . . . . . . . . . . . . . 332

12.2 Population density methods. . . . . . . . . . . . . . . . . . . . . 334

12.3 The Wilson Cowan equations. . . . . . . . . . . . . . . . . . . . 337

12.3.1

Scalar recurrent model. . . . . . . . . . . . . . . . . 339

12.3.2

Two neuron networks. . . . . . . . . . . . . . . . . . 339

12.3.3

Excitatory-inhibitory pairs. . . . . . . . . . . . . . . 343

12.3.4

Generalizations of ﬁring rate models. . . . . . . . . . 349

12.4 Projects. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 352

12.5 Exercises. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 353

12.6 Some methods for delay equations. . . . . . . . . . . . . . . . . 356

13 Spatially distributed networks.

359

13.1 Introduction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 359

13.2 Unstructured networks. . . . . . . . . . . . . . . . . . . . . . . . 360

13.2.1

McCulloch-Pitts. . . . . . . . . . . . . . . . . . . . . 360

13.2.2

Hopﬁeld’s model. . . . . . . . . . . . . . . . . . . . . 360

13.2.3

Designing memories. . . . . . . . . . . . . . . . . . . 363

13.3 Waves . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 364

13.3.1

Wavefronts . . . . . . . . . . . . . . . . . . . . . . . 366

13.3.2

Pulses. . . . . . . . . . . . . . . . . . . . . . . . . . 368

13.4 Bumps. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 372

13.4.1

The Wilson-Cowan equations. . . . . . . . . . . . . 373

13.4.2

Stability . . . . . . . . . . . . . . . . . . . . . . . . . 375

13.4.3

More general stability. . . . . . . . . . . . . . . . . . 377

13.4.4

More general ﬁring rates. . . . . . . . . . . . . . . . 377

13.4.5

Applications of bumps. . . . . . . . . . . . . . . . . 378

13.5 Spatial patterns - Hallucinations . . . . . . . . . . . . . . . . . . 381

13.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 387

14 Models

393

14.1 Channels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 393

Bibliography

413

i i

i i

x

Contents

i i

i i

i i

List of Figures

1.1

..................................... 2

1.2

..................................... 3

1.3

..................................... 4

1.4

..................................... 5

1.5

..................................... 6

2.1 The K+ ﬂux is determined by both the K+ concentration gradient and the electrical potential across the membrane. A) For a cell that is permeable only to K+, the concentration gradient of K+ moves K+ ions out of the cell. B) The continued eﬄux of K+ builds up an excess of positive charge on the outside and negative charge on the inside. At equilibrium, the electrical and chemical driving forces are equal and opposite. . . . . . . . . . . . . . . . . 10
2.2 Cartoon of the cell membrane showing the insulating lipid bilayer and a K+ channel which allows current to ﬂow. The equivalent electrical circuit is shown on the right . . . . . . . . . . . . . . . . 18
2.3 Equivalent circuit for a membrane with three channels. . . . . . . 20
2.4 The change of membrane potential in response to a step of current. The membrane potential is shown with a solid line. The dashed lines show the time courses of the purely capacitive and resistive elements. The bottom panel shows the time course of the total membrane current, the ionic current and the capacitive current. . 22
2.5 Equivalent circuit for a uniform passive cable. . . . . . . . . . . . 23
2.6 Equivalent circuit underlying the Hodgkin-Huxley equations. . . . 27
2.7 The action potential. During the upstroke, sodium channels open and the membrane potential approaches the sodium Nernst potential. During the downstroke, sodium channels are closed, potassium channels are open and the membrane potential approaches the potassium Nernst potential. . . . . . . . . . . . . . . . . . . . 27
2.8 Numerically computed voltage-clamp experiment. The membrane potential is stepped from rest to 0 mV. This results in an inward current followed by an outward current. The separate potassium and sodium currents are also shown. . . . . . . . . . . . . . . . . . 30

xi

i i

xii

List of Figures

2.9 Numerically computed voltage-clamp experiment. The membrane potential is stepped to diﬀerent values and the resulting potassium and sodium conductances are computed. . . . . . . . . . . . . . . 31
2.10 The Hodgkin-Huxley sodium channel. (A-C) Voltage clamp dynamics. (D) Physical model of the channel. If the voltage step is small (A), then the Na-channel’s activation gate (line) is closed but the inactivation gate (ball) is open. At intermediate steps (B), both gates are partially open. For large steps (C), the activation gate is open and the inactivation gate is closed. . . . . . . . . . . . 32
2.11 HH functions. Left shows the steady state opening of the gates and right shows the time constants. . . . . . . . . . . . . . . . . . 33
2.12 Response of the activation and inactivation variables m, h, and n to a step in voltage. . . . . . . . . . . . . . . . . . . . . . . . . . . 33
2.13 Responses of the HH model to applied currents. Left: transient responses showing “all-or-none” behavior; Right: Sustained periodic response. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
2.14 Solution of the Hodgkin-Huxley equations showing an action potential. Also shown are the sodium and potassium conductances. . 35
2.15 Mechanisms underlying the action potential. . . . . . . . . . . . . 36
3.1 A. Branched dendrite converted to a series of cylinders for modeling. B. Simple 3 compartment model. . . . . . . . . . . . . . . . . 42
3.2 A simple dendritic tree. . . . . . . . . . . . . . . . . . . . . . . . . 49
3.3 Example of the Rall reduction to an equivalent cylinder. . . . . . . 51
3.4 Schematic of 2-compartment model showing applied currents and outward and inward currents to soma and dendrite compartments. 55
3.5 Voltage and calcium traces of a bursting solution in the 2-compartment model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57
4.1 Solutions of the Morris-Lecar equations. Parameters are listed in Table 4.2, the Hopf case. A) A small perturbation from rest decays to the resting state, while a larger perturbation generates an action potential. Here, Iapp = 60. B) A periodic solution of (ML). Here, Iapp = 100. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61
4.2 Phaseplanes and time series for the ML model in the Hopf regime. (A) I = 60; an excitable system with threshold at about 20 mV. Nullclines are included as well, (B) Starting at n = nrest and varying V from -20 to -20.1 mV; (C) I = 90 showing bistability between a stable limit cycle (SLC) and a ﬁxed point, separated by the unstable limit cycle (ULC); (D) I = 95, the ﬁxed point is stable and only a limit cycle remains. . . . . . . . . . . . . . . . . 64
4.3 Threshold construction for the ML model. . . . . . . . . . . . . . . 65

i i

i i

List of Figures

xiii

4.4 Bifurcation diagram for the ML model in the Hopf regime. (A) Voltage as a function of current. The curves above and below the ﬁxed point curve correspond to the maximum and minimum voltages along periodic orbits. Solid curves represent stable solutions and dashed curves represent unstable solutions. Arrows shown at Iapp = 60, 90 and 100 correspond to the solutions shown in Figure 4.1, Figure 4.2A and Figure 4.2B, respectively. (B) Frequency (Hz) versus current. (C) Two-parameter bifurcation showing the curve of Hopf bifurcations as φ and Iapp vary. . . . . . . . . . . . . . . . 67
4.5 Dynamics of the ML model with saddle-node dynamics. A) The delay to spike can be arbitrary but the spike height is invariant. B) and C) Phase-plane explaining A). The ﬁxed points N, S, and U are, respectively a stable node (the rest state), a saddle-point, and an unstable node. Σ± are the stable (−) and unstable (+) manifolds of S. D) There exists a stable limit cycle for suﬃcient current; the nullclines are also shown. . . . . . . . . . . . . . . . . . . . . . 69
4.6 Bifurcation for the ML model with saddle-node dynamics. A) Voltage vs current showing saddle-nodes, SN1,2 and Hopf H bifurcations. B) Frequency as a function of current. C) Two-parameter bifurcation diagram showing the curves of Hopf and saddle-node bifurcations as the rate, φ, of the potassium channel varies. The Hopf curve meets the left-most saddle-node curve at a double zero eigenvalue characterizing a Takens-Bogdanov bifurcation (TB). . . 70
4.7 Bifurcation for the ML model with increased φ. A) Voltage vs current. B) Zoom in of A) showing the homoclinic orbit (Hc). The vertical line at Iapp = 37 shows tristability. (C) Frequency versus current; note the much steeper approach to I∗ than in Figure 4.6. 70
4.8 Phaseplane for the ML system near the homoclinic bifurcation showing A) Iapp < IHc, B) Iapp ≈ IHc and C) Iapp > IHc. . . . . 71
4.9 From Tateno etal; Properties of RS and FS neurons in cortex. A. Firing rate versus current for RS neurons. (Note that these cells have spike-frequency adaptation so that the inter-spike interval (ISI) is not constant. Thus, this shows the ISI after several spikes as well as the steady-state.) (B) Same as A for FS neurons. (C) Mixture of spikes and subthreshold oscillations near the critical current for FS. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73
4.10 Bifurcation diagram for the HH model. A) V versus Iapp, the applied current; B) Expanded view of A); C) Frequency as a function of current; D) (V, n)−phase plane projection showing 4 diﬀerent limit cycles. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74
4.11 Projection of limit cycles in HH equations in the (n, h)−plane. . . 77
4.12 Equivalent potentials for the Hodgkin-Huxley model. (A) the voltages of the 4 variables; (B) Bifurcation diagram for (V, Vh)−system; (C) Phase plane at rest; (D) Phase-plane showing how the ﬁxed point moves to the middle branch as Iapp increases. . . . . . . . . 78

i i

i i

xiv

List of Figures

5.1 Persistent sodium provides the pacemaker current for the model Pre-Botzinger cell. (A) Potential with EL = −60 mV for the full bursting model. (B) Bifurcation diagram with fast sodium blocked showing onset of pacemaker oscillations at the Hopf bifurcation. (C) Phaseplane with n = n∞(V ) showing relaxation oscillation. (D) Potential of the simple relaxation model. . . . . . . . . . . . . 88
5.2 Properties of the T-type calcium current. . . . . . . . . . . . . . . 90 5.3 Connor-Stevens model. (A) Delay to spiking depends on the A-
current. Dashed curve shows gK = 27.7, gA = 40 and solid curve shows gK = 17.7, gA = 50. (B) Steady-state I-V curve with two diﬀerent amounts of A-current. (C) Full bifurcation diagram for the CS model with default parameters. (D) Frequency-current curve for the CS model showing class I behavior. . . . . . . . . . . 91 5.4 Spike frequency adaptation from the M-type potassium current. The model is from Destexhe and Pare (1999) and represents a cortical pyramidal neuron. Applied current is 6 µA/cm2 and gM = 2mS/cm2. (A) Voltage and (B) instantaneous frequency versus spike number. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93 5.5 Eﬀects of M-current on equilibria. (A) Steady state as a function of current at three values of gm. With no M-current, the neuron is class I and oscillations are borne via a SNIC along the fold curve F. With large enough M-current (gm = 2), oscillations are borne via a Hopf (H) bifurcation and the fold points no longer exist since there is a unique equilibrium point. For intermediate values, the folds still exist, but the Hopf bifurcation occurs on the lower branch of ﬁxed points. (B) Two-parameter diagram. The two fold curves (F) meet at a cusp point (C) at near I = 4.8 and gm = 1.8. There is a curve of Hopf points (H) which terminates at a Takens-Bogdanov (TB) point when the Hopf curve meets a fold curve. Dashed line corresponds to gm = 1; as I increases, there is ﬁrst a Hopf point and then the fold. At gm = 0, no Hopf is encountered and when gm = 2, there are no folds. . . . . . . . . . . . . . . . . . . . . . . 93 5.6 The sag (Ih) current causes a slow repolarization of the potential to hyperpolarizing steps. (Parameters are those from McCormick et al.) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95 5.7 Calcium-dependent potassium channel. (A) Spike frequency adaptation showing decrease in frequency over time. (B) Steady-state ﬁring rate with and without adaptation. . . . . . . . . . . . . . . . 98 5.8 The CAN current can explain long-lasting persistent activity. (A) The voltage of a spiking model with three calcium stimuli. (B) The gate for the CAN current. . . . . . . . . . . . . . . . . . . . . 101
6.1 Square-wave bursting. Note that the active phase of repetitive ﬁring is at membrane potentials more polarized than during the silent phase. Moreover, the frequency of spiking slows down at the end of the active phase. . . . . . . . . . . . . . . . . . . . . . . . . 111

i i

i i

List of Figures

xv

6.2 A bifurcation diagram of the Morris-Lecar equations, homoclinic case. The set of ﬁxed points form an S-shaped curve (not all of which is shown). A branch of limit cycles originates at a Hopf point and terminates at a homoclinic orbit. There is an interval of applied currents for which the system displays bistability. . . . . . 112
6.3 (A) Bifurcation diagram of the fast-subsystem for square-wave bursters. (B) The projection of the bursting trajectory onto the bifurcation diagram. . . . . . . . . . . . . . . . . . . . . . . . . . . 114
6.4 Dependence of bursting oscillations and continuous spiking with respect to ǫ and λ. Bursting exists if λ < λ0 and spiking exists if λ > λ0. However, how small ǫ must be depends on how close λ is to λ0. There is an wedge-shaped region in which chaotic dynamics exist. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116
6.5 (A) Elliptic burster. Note the subthreshold oscillations. (B) Parabolic bursting. The frequency of spiking ﬁrst increases and then decreases during the active phase. . . . . . . . . . . . . . . . . . . . . 117
6.6 Bifurcation diagram associated with elliptic bursting. The projection of the elliptic bursting trajectory onto the bifurcation diagram is shown in (B). . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118
6.7 Bifurcation diagram of the fast-subsystem for parabolic bursting. (A) One of the slow variables is ﬁxed. Note that the branch of periodic orbits end at a SNIC. (B) With both slow variables as bifurcation parameters, the sets of ﬁxed points and limit cycles form surfaces. Also shown is the projection of the bursting trajectory onto the bifurcation diagram. . . . . . . . . . . . . . . . . . . . . . 120
6.8 Projection of the parabolic bursting solution onto (V, y1, y2)-space. There is a curve in the slow (y1, y2)-plane corresponding to SNIC’s. This curve separates the regions where the fast subsystem exhibits spiking and resting behavior. . . . . . . . . . . . . . . . . . . . . 121
6.9 Top hat bursting. . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
6.10 Chaotic dynamics may arise during the transition of adding spikes. As we increase ǫ, the number of spikes per burst will increase. As B) demonstrates, during this transition, there may exist solutions in which the number of spikes per burst is not constant. . . . . . . 124
6.11 A chaotic burst arising during the transition between bursting and continuous spiking. As we increase the parameter kCa, the model may exhibit A) regular bursting; B) chaotic bursting; C) chaotic spiking; and D) continuous spiking. . . . . . . . . . . . . . . . . . 125
6.12 Poincare map. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126
6.13 The Smale Horseshoe. The square S is stretched in the vertical direction, contracted in the horizontal direction and then folded. The intersection of π(S) with S forms two vertical strips. . . . . . 126
6.14 A generalized Smale horseshoe-type map that generates symbolic dynamics. The two squares S1 and S2 are stretched, contracted and then folded onto each other as shown. . . . . . . . . . . . . . . 128

i i

i i

xvi

List of Figures

6.15 The transition from bursting to spiking in the square-wave bursting model. If one ﬁxed ǫ > 0 and increases λ, then there is a series of increasingly more complex global bifurcations in which the system exhibits symbolic dynamics. . . . . . . . . . . . . . . . . . . . . . . 129
6.16 A) Bistability of bursting and spiking. There are stable and unstable limit cycles of the full system that lie close to P, the branch of periodic solutions of the fast-subsystem. The stable manifold of the unstable limit cycle separates those orbits that approaching the bursting solution from those that exhibit continuous spiking. B) The periodic orbits lie to the right of the left knee. Bursting no longer exhibits; however, there are orbits heteroclinic between the two limit cycles. C) and D) A blue-sky catastrophe occurs if the two limit cycles form a saddle-node bifurcation. . . . . . . . . 130

7.1 Action potential propagation for the HH equations. Discretization of the nonlinear PDE for a 10 cm axon into 150 segments.Ri = 100Ωcm and d = 0.1cm. (A) Voltage at x = 6 cm and x = 7 cm, showing velocity if about 1.25 meters/second (B) Spatial proﬁle at t = 20 msec; (C) Three-dimensional trajectory of the wave at grid point 50; axes are voltage, potassium gate and the voltage derivative.135
7.2 Numerical shooting for the HH ODE. (A) Shooting from the onedimensional stable manifold (SM) by integrating backward in time. For c too low, the stable manifold gos oﬀ the top and for c too high, out the bottom. (B) Numerically computed dispersion relation. This shows the speed c as a function of the spatial period, P . For each period P > P ∗ there are two velocities; one fast and one slow. 136
7.3 Existence of fronts in equation (7.4). For c = 0, the system is integrable. For c small, the unstable manifold of the right ﬁxed point (UM) falls below the stable manifold of the left-ﬁxed point (SM). For large c, the positions of the manifolds are reversed. For a single intermediate value of c = c∗, the manifolds intersect for a homoclinic. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138
7.4 Singular construction of the traveling wave. (A) Projection of the wave onto the (V, w)−phase plane. Initiation of the action potential is a front from the rest state to the right-branch with w held constant. Then along the right-branch of the nullcline w increases until wj where a wave back goes to the left branch. w then decays to rest along the left branch. (B) Pieces of the wave and the relevant voltages. Solid lines are front dynamics governed by (??) and dashed are branch dynamics governed by (??). (C) Details of the left and right branches. . . . . . . . . . . . . . . . . . . . . . . . . 142
7.5 Velocity versus temporal period T = P/c for the HH equations. (A) Full dispersion relation; (B) The function D(φ) = 1/c(φ) − 1/c∞.144

i i

i i

List of Figures

xvii

7.6 Dispersion relation for the ML model. (A) Class II dynamics showing characteristic damped oscillatory form with fast and slow wave branches connected (I = 80.) (B) Class I dynamics showing disconnected fast and slow waves (slow waves for I = 30 are on the c = 0 axis.) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146
7.7 Ermentrout-Rinzel excitable model. (A) Dynamics lies on a circle; the nonlinearit is periodic with period 2π and two ﬁxed points. (B) Phase-space of the travelling wave equations is a cylinder. For c = c∞ > 0 there is a “big” homoclinic which wraps around the cylinder; for c = 0, there is also a small homoclinic. These are depicted on the unfolded cyclinder; the “big” homoclinic is now a heteroclinic joining (2π + r, 0) to (r, 0) where f (r) = 0 and f ′(r) < 0. (C) Dispersion relation for f (V ) = I − cos(V ) when I = 0.95. (D) Velocity of a large period (100) wave as I varies. . . . . . . . . 147
7.8 Myelinated axon. Currents in myelinated region are conﬁned to the axial direction. Potentials at the nodes are governed by active currents. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152
7.9 The jellyﬁsh, A. digitale and the phaseplane for a tristable system 155
8.1 Model synaptic conductances. (A) AMPA (black) and GABA-B conductance due to a single presynaptic spike. (B) NMDA conductance to a single (red) and a burst of four (black) spikes. (C) GABA-B conductance to a burst of 8 spikes. Single spike response is negligible. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162
8.2 (A) Short-term synaptic plasticity in cortical neurons (From Beierlein et al 2003). Connections between cortical excitatory cells (RS) and cortical fast spike units (inhibitory) show synaptic depression to 20 Hz stimuli while RS to low threshold spike (LTS) inhibitory cells show facilitation. (B-D) simulations of equations (8.12) and (8.13) to periodic stimuli.Parameters for B are τd = 300, ad = 0.5, d0 = 1, τ = 10 and there is no facilitation. Parameters for C are τf = 500, af = 0.2, f0 = 0, τ = 10 with no depression. Frequency is 20 Hz. D has both depression and facilitation with f0 = 0, d0 = 1, τf = 50, τd = 400, af = 0.2, ad = 0.05 and τ = 5. The frequency is 100 Hz. . . . . . . . . . . . . . . . . . . . . . . . 166
9.1 Phase for a limit cycle. (A) Time trace showing deﬁnition of the phase zero as the peak of the potential. (B) Limit cycle in the phase plane showing contours with the same asymptotic phase. These are called isochrons. Initial condition x(0) is mapped to y0 on the limit cycle with phase φ. (C) Geometry of phase-resetting. At point (i) a perturbation along the x−axis at phase φ tends to a new asymptotic phase φ′ which is closer to spiking with respect to the original phase. The same perturbation at (ii) delays the next spike time. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173

i i

i i

xviii

List of Figures

9.2 Morris-Lecar oscillator (Class I parameters, I = 42) showing the asymptotic phase function Θ(x) and some representative isochrons. Black dots show values on the limit cycle in increments of 2.5 msec. Period of the limit cycle is 145 msec. . . . . . . . . . . . . . . . . . 174
9.3 Some experimentally measured PRCs from neurons. (A) Entorhinal cortex cells (Netoﬀ et al 2005) for excitatory (i) and inhibitory (ii) synaptic perturbations; (B) rat barrel cortex pyramidal cells (Stoop et al 2000) with inhibitory (i) and excitatory (ii) perturbations; (C) cat motor cortex neurons. Note that in B, what is plotted is T ′(φ)/T = g(φ) = 1 + ∆(φ)/T . . . . . . . . . . . . . . 176
9.4 Singular trajectory and the fast variable as a function of time. . . 181
9.5 The numerically computed adjoint for the ML model near the saddle-node bifurcation and its comparison to the asymptotic solution. Left panel, I = 40 and T = 943; right panel, I = 50 and T = 75.5. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181
9.6 The numerically computed adjoint for the Golomb-Amitai model near the supercritical Hopf bifurcation. Bottom ﬁgure shows the bifurcation diagram as a function of the current. Top two curves show the adjoint (black) and the approximation (red) a sin θ + b cos θ. Choices of a, b come from the Fourier expansion of the numerically computed adjoints. . . . . . . . . . . . . . . . . . . . . . 182
9.7 The adjoint for the ML model near the turning point bifurcation. Black curve is closest to the limit point and the adjoint has been scaled by a factor of 10 to ﬁt on the same ﬁgure. Phase is normalized from 0 to 1 for easier comparison since the periods are diﬀerent. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184
9.8 The eﬀects of outward currents on the PRC. (A) Adding an M-type potassium current to the Destexhe-Pare model adds a negative component to the adjoint. (B) PRCs for the quadratic integrate and ﬁre model with adaptation computed by injecting a pulse with amplitude 1 for 0.2 time steps. . . . . . . . . . . . . . . . . . . . 185
9.9 Post stimulus time histogram for a neuron. . . . . . . . . . . . . . 187
9.10 The rotation number for the map M (φ) = φ + ∆(φ) + Tf for ∆(φ) = 0.8(1 − cos φ) (black) and ∆(φ) = 0.000013φ6(2π − φ) (red) as Tf varies. Expanded region is shown on below. Some rational rotation numbers are shown. The right panel shows the relative sizes of the two PRCs. The slope of the red PRC at φ = 2π is the same as that of the black at φ = 3π/2. . . . . . . . . . . . . 192
9.11 Spike times of 2 coupled oscillators . . . . . . . . . . . . . . . . . . 193
9.12 Coupling of two phase equations. . . . . . . . . . . . . . . . . . . . 194
9.13 Mirollo-Strogatz map with f (t) = t(2 − t) and ǫ = 0.02 . . . . . . 197
9.14 Hippocampal oscillatory circuit. Two “columns” coupled via E to I synapses with a delay. . . . . . . . . . . . . . . . . . . . . . . . . 198
9.15 Weakly coupled WB model for inhibitory (left) and excitatory (right) coupling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207

i i

i i

List of Figures

xix

9.16 Interaction functions for an excitatory-inhibitory pair. Inset shows pure excitatory network. . . . . . . . . . . . . . . . . . . . . . . . 209
9.17 V ′(t) and two diﬀerent adjoints. . . . . . . . . . . . . . . . . . . . 210
9.18 50 Wang-Buszaki neurons coupled to nearest neighbors with inhibitory synapses (Reversal potential -80 mV, decay 6 msec). Each oscillator is driven by a constant current of 0.5 plus a small random value(between −0.0035 and 0.0035) to produce heterogeneity. Coupling strength is 0.02. Right-hand side is the phase-locked solution to the corresponding phase model. Below shows the space-time plot from Bao & Wu for a carbachol-treated slice. . . . . . . . . . 214
9.19 Steady state phases for a chain of 50 oscillators, H(φ) = sin φ + 0.5 cos φ with cut ends. Black line is equation (9.53). Right panel shows an array of 50 × 50 oscillators with the same H. . . . . . . 215
9.20 Rotating and spiral wave patterns seen in neural tissue. (A) From Huang et al in a tangential dis-inhibited cortical slice; (B) From Fuchs et al reconstructed from EEG electrodes in a human during alpha activity; (C) from Ermentrout and Kleinfeld optical activity in the turtle visual area; (D) steady state phases in a 20 × 20 array of nearest neighbor phase oscillators (H(φ) = sin φ); (E)as in (D) but H(φ) = sin φ + 0.5(cos φ − 1). . . . . . . . . . . . . . . . . . . 217
9.21 Propagating wave of activity in a brain slice preparation in which the inhibition has been blocked (Pinto et al 2006) (a) shows where the slice comes from (b) the exracellular potential recorded from a 16 electrode array (c) plot of (b) in pseudocolor (d) simulation of an array of 200 HH neurons with excitatory synaptic coupling and exponentially decaying spatial connectivity, (e) the membrane potential from cells at position 25 and 125 in the array . . . . . . 222
9.22 (A) Calculation of the wave speed for single-spike traveling waves as a function of the threshold and drive (B) Experimental velocity in a one-dimensional cultured network as a function of the amount of excitatory synaptic blocker, DNQX; (C) Same for a disinhibited slice. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 226
10.1 Solutions of a network of two mutually coupled Morris-Lecar neurons with excitatory coupling. A) Synchronous solution. The membrane potentials are equal so only one is shown. B) Antiphase behavior. The solutions shown in A) and B) are for the same parameter values but diﬀerent initial conditions. Hence, the system is bistable. . . . . . . . . . . . . . . . . . . . . . . . . . . . 248
10.2 Solutions of a network of two mutually coupled Morris-Lecar neurons with inhibitory coupling. A) Each cell ﬁres due to postinhibitory rebound. B) An almost-synchronous solution. C) A suppressed solution. D) The cells take turns ﬁring three spikes while the other cell is silent. . . . . . . . . . . . . . . . . . . . . . 249

i i

i i

xx

List of Figures

10.3
10.4
10.5
10.6
10.7 10.8 10.9 10.10 10.11 10.12 10.13
10.14 10.15 10.16 10.17

Firing patterns in inhibitory network. A) and B) show examples of clustering. Wave-like is shown in C) and dynamic clustering in D). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 250
Periodic solution of the Morris-Lecar equations corresponding to an action potential. The projection of this solution onto the (v, w)phase plane is shown in B). . . . . . . . . . . . . . . . . . . . . . . 251
Response of a model neuron to applied current. Current is applied at time t = 50 and turned oﬀ at t = 100. In the top ﬁgure, the current is depolarizing (I0 = .1), while in the bottom ﬁgure the current is hyperpolarizing (I0 = −.1) and the neuron exhibits post-inhibitory rebound. . . . . . . . . . . . . . . . . . . . . . . . 254
Phase space representation of the response of a model neuron to applied current. Current is applied at time t = Ton and turned oﬀ at t = Toff . (Left) Depolarizing current. The cell jumps up as soon as the current is turned on. (Right) Hyperplorizing current. The cell jumps to the left branch of C0 when the current is turned on and jumps up to the active phase due to post-inhibitory rebound when the current is turned oﬀ. . . . . . . . . . . . . . . . . . . . . 254
Synchronous singular trajectories corresponding to A) excitatory synapses and B) inhibitory synapses. . . . . . . . . . . . . . . . . . 256
Fast Threshold Modulation. . . . . . . . . . . . . . . . . . . . . . . 258
Post-Inhibitory Rebound. . . . . . . . . . . . . . . . . . . . . . . . 260
A) Cellular and B) synaptic escape mechanisms. . . . . . . . . . . 261
An example of dynamic clustering and reduction to discrete dynamics. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263
Discrete graph of dynamics associated with the network shown in Figure 10.3. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 264
Singular construction of antiphase solution. A) Cell 1 is shown in red and cell 2 in green. B) The auxiliary function w0(τ ) needed in the existence proof. . . . . . . . . . . . . . . . . . . . . . . . . . . 265
A) Projection of the antiphase solution onto the slow (w1, w2) phase plane. B) The one-dimensional map. . . . . . . . . . . . . . 268
Singular construction of the almost-synchronous solution. Cell 1 is shown in red and cell 2 in green. . . . . . . . . . . . . . . . . . . 271
Geometric construction of an antiphase solution for slow synapses. 275
Thalamic network model. (A) Phaseplane showing the h-nullcline (dashed) and V -nullcline at rest (s = 0). Several important values of h are shown. The approximate singular trajectory of a lurching wave is drawn in thick lines. (B) The architecture of the full model. (C) A simulation of a lurching wave. Grey scale depicts voltage; white=-40mV and black=-90mV. (D) The function F (φ) from equation (10.44 with hmax = .7, hmin(φ) = .2 + .5φ, hr(φ) = .5 + φ, τR/τL = .2 . . . . . . . . . . . . . . . . . . . . . . . . . . . 279

i i

i i

List of Figures

xxi

11.1 Noisy neurons. (A) Integrate-and-ﬁre model dV = (I − V )dt + σdW (t) with I = 0.75 and σ = 0.1. This numerical solution was computed using (11.2) with h = 0.01. Vertical lines represent times at which the model crosses V = 1 and is reset to 0. (B) Noise allows a subthreshold stimulus to be encoded. (C) Noisy ML model with class II parameters, I = 85 and unit variance noise in the voltage component. (D) Distribution of crossings of w = 0.3. . . . . . . . . 284
11.2 Simulated Wiener process, h = 0.01. (A). Sample path and mean and variance of 1000 sample paths (B).Probability histogram for 100000 sample paths starting at W (0) = 0. . . . . . . . . . . . . . 286
11.3 F-I curves for the leaky (spike is at 1 and reset at 0) and quadratic (spike is at 10 and reset at -1) integrate and ﬁre models. Solutions to the BVP are shown in black and Monte-Carlo simulations are shown in red. (A,B) LIF with σ = 0.25 (A) and σ = 1.0 (B). QIF with σ = 0.25 (C) and σ = 1 (D). . . . . . . . . . . . . . . . . . . 301
11.4 Interspike interval distributions for noisy scalar models. Monte Carlo simulations are dashed and solid lines are solutions to (11.15). Monte Carlo simulations are 50000 ISIs from an Euler simulation of (11.18). the PDE is solved by the method of lines on a ﬁnite interval divided into 200 bins. (A,B) Leaky integrate and ﬁre, f (V ) = I − V . PDE is solved on the interval (-4,1) with V = 1 absorbing and V = 0 as the reset value. (C,D) Quadratic integrate and ﬁre, f (V ) = I + V 2. PDE is solved on the interval (-5,5) with V = 5 absorbing and V = −1 as the reset value. Currents and noise are indicated in the ﬁgure. . . . . . . . . . . . . . . . . . . . 304
11.5 Response of a noisy LIF model to non-constant stimuli. LIF model has I = 0.75, Vspike = 1, Vreset = 0, σ = 0.4. (A) A non-periodic stimulus. Blue curve shows the stimulus. Lower curves show the response of the FP equation (red) and the instantaneous ﬁring rate (green) predicted by the steady-state FI curve. (B-D) Periodic stimuli at diﬀerent periods (denoted by P in the ﬁgures). Blue curve shows the stimulus and red the solution to the FP equation. The instant response is shown in green and the solution to the simple dynamic model (see text) is shown in black (τ = 0.2.) . . . 306
11.6 Bifurcation diagram for Morris-Lecar moment expansion for (A) Class II and (B) class I excitability as the current varies at zero noise and with large noise (σ2 = 2). In each case, the addition of noise shifts the loss of the stable ﬁxed point to a lower value of I. 309
11.7 Stochastic simulation of the Morris-Lecar model with 100 potassium and 100 calcium channels. I = 80µA/cm2 injected is subthreshold for repetitive ﬁring. (A) Time seris of the voltage (B) projection onto the (V, W ) plane showing stochastic limit cycle. (C,D) Langevin approximations to the channel dynamics. . . . . . 314

i i

i i

xxii

List of Figures

11.8 Poisson process with a relative refractory period. r(t) = rmax(1 − exp(−t/τ )). (A) Density function for a pure Poisson process with a 40 Hz rate and one with a refractory period, τ = 50 msec. (B) CV for diﬀerent rates and refractory periods. . . . . . . . . . . . . 316

12.1 Schematic of a pair of neurons synaptically coupled. . . . . . . . . 326
12.2 Nullcline conﬁgurations for mutually excitatory/inhibitory networks (A) mutual excitation, (B) mutual inhibition, (C) mutual excitation with weak self-connections. . . . . . . . . . . . . . . . . . . . 341
12.3 The simplest model for competition between two populations. (A) the circuit (B) nullclines for identical inputs at 3 diﬀerent strengths (C) bifurcation diagram when the inputs are identical (D) same as (C) but there is a small bias to population 1 . . . . . . . . . . . . 341
12.4 Sample bifurcation diagram for an excitatory and inhibitory population. Parameters are w11 = 12, w12 = 10, w21 = 16, w22 = 4, τ = 2. (A) Behavior of u1 as I1 increases, I2 = −4. (B) Two parameter diagram as a function of the inputs, I1, I2. Green circle indicate Takens-Bogdanov points. (C) Phaseplane for I2 = −4, I1 = 0. . . . 345
12.5 Modeling up and down states in cortex. (A) Experimental data from Shu et al showing (a) extracellular (upper curve) and intracellular (lower curve) recordings over about 10 seconds; (b) shows evoked states via external stimuli, (B) Simulation of up/down states in a noisy Wilson-Cowan model showing spontaneous switching. (C) Phaseplane explanation of the balanced bistable state. (Parameters are τ1 = 5, τ2 = 3, w11 = 16, w21 = 24, w12 = 10, w22 = 6, I1 = −3.7, I2 = −6.7. Colored noise is added to the inputs.) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 347
12.6 Whisker barrel system of the rat. (A) Rat face (B) layer 4 cortex in the whisker area of the rat showing discrete barrels corresponding to individual whiskers. The C3 barrel is circled. (C) Local circuitry within a barrel showing strongly recurrent excitatory and inhibitory network along with thalamic input. (D) Population response of excitatory cells to experimental movement of a whisker. Thalamic response is also shown. . . . . . . . . . . . . . . . . . . 348
12.7 Simulation of the barrel network. (A) Phaseplane for the barrel network at rest with two responses superimposed corresponding to input peaks at 1.6 and 3.2 msecs. (B) Firing rate of the excitatory population for the two inputs in (A) along with the inputs themselves (dashed). (Fe(x) = 5.12/(1 + exp(−(x − 15)/4.16)), Fi(x) = 11.61/(1 + exp(−(x − 15)/3.94), wee = 42, wie = 24.6, wei = 42, wii = 18, τe = 5, τi = 15, wte = 53.43, wti = 68.4.) . . . . 349
12.8 Stability plots for delay equations. . . . . . . . . . . . . . . . . . . 358

i i

i i

List of Figures

xxiii

13.1 Two examples of propagation in slices (a-c) a cortical layer 2/3 slice. A multiple electrode array is placed into the slice in which inhibition is blocked. Local shocking produces an event which propagates along the slice with a characteristic speed. (d,e) Similar experiment in the ferret thalamus showing the propagation of sleep spindles.(a-c from Pinto et al 2006; d,e from Kim et al, 1995.) . . 365
13.2 Space-time plots for the simulation of a network of 200 neurons coupled with an exponentially decaying weight function. Time goes down and spatial position is across. Colored according to the synaptic gate, s. (A) Traub model with synaptic decay of 3 msec; (B) Traub model with synaptic decay of 10 msec; (C) Firing rate model derived from the biophysical model. . . . . . . . . . . . . . 365
13.3 Waves in a slice preparation and simulations. (A) Experimental waves show spatial distribution of potential in an evoked wave. Inset shows the intracellular potential of a single cell as the wave passes through. (B) Simulation of the Traub model with an additional slow potassium current which terminates spikes. (C) Single cell potential as the wave passes through. (D) Plot of the synaptic gate against the slow potassium gate. . . . . . . . . . . . . . . . . 368
13.4 Singular construction of th traveling pulse. (A) Simulation of the network in equation (13.14- 13.15) showing four stages in the evolution of the wave. Synaptic activity and adaptation are shown. (B) Phase plane of (A). (C) “Fast” local dynamics showing bistability. 370
13.5 (A) Composite interaction function; (B) “bump” solution; (C) integral of J(x) showing allowable widths of the “bump”. . . . . . 374
13.6 Orientation tuning in neurons. (A) Sample stimuli to the visual system consist of oriented bars; (B) Firing rate of a visual cortex neuron as a function of the stimulus angle; (C) “Polar plot” for a neuron in the somatosensory cortex of the rat showing the strength (radial coordinates) of the response as a function of the direction of the whisker. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 379
13.7 The transformation from retinal to cortical coordinates (left) and its eﬀect on three of Kluver’s form constants. Most notably, bullseyes (starbursts) are transformed into horizontal (vertical) stripes. . . . 382
13.8 (A) The lateral inhibitory kernel, w(x) and the corresponding Fourier transform (B) . . . . . . . . . . . . . . . . . . . . . . . . . 385

i i

i i

xxiv

List of Figures

i i

i i

i i

Preface
One can say that the ﬁeld of computational neuroscience started with the 1952 paper of Hodgkin and Huxley in which they describe, through nonlinear partial differential equations, the genesis of the action potential in the axon of the giant squid. These equations and the methods that arose from this combination of modeling and experiments have since formed the basis for every subsequent model for active cells. The Hodgkin-Huxley model and a host of simpliﬁed equations that are derived from them have inspired the development of new and beautiful mathematics. Dynamical systems and computational methods are now being used to study activity patterns in a variety of neuronal systems. It is becoming increasingly recognized, by both experimentalists and theoreticians, that issues raised in neuroscience and the mathematical analysis of neuronal models provides unique interdisciplinary collaborative research and educational opportunities.
This book is motivated by a perceived need for an overview of how dynamical systems and computational analysis have been used in understanding the types of models that come out of neuroscience. Our hope is that this will help to stimulate an increasing number of collaborations between mathematicians, looking for classes of interesting and relevant problems in applied mathematics and dynamical systems, and neuroscientists, looking for new ways to think about the biological mechanisms underlying experimentally observed ﬁring patterns.
The book arose out of several courses that the authors have taught. One of these is a graduate course in computational neuroscience that has students from psychology, mathematics, computer science, physics and neuroscience. Of course, teaching a course to students with such diverse backgrounds presents many challenges. However, the course provides many opportunities to encourage students, who may not normally interact with each other, to collaborate on exercises and projects. Throughout the book are many exercises that involve both computation and analysis. All of the exercises are motivated by issues that arise from the biology.
We have attempted to provide a comprehensive introduction to the vocabulary of neuroscience for mathematicians who are just getting interested in the ﬁeld but who have struggled with the biological details. Anyone who wants to work in computational neuroscience should learn these details as this is the only way one can be sure that the analysis and modeling is actually saying something useful to the biologists. We have also tried to provide background material on dynamical systems theory, including phase plane methods, oscillations, singular perturbations and bifurcation analysis. An excellent way to learn this material is by using it,
xxv

i i

xxvi

Preface

together with computer simulations, to analyze interesting, concrete examples. The only prerequisite is a basic calculus course; however, it is very useful if students are comfortable with the basic theory of ordinary diﬀerential equations as well as linear algebra. Much of the mathematics is at the level of the book by Strogatz.
The book is organized from the bottom up. That is, we start with the biophysics of the cell membrane and from this introduce compartmental models, continuum limits and cable theory. We then add active ion channels. Prior to the work on active channels, all equations are linear and in theory completely solvable in closed form. Here we introduce a number of interesting approaches toward quantifying the responses of passive membranes to inputs. ...
There are several recent books that cover some of the same material in the present volume. Theoretical Neuroscience by Dayan and Abbott has a broader range of topics than our book. However, it does not go very deeply into the mathematical analysis of neurons and networks, nor does it emphasize the dynamical systems approach. A much closer book is Dynamical Systems in Neuroscience by Eugene Izhikevich. This book emphasizes the same approach as we take here. However, the main emphasis of DSN is in single neuron behavior. We cover a good deal of single neuron biophysics, but include a much larger proportion of theory on systems neuroscience and applications to networks.

i i

i i

Chapter 1

i i

Some basic biology
Neuroscience is the study of the brain. Brain function underlies all behavior including simple motor activity such as walking and smiling and higher order cognitive behavior such as thinking, learning and memory. The brain consists of neurons and glial cells. Neurons are the basic signaling units of the nervous system. The majority of this book is devoted to the mathematical analysis of models that describe the behavior of these cells. Glial cells are important in maintaining the health of neurons and how they behave and interact. Neurons communicate with each other at synapses. It has been estimated that there are approximately 1011 neurons and 1015 synapses in the human brain. Hence, neurons typically receive inputs from a very large number of other cells.
In the remainder of this chapter, we describe some basic properties of the brain, neurons and synapses. We will only touch on material that is absolutely essential for anyone interested in computational neuroscience. We highly recommend that the reader study this material in more detail by consulting one of the many excellent books devoted to neuroscience. Such books include Kandel/Schwartz/Jessell, Johnston/Wu, ... In fact, much of the following discussion is based on material from those books.
1.1 The brain
The brain is highly organized both anatomically and functionally. The central nervous system (CNS) consists of two main parts: the spinal cord and the brain. The brain itself is partitioned in several areas. These are: the medulla oblongata, the pons, the cerebellum, the midbrain, the diencephalon, and cerebral hemispheres. Each of these consists of many parts or nuclei. For example, the diencephalon contains the thalamus and the hypothalamus. The cerebral hemispheres consist of the cerebral cortex and deep-lying structures that include the basal ganglia, the hippocampus and the amygdaloid nucleus. The cortex consists of four lobes; these are the frontal, parietal, occipital and temporal lobes.
Diﬀerent brain structures are responsible for diﬀerent functions. For example,
1

i i

2

Chapter 1. Some basic biology

the brainstem is responsible for maintaining many of the functions necessary for life such as breathing and heart rate. The basal ganglia participate in regulating motor performance and the thalamus processes most of the information reaching the cerebral cortex from the rest of the CNS. The cerebral cortex is the large region (large in mammals, notably humans, but nonexistent in many other vertebrates) that is directly beneath the skull. The cortex is responsible for our sensory, cognitive, and voluntary motor behaviors. The diﬀerent lobes of the cortex have specialized functions: the frontal lobe is largely concerned with the planning and organization of future actions; the occipital lobe is concerned with vision; the pariental lobe receives sensory information; and the temporal lobe is involved with hearing and other aspects of language and memory.

Figure 1.1.
We note that each hemisphere is concerned primarily with sensory and motor processes on the contralateral side of the body. That is, sensory information that enters the spinal cord from the left side of the body crosses over to the right side of the nervous system, while motor areas in one hemisphere exert control over the movements of the opposite half of the body.
Cognitive and motor activities may be highly localized within the cerebral cortex. There are, in fact, sensory maps in which sensory information such as touch is organized topographically in the brain. Each part of the body is represented separately in a speciﬁc location in the somatosensory cortex. Sensitive regions, such as the ﬁngers and mouth, take up the most space. This is shown in Figure 1.2.
As one further example of how cognitive activities are localized within the brain, consider language. Diﬀerent aspects of language are processed in diﬀerent areas of the cortex. One area, called Wernicke’s area, is important to the understanding of spoken language, while another area, called Broca’s area, is concerned

i i

i i

1.2. The neuron

3

Figure 1.2.
with issuing speciﬁc commands that cause the mouth and tongue to form words. Hence, damage to Wernicke’s area makes it impossible for a person to understand speech, while damage to Broca’s area makes it impossible for a person to speak.
While cognitive and motor activities are localized within the brain, it is important to realize that complex mental activities, such as learning or memory, typically involve interconnections between many brain regions. We have seen, for example, that language involves both Wernicke’s and Broca’s area, which lie in diﬀerent parts of the left cerebral hemisphere. Interrelated mental activities are processed by many neural pathways that are distributed in parallel. For this reason, damage to one single area often does not necessarily lead to the loss of a speciﬁc function.
1.2 The neuron
Neurons are specialized cells that like all other cells contain the usual organelles necessary for staying alive. These include the mitochondria, responsible for fueling the cells, and the nucleus, which holds the genetic material that gets passed on when the cell divides.
The structure of a neuron can be divided into three parts: (i) the dendrites; (ii) the soma; and (iii) the axon. The soma or cell body is the site of the nucleus and all the normal cellular machinery. Functionally the soma plays the role of integrating all of the inputs of the cell to produce some output. The dendrites and axon are processes that emanate from the soma. Neurons usually have several dendrites; these form the “input lines” of the cell. The dendrites often branch out

i i

i i

4

Chapter 1. Some basic biology

in a tree-like fashion that can be very large. In many cases, the majority of the surface area of the cell is taken up by the dendrites. Neurons usually have some sort of general orientation. Dendrites that lie at the top of the neuron are called apical dendrites and those that lie at the base are called basal dendrites. Figure 1.2 shows the variety of possible shapes that neurons can take; the main diﬀerences are in the shapes of the dendritic trees. Although neurons share many common features, it has been estimated that there are as many as 10,000 diﬀerent types.

Figure 1.3.
The axon typically leaves the soma as a single thin process but then branches out in order to connect to other cells. The diameter of an axon may range from .2 to 20 µm and may extend for up to one meter. The axon is the major conducting unit of the neuron; it can convey information great distances by propagating a transient electrical signal called the action potential. The action potential is initiated at a specialized region of the soma called the axon hillock. Large axons are surrounded by a fatty insulating sheath called myelin. This is essential for high-speed conduction of action potentials. The sheath is interrupted at regular intervals by nodes of Ranvier.
The action potential represents a change in the neuron’s membrane potential. Neurons, like all other cells, maintain a potential diﬀerence of about 65 mV across their external membrane. What distinguishes neurons and other excitable cells from most cells in the body is that this resting membrane potential can be altered and can, therefore, serve as a signaling mechanism. The action potential corresponds to a change in resting potential that propagates along the axon. The action potential is initiated when the membrane potential at the axon hillock reaches some threshold potential; once this threshold is reached, the signal propagates in a all-or-none fashion. That is, the amplitude and duration of the signal is always the same no matter how it is generated. Action potentials may last as short as 1 ms and

i i

i i

1.3. The synapse

5

may travel at rates that vary between about 1 and 100 meters per second. After each action potential, there is a period during which a second impulse cannot be initiated. The is referred to as the refractory period.
Stronger stimuli often produce higher frequencies of impulse ﬁring. Since the shape and speed of each action potential does not depend on the stimulus, information about the stimulus is often carried in the frequency of ﬁring. The frequency is limited by the refractory period. Some neurons are capable of continuously generating action potentials, even without inputs. The temporal pattern of ﬁring may be quite complicated. A neuron may generate a single spike in a periodic fashion, or may generates bursting activity in which there are episodes of high frequency ﬁring separated by periods of quiescent behavior. More complicated ﬁring patterns are possible and these will be described later in the text.
In the following sections, we shall give much more details of the mechanisms underlying the generation of action potentials. This, in turn, will lead to the famous Hodgkin-Huxley model for the propagation of action potentials along the nerve axon.

V
20 0
−20 −40 −60
0 C

10mV

500

1000

1500

gton=.6

2000

2500

4 sec

Figure 1.4.
1.3 The synapse
Neurons communicate with each other at synapses. The cell that is sending the signal is called the presynaptic neuron and the cell that is receiving the signal is called the postsynaptic neuron. Synapses can be either electrical or chemical. In electrical synapses, there is a direct connection from one neuron to another by way of a channel or gap junction. This type of synapse is rare among the principal cell types in the mammalian brain; for this reason, we will concentrate primarily on chemical synapses.

i i

i i

6

Chapter 1. Some basic biology

In chemical synaptic signaling, there is a space, called the synaptic cleft, separating the presynaptic from the postsynaptic cell. Most presynaptic neurons terminate near the dendrites of the postsynaptic cell; however, communication may occur with the cell body or, less often, with portions of the axon.
Signals from the presynaptic neurons result in the release of chemicals, called neurotransmitters. Neurotransmitters diﬀuse across the synaptic cleft and bind to receptors on the postsynaptic cell causing changes in the membrane potential. The membrane potential of the postsynaptic cell may either increase or decrease relative to its resting potential. This depends on the nature of the neurotransmitter and the type of receptor it binds to. A reduction of membrane potential (that is, the inside of the cell becomes less negative with respect to the outside) is called depolarization and the synapse is said to be excitatory. An increase of membrane potential (the inside becomes more negative) is called hyperpolarization. In this case, the synapse is said to be inhibitory.

Figure 1.5.
We have seen that chemical synapses can be either excitatory or inhibitory. They can also be classiﬁed as direct or indirect. In a direct synapse, the postsynaptic receptor contains both the transmitter binding site and the ion channel opened by the transmitter as part of the same receptor. In an indirect synapse, the transmitter binds to receptors that are not themselves ion channels. Direct synapses are typically much faster than indirect synapses. In fact, direct synapses are often referred to as fast synapses, while indirect synapses are referred to as slow synapses.
Electrical synapses have the advantage that they are fast; there is not the time delay associated with chemical synapses. However, chemical synapses, which are much more abundant in the human brain, have many advantages. They are able to

i i

i i

1.3. The synapse

7

amplify signals; a single action potential from the postsynaptic cell may result in a much more powerful, longer lasting response in the postsynaptic cell. Moreover, indirect synapses can be modiﬁed, through a process called neuromodulation, so that the eﬃcacy of the synaptic response may change (through learning, for example).
The architecture of synaptic connections may be quite complicated. Each neuron in the human brain receives, on average, inputs from about 10000 other neurons. Neurons may communicate with other cells close by, while neurons with long axons may make synapses up to a meter away. Synaptic communication need not be in one direction; that is, neurons may make reciprocal synapses onto their presynaptic cells. Since most neurons have similar electrical properties, diﬀerent functions carried out by diﬀerent parts of the brain may be due to diﬀerences in the synaptic connections.

i i

i i

8

Chapter 1. Some basic biology

i i

i i

i i

Chapter 2
The Hodgkin-Huxley equations
2.1 The resting potential
All living cells have an electrical voltage, or potential diﬀerence, between their inside and outside. Since the cell’s membrane is what separates the inside from the outside, this potential diﬀerence is referred to as the membrane potential. In mathematical terms, the membrane potential VM is deﬁned as
VM = Vin − Vout
where Vin is the potential on the inside of the cell and Vout is the potential on the outside. This will change during an action potential, for example.
The resting potential refers to the potential across the membrane when the cell is at rest. A typical neuron has a resting potential of about -70 millivolts. An inward current corresponds to a positively charged ion, such as Na+, entering the cell. This raises the membrane potential; that is, it brings the membrane potential closer to zero. In this case, the cell is said to be depolarized. An outward current corresponds to a positively charged ion, such as K+, leaving the cell or a negatively charged ion, such as Cl−, entering the cell. In this case, the cell becomes hyperpolarized.
The potential diﬀerence arises from diﬀerences in the concentrations of various ions within and outside the cell. The maintenance of the potential diﬀerence also involves the transport of ions across the cell membrane and the selective permeability of the membrane to these ions. The principal ions found on either side of the cell membrane are Na+, K+, and Cl−. The concentration of K+ ions inside a cell is about 10 times that in the extracellular ﬂuid, whereas the concentrations of Na+ and Cl− are much higher outside the cell than inside.
The lipid bilayer of the cell membrane is a poor conductor of ionic current because it is not permeable to ions. However, the membrane does contain channel proteins that allow for the ions to move through it. There are two types of ion channels in the membrane: gated and nongated. Nongated channels are always open, while gated channels can open and close and the probability of opening often depends on the membrane potential; these are referred to as voltage-gated chan-
9

i i

10

Chapter 2. The Hodgkin-Huxley equations

nels. Gated channels are typically selective to a single ion. The permeability of the
membrane to a particular ion depends on the number of open channels selective to
that ion. Most gated channels are closed at rest. Hence, the nongated ion channels are primarily responsible for establishing the resting potential. An action potential
is generated when gated channels open allowing for the ﬂux of ions across the cell membrane.
Because of concentration diﬀerences, when the appropriate channels are open,
sodium and chloride ions tend to diﬀuse into the cell, while potassium ions tend to diﬀuse outwards. Note that ions do not simply diﬀuse in or out of an open channel
until the concentrations of that ion on either side of the cell is zero. This is because
of the electric ﬁeld created by separation of positive and negative charges across the cell membrane.
Suppose, for example, that the cell is permeable only to K+. The concentration gradient of K+ moves K+ ions out of the cell. However, the continued eﬄux of K+ builds up an excess of positive charge on the outside of the cell and leaves behind
an excess of negative charge on the inside. The negative charge consists mostly of impermeable organic anions A−. This buildup of charge acts to impede the further eﬄux of K+, so that eventually an equilibrium is reached. At this equilibrium,
the electrical and chemical driving forces are equal and opposite. The membrane potential at which K+ ions are in equilibrium across the membrane is called the K+
Nernst, equilibrium or reversal potential.

A)
Cl -

Na+

Na+

Na+ K+

Extracellular side

B)

Cl -

Cl -

Na+

K+

Na+

Na+

Na+

++++++

Cl -

K+

Na+

++++++

Cytoplasmic side
AA-
K+

K+

K+

A-

A-
K+

-----A- A-

------

K+

A-

K+

A-

K+

Figure 2.1. The K+ ﬂux is determined by both the K+ concentration
gradient and the electrical potential across the membrane. A) For a cell that is permeable only to K+, the concentration gradient of K+ moves K+ ions out of the cell. B) The continued eﬄux of K+ builds up an excess of positive charge on the
outside and negative charge on the inside. At equilibrium, the electrical and chemical
driving forces are equal and opposite.

In the next section, we shall derive the following expression for the K+ Nernst

i i

i i

2.2. The Nernst equation

11

potential:

EK

=

RT zF

ln

[K + ]out [K +]in

.

(2.1)

Here, EK is the K+ Nernst potential, R is the gas constant, T is the temperature in degrees Kelvin, z is the valence of K+, F is Faraday constant and [K+]out and [K+]in are the concentrations of K+ ions outside and inside of the cell. A similar formula holds for the Na+ and Cl− Nernst potentials.
Neurons at rest are permeable to Na+ and Cl− in addition to K+. Because of their concentration diﬀerences, Na+ and Cl− ions move into the cell and K+ ions move outwards. The inﬂux of Na+ ions tends to depolarize the cell, while the eﬄux of K+ and the inﬂux of Cl− have the opposite eﬀect. The resting potential of the
cell is the potential at which there is a balance between these ﬂuxes. It depends
on the concentrations of the ions both inside and outside of the cell, as well as the
permeability of the cell membrane to each of the ions. We note that at rest, there are many more K+ and Cl− channels than Na+ that are open. Hence, the cell’s resting potential is determined primarily by the K+ and Cl− Nernst potentials. In the
following sections, we shall derive the Goldman-Hodgkin-Katz equation, which gives
an explicit expression for how the resting potential depends on the concentrations,
both inside and outside, of ions and the permeabilities of the membrane to the ions. In order for a cell to maintain a constant resting potential, the eﬄux of K+
ions must balance the inﬂux of Na+ ions. (Here we are ignoring Cl− ions.) That
is, the charge separation across the membrane must be constant. If these steady
ion leaks continue unopposed, then potassium ions within the cell would become
depleted, while the concentration of sodium ions inside the cell would increase. This
would eventually result in a loss of the ionic gradients, necessary for maintaining the
resting potential. The dissipation of ionic gradients is prevented by active pumps the extrudes Na+ ions from the cell while taking in K+. The Na+-K+ pump is an integral membrane protein that exchanges three Na+ ions for two K+ ions. This
is probably the most important ion transporter in biological membranes; however,
there are many other proteins in the membrane that are capable of pumping ions
from one side of the membrane to the other.

2.2 The Nernst equation
Here we derive the Nernst equation and in the next section, we derive the GoldmanHodgkin-Katz (GHK) equation. Recall that if the membrane is permeable to only one ion, then that ion’s Nernst potential is the resting potential at which the electrical and chemical driving forces balance. The GHK equation is, in some sense, a generalization of the Nernst equation in which we assume that the membrane is permeable to more than just one ion. The GHK equation determines the resting potential at which the electrical and chemical forces, generated by each of these ions, balance with each other. The ﬁrst step in deriving these equations is to derive the Nernst-Plank equation.
In what follows, let [C](x) be the concentration of some ion and V (x) be the potential at the point x across the membrane. Then Fick’s law of diﬀusion says

i i

i i

12

Chapter 2. The Hodgkin-Huxley equations

that the diﬀusive ﬂux, Jdiff , is given by:

Jdif f

=

−D

∂[C] ∂x

.

The diﬀusion constant, D has units of cm2/sec and the concentration is in molecules per cubic centimeter so that the diﬀusive ﬂux has units of molecules/sec-cm2. (Think of the ﬂux as movement across the two-dimensional cell surface.) The direction of movement is from high concentrations to low concentrations. The diﬀusion constant (empirically measured) depends on the size of the molecule and the medium in which it is diﬀusing. A typical value for ions like potassium, chloride, and sodium is 2.5 × 10−6cm2/sec. Calcium has a diﬀusion constant about an order of magnitude less.
The other physical force that is responsible for the passive movement of ions is the electrical drift described by the microscopic version of Ohm’s law:

Jdrif t

=

−µz[C]

∂V ∂x

.

The

electric

ﬁeld,

E

≡

−

∂V ∂x

,

is

the

gradient

of

the

potential

V

(measured in volts)

and thus has units of volt/cm. z is the valence of the ion (±1, ±2, etc). The param-

eter µ is mobility and has dimensions of cm2/V-sec and [C] is the concentration.

The higher the concentration, the greater the drift. Note that drift has the same

dimensions as the diﬀusive ﬂux.

The total ﬂux across the membrane is given by the sum of these two:

Jtotal

=

−D

∂[C ∂x

]

−

µz[C

]

∂V ∂x

.

Einstein’s relation connects the mobility with the diﬀusion coeﬃcient:

D

=

kT q

µ

where k is Boltzmann’s constant (joule/◦K), T is the absolute temperature, and q is the charge (measured in coulombs). Thus, we can write the total ﬂux as:

Jtotal

=

−

µkT q

∂[C] ∂x

−

µz[C]

∂V ∂x

.

It is convenient to convert this equation, which is in terms of the number of individual molecules into its molar equivalent, by dividing by Avogadro’s number. It is also convenient to replace kT /q with RT /F where R is the ideal gas constant and F is the Faraday constant. (A list of these constants is given at the end of this section.) This will yield the ﬂux per mole. Multiplying this ﬂux by the valence and Faraday’s constant yields a current ﬂux:

I =−

uzRT

∂[C] ∂x

+

uz2F

[C]

∂V ∂x

i i

i i

2.3. The Goldman-Hodgkin-Katz equation

13

measured in amperes/cm2. The quantity u is the molar mobility, µ/NA. This equation is the Nernst-Planck Equation.
The Nernst equation is obtained by setting the current to zero. That is, for a given ion species, at equilibrium, the diﬀusion and electric eﬀects balance:

I =−

uzRT

∂[C] ∂x

+

uz

2F

[C

]

∂V ∂x

= 0.

As an exercise, it is left to the reader to prove that this implies the Nernst equation:

Veq

≡

Vin

− Vout

=

−

RT zF

ln

[C ]in [C ]out

.

(2.2)

That is, the equilibrium, or Nernst, potential, occurring when all the ﬂuxes balance, depends on the logarithm of the ratio of the concentrations of the ions inside and outside of the cell.
To illustrate how to use the Nernst equation to compute an equilibrium potential, note that in a typical mammalian cell, there is 140 mM of potassium inside the cell and 5 mM outside. At room temperature 37◦C, RT /F = 62 mV. This means the equilibrium potential of potassium is

−62

log

140 5

=

−89.7mV.

As above, we will leave the details of this calculation the reader.

2.3 The Goldman-Hodgkin-Katz equation
The Nernst-Planck equation describes the movement of charged ions in aqueous media. However, the cell membrane has thickness and there may be energy barriers or blocking sites within the channel. In this case, the ions ﬂowing through the open channel may not obey the Nernst-Planck equation and we must model the complex behavior within this membrane to get a true picture of the ﬂux across the cell. This type of biophysics is beyond the details that are needed for this book, but the resulting equation does play a role in later parts. Thus, we will present a shortened derivation of a simpliﬁcation of what happens within the membrane. Goldman, Hodgkin, and Katz came up with this simpliﬁed model called the constant ﬁeld equation (CFE). They assume that (i) the electric ﬁeld across the lipid membrane is constant, (ii) the Nernst-Planck equation holds within the membrane, and (iii) the ions all move independently.
Let VM be the total potential across a membrane of width l and let V (x) be the potential at the point x across the membrane. Since the electric ﬁeld is constant, E = −VM /l. This implies that dV /dx = VM /l. The mobility of ions within the membrane will be diﬀerent than in the aqueous solution; denote this mobility by u∗. Finally, let β be the ratio of the ion solubility within the membrane to the solubility in the aqueous solution. Thus, if [C] is the aqueous concentration, then β[C] is the membrane concentration. With these assumptions the Nernst-Planck

i i

i i

14

Chapter 2. The Hodgkin-Huxley equations

equation for current across the membrane is:

I

=

−u∗z2F

β[C]

VM l

−

u∗z

RT

β

d[C dx

]

,

0 < x < l.

This is just a ﬁrst order linear ordinary diﬀerential equation for [C] subject to the two boundary conditions

[C](0) = [C]in, [C](l) = [C]out.

One cannot, in general, solve a ﬁrst order equation with two boundary conditions. However, the current I is unknown, so that choosing this correctly will allow us to ﬁnd a solution that satisﬁes both boundary conditions. We leave this elementary exercise to the reader. The result is:

I

=

u∗z2F VM β l

[C]oute−ξ − [C]in e−ξ − 1

where

ξ

=

zVM F RT

.

This expression is often written in terms of the permeability,

P

≡

βu∗RT lF

;

that is,

I = PzFξ

[C]oute−ξ − [C]in e−ξ − 1

.

(2.3)

The permeability has dimensions of cm/sec. Thus, the dimensions are in terms of current per unit area.
This is the current due to a single ionic species. The current vanishes at the equilibrium or Nernst potential of the ionic species. A common quantity to plot is the current-voltage (I − V ) plot. If the inside and outside concentrations are identical, then the I − V plot is linear. For [C]out > [C]in (resp. [C]out < [C]in ) the I − V plot is concave down (resp. concave up). The reader is encouraged to plot the current as a function of the voltage for diﬀerent concentration ratios. If the concentrations are quite diﬀerent on the inside and outside, then the I − V curve is strongly rectifying. That means that the magnitude of the current depends strongly on whether or not the potential is above or below the equilibrium.
Given several ionic species, the total current is just a sum of the individual currents. This is a consequence of assumption (iii) which says that the ions do not interact. Suppose that there are three permeant ions: K+, N a+ and Cl− with corresponding currents, IK , INa and ICl. At equilibrium the total current, I = IK + INa + ICl vanishes; that is, I = 0. The potential at which this occurs is:

VM

=

RT F

ln

PK [K+]out + PNa[N a+]out + PCl[Cl−]in PK [K+]in + PNa[N a+]in + PCl[Cl−]out

(2.4)

i i

i i

2.3. The Goldman-Hodgkin-Katz equation

15

Table 2.1. Typical ion concentrations in cells. (From Johnstonand Wu).

Ion

Inside

Outside

Equilibrium Potential

(mM)

(mM)

Ei

=

RT zF

ln

[C ]out [C ]in

Frog Muscle

T = 20◦C

K+

124

2.25

N a+

10.4

109

Cl−

1.5

77.5

C a2+

10−4

2.1

Squid Axon

58 log

2.25 1.24

=

−101mV

58 log

109 10.4

=

+59mV

−58 log

77.5 1.5

=

−99mV

29 log

2.1 10−4

=

+125mV

T = 20◦C

K+ N a+ Cl−
C a2+
Mammalian cell K+ N a+
Cl− C a2+

400 50 40-150 10−4
140 5-15 4 10−4

20 440 560 10
5 145 110 2.5-5

58 log

20 400

=

−75mV

58 log

440 50

=

+55mV

−58

log

560 40−150

= −66 to

− 33mV

29 log

10 10−4

=

+145mV

T = 37◦C

62 log

5 140

=

−89.4mV

62 log

145 5−15

=

+90

−

(+61)mV

−62 log

110 4

=

−89mV

31 log

2.5−5 10−4

=

+136

−

(+145)mV

where the Pj ’s are the permeabilities of each of the three ionic species. This is a generalization of the Nernst equilibrium discussed above and is called the GoldmanHodgkin-Katz equation (GHK). With one species, the equation reduces to the Nernst potential. For example, in the squid axon, the ratios of the permeabilities, at rest, are PK : PNa : PCl = 1 : 0.03 : 0.1. The ion concentrations inside the cell are, respectively, for K, N a and Cl, 400 mM, 50 mM, and 40 mM; while outside the cell they are 10 mM, 460 mM, and 540 mM. Thus, at room temperature, the equilibrium or resting potential is -70 mV.

i i

i i

16

Chapter 2. The Hodgkin-Huxley equations

Table 2.2. Elementary constants

NA = 6.022 · 1023 /mol Avogadros number k = 1.380658 · 10−23j/K Boltzmanns constant R = 8.31451 j/(mol − K) Ideal gas constant e = 1.602177 · 10−19 C electron charge F = 96485.3 C/mol Faraday’s constant ǫ0 = 8.85 · 10−12 F/m permittivity constant
Kelvin = Centigrade + 273.16 1 j = .238845 cal
L = liter nt = newton j = joule (nt-sec) V = volt = 1joule/coulomb C = coulomb A = ampere (C/sec) Ω = Ohm (V/A) S = 1/Ω = siemens (A/V) F = farad (sec-A/V) = (C/V)

2.4 Exercises
1. Suppose the external potassium in a mammalian cell is increased by a factor of 10. What is the new value of EK?
2. At 10◦C a cell contains 80 mM sodium inside and has only 100 mM sodium outside. What is the equilibrium potential for sodium?
3. Using the same permeabilities for the mammalian cell as were used for the squid axon, compute Vrest, Vm using the table of ion concentrations.
4. Derive the Nernst equation from the Nernst-Planck equation by setting the current to 0 and integrating with respect to x across the membrane.
5. Using the elementary constants deﬁned in Table 2.3, obtain the two simpliﬁed versions of the Nernst equation. Compute the calcium equilibrium potential for a mammalian cell assuming that the extracellular concentration is 5 mM and the intracellular is 10−4mM.

i i

i i

2.5. Equivalent circuits: the electrical analogue

17

6. Derive the constant ﬁeld equation from the linear Nernst-Planck equation.
7. Derive the GHK equation from the constant ﬁeld equation.
8. Consider the GHK equation and plot the I − V relation for diﬀerent values of the inside and outside concentrations. Show that for [C]out > [C]in (resp. [C]out < [C]in ) the I − V plot is concave down (resp. up)

2.5 Equivalent circuits: the electrical analogue

We have seen in the previous section that the electrical properties of cells are de-

termined by the ionic species that move through the membrane. Currents ﬂow

according to the permeabilities of ion channels and concentration gradients across

the cell membrane. However, all of our discussion so far has been in a steady-state

environment. The Goldman-Hodgkin-Katz equation does not determine how the

membrane potential changes in response to changes in the permeabilities. For this

reason, it cannot be used to understand how these changes in permeabilities may

generate an action potential. A very useful way to describe the behavior of the

membrane potential is in terms of electrical circuits; this is commonly called the

equivalent circuit model. The circuit consists of three components: (1) conductors

or resistors, representing the ion channels; (2) batteries, representing the concen-

tration gradients of the ions; and (3) capacitors, representing the ability of the

membrane to store charge. The equivalent circuit model leads to both an intuitive

and quantitative understanding of how the movement of ions generate electrical

signals in the nerve cell.

We ﬁrst consider a membrane that is only permeable to potassium. The

equivalent circuit is shown in Figure 2.2. The lipid bilayer that comprises the cell

membrane has dielectric properties and as such behaves in much the same manner

as a capacitor. Recall that capacitors store charge and then release it in the form

of currents. The relationship between the charge stored and the potential is given

by:

q = CM VM ;

(2.5)

that is, the total charge q is proportional to the potential VM with a proportionality constant CM called the membrane capacitance. Note that the total capacitance depends on the total area of the dielectric; thus larger neurons have a larger to-
tal capacitance than smaller ones. The capacitance per square centimeter is called the speciﬁc membrane capacitance and will be denoted as cM . Hence, the total membrane capacitance CM is the membrane speciﬁc capacitance cM times the total surface area of the cell. In general, the speciﬁc membrane capacitance may depend on the potential; however, for most cell membranes, the speciﬁc membrane capacitance is very close to 1 µ F/cm2.
Since current is the time derivative of charge, we can diﬀerentiate (2.5) and obtain an expression for the speciﬁc capacitance current:

icap

=

cM

dVM dt

.

(2.6)

i i

i i

18

Chapter 2. The Hodgkin-Huxley equations

Lipid bilayer

RK

CM

VM

EK

Channel

Figure 2.2. Cartoon of the cell membrane showing the insulating lipid bilayer and a K+ channel which allows current to ﬂow. The equivalent electrical
circuit is shown on the right

This gives the capacitance current per unit area. We will denote the total capaci-
tance current as Icap. In the equivalent circuit, K+ channels are represented as a conductor in series
with a battery. If gˆK is the conductance of a single K+ channel, then, using Ohm’s law, the ionic current through this channel is

IˆK = gˆK(VM − EK ).

(2.7)

Here EK is the potential generated by the battery; this is given by the K+ Nernst potential. The driving force is VM − EK . Now suppose there are NK potassium channels in a unit area of membrane. These can all be combined into the single
equivalent circuit shown in Figure 2.2. The conductance per unit area, or speciﬁc membrane conductance (S/cm2) is given by gK = NK × gˆK and the speciﬁc membrane resistance (Ω-cm2) is rK ≡ 1/gK. Since the Nernst potential depends only on the concentration gradient of K+, and not on the number of K+ channels, it follows that the K+ current, per unit area, is given by

IK

=

gK (VM − EK )

=

VM

− rK

EK

.

(2.8)

Kirchhoﬀ’s current law states that the total current into the cell must sum to zero. Together with the equivalent circuit representation, this leads to a diﬀerential equation for the membrane potential:

0=

icap + IK

=

cM

dVM dt

+

VM − EK rK

(2.9)

or

cM

dVM dt

=

− VM − EK rK

=

− gK (VM − EK ).

(2.10)

i i

i i

2.5. Equivalent circuits: the electrical analogue

19

Figure 2.3 shows an equivalent circuit with three parallel conductances and a current source, I(t). Here the capacitance current must be equal to the sum of the ionic currents and the current source. As before, the capacitance current, per unit area, is given by (2.6) and the ionic current, per unit area, is given by

iion = gCl(VM − ECl) − gK(VM − EK ) − gNa(VM − ENa).

(2.11)

The current source is not typically expressed as current per unit area, so we must divide I(t) by the total surface area of the neuron, A. It then follows that

cM

dVM dt

= −gCl(VM − ECl) − gK (VM − EK ) − gNa(VM − ENa) + I(t)/A.

(2.12)

Note that we can rewrite this equation as

cM

dVM dt

=

−

(VM − rM

ER)

+

I (t)/A

(2.13)

where

ER = gClECl + gK EK + gNaENa

is the cell’s resting potential and

rM

=

gCl

1 + gK

+ gNa

is the speciﬁc membrane resistance. For a passive membrane in which the conductances and currents are all con-
stant, then VM will reach a steady state:

Vss

=

gClECl + gK EK + gNaENa gCl + gk + gNa

+ I/A .

In absence of the applied current, the steady state potential is a weighted sum of the equilibrium potentials of the three currents. This is similar to the GoldmanHodgkin-Katz equation (2.4) in which the contribution to the resting potential by each ion is weighted in proportion to the permeability of the membrane for that particular ion. Note, however, that in the equivalent circuit model, the equilibrium is a linear weighted sum of the equilibrium potentials, while in the GHK equation, the sum is nonlinear.
We remark that membrane conductance and permeability are related concepts; however, they are not the same. The permeability depends on the state of the membrane, while conductance depends on both the state of the membrane and the concentration of the ions. The permeability to K+, for example, may be high if there are a large number of open K+ channels. However, if the concentration of K+ ions is low on both sides of the membrane, then the K+ conductance would be low.

i i

i i

20

Chapter 2. The Hodgkin-Huxley equations

I(t)

CM

gCl

gK gNa

ECl EK

ENa

Figure 2.3. Equivalent circuit for a membrane with three channels.

2.6 The membrane time constant
In this section, we consider how a passive, isopotential cell responds to an applied current. This will help explain how each component of the electrical circuit contributes to changes in the membrane potential. The cell is said to be passive if its electrical properties do not change during signaling. Such a cell cannot generate an action potential; however, it is important to understand how a cell’s passive, or constant, properties inﬂuence changes in the membrane potential before considering active signaling. Moreover, many dendrites do not have gated channels so their behavior is inﬂuenced primarily by their passive properties. The cell is said to be isopotential if the membrane potential is uniform at all points of the cell; that is, the membrane potential depends only on time. To simplify the analysis, we will consider a spherical cell with radius ρ.
Suppose that this cell is injected with an applied current, I(t), that is turned on at t = 0 to some constant value, I0, and turned oﬀ at t = T . Here, we assume that I0 > 0; however, this is really not necessary. Note that for an isopotential cell, the injected current distributes uniformly across the surface. It follows that for a spherical cell, the current ﬂowing across a unit area of the membrane is

 I0

IM (t)

=

I (t) 4πρ2

=

 

4πρ2
0

if 0 < t < T otherwise

(2.14)

As before, suppose that cM is the speciﬁc membrane capacitance, rM is the

speciﬁc membrane resistance and ER is the cell’s resting potential. To simplify things, we take ER = 0 so that VM measures deviation of the membrane potential

from rest. From 2.13, the membrane potential satisﬁes the ordinary diﬀerential

equation

cM

dVM dt

=

−

VM rM

+ IM (t).

(2.15)

i i

i i

2.7. The cable equation

21

If the cell starts at rest, then the solution of this linear equation satisﬁes

VM (t)

=

rM I0 4πρ2

1

−

e−

t τM

for 0 < t < T

(2.16)

where τM

≡

1 cM rM

is the membrane time constant and

VM

(t)

=

VM

(T

)e−

t τM

for t > T.

(2.17)

The solution is shown in Figure 2.4. Once the current is turned on, the membrane potential asymptotically approaches the steady state value rM I0/(4πρ2). The approach is exponential with the time constant τM . The membrane time constant also determines the rate at which the membrane potential decays back to rest after
the current is turned oﬀ. The steady state membrane potential satisﬁes

I0

rM 4πρ2

≡ I0RINP

(2.18)

where RINP is the input resistance of the cell. Note that if the input current changes by ∆I, then the steady state membrane potential changes by RINP × ∆I; that is, the input resistance is the slope of the I − V curve obtained by plotting the steady state voltage against the injected current.
The initial rise in membrane potential is determined primarily by the membrane capacitance. Initially the voltage across the resistor and capacitor are both equal to 0. From Ohm’s law, it follows that initially no current ﬂows through the resistor and all the current is due to the capacitor. Because of the capacitive current, the potential across the capacitor and hence the membrane potential, will become more positive. As VM increases, the membrane potential diﬀerence begins to drive current across the membrane resistance resulting in less current across the capacitor. Eventually, the membrane potential reaches a value where all the membrane current ﬂows through the resistor. This value is given by VM = I0RINP .
Figure 2.4 also shows responses in which there are purely resistive or purely capacitive elements. If there is no membrane capacitance, then VM satisﬁes

VM (t) = rM IM (t).

(2.19)

That is, VM jumps to the steady state potential, RINP I0, as soon as the injected current is turned on and it jumps back to rest as soon as the current is turned oﬀ. If there is only a capacitive element, then the membrane potential changes linearly as long as there is an applied current.

2.7 The cable equation
We have, so far, considered the passive properties of an isopotential cell. This analysis may be used to describe signaling within the cell body, which can be approximated by a sphere. However, it is clearly not appropriate for studying electrical properties of the axon or dendrites. These are better approximated by cylinders that are not isopotential. A subthreshold voltage signal that is initiated at one

i i

i i

22

VM
ImRM

purely resistive

Chapter 2. The Hodgkin-Huxley equations
purely capacitive
VM

IM
Im

IM Iion

Icap

time

Iion Icap

Figure 2.4. The change of membrane potential in response to a step of current. The membrane potential is shown with a solid line. The dashed lines show the time courses of the purely capacitive and resistive elements. The bottom panel shows the time course of the total membrane current, the ionic current and the capacitive current.
point along the axon or dendrite will decrease in amplitude with distance from the point of initiation. It is important to understand how the geometry of the cell affects the spread of the signal. The signal may, for example, correspond to synaptic input from another neuron. Understanding how geometry aﬀects the spread of the signal will help determine whether the synaptic input will cause the cell to ﬁre an action potential. Here we assume that the membrane is passive, so the analysis is more applicable to dendrites than to axons. However, as we shall describe later, the passive spread of current ﬂow helps determine the velocity of propagating action potentials in the axon.
We consider a cell that is shaped as a long cylinder, or cable, of radius a. We assume that the current ﬂow is along a single spatial dimension, x, the distance along the cable. In particular, membrane potential depends only on the x-variable, not on the radial or angular components. The cable equation is a partial diﬀerential equation that describes how the membrane potential VM (x, t) depends on currents entering, leaving and ﬂowing within the neuron. The equivalent circuit is shown in Figure 2.5 where Ilong is the current along the inside of the cable, IM is the current across the membrane, RL is the resistance of the cytoplasm, Re is the resistance of the extracellular space, RM is the membrane resistance and CM is the membrane capacitance. In what follows, we will assume that Re = 0, so that the extracellular

i i

i i

2.7. The cable equation

23

space is isopotential. This assumption is justiﬁed if the cable is in a bath with large cross-sectional area.

Re

RM CM

IM

a

Ilong

RL

x

Figure 2.5. Equivalent circuit for a uniform passive cable.

We ﬁrst consider the axial current ﬂowing along the neuron due to voltage
gradients. Note that the total resistance of the cytoplasm grows in proportion to the length of the cable and is inversely proportional to the cross-sectional area of the
cable. The speciﬁc intracellular resistivity, which we denote as rL, is the constant of proportionality. Hence, a cable of radius a and length ∆x has a total resistance of RL = rL∆x/(πa2) It follows from Ohm’s law that at any point x, the decrease in VM with distance is equal to the current times the resistance. That is,

VM (x

+

∆x,

t)

−

VM

(x,

t)

=

−Ilong (x,

t)RL

=

−Ilong (x,

t)

∆x πa2

rL.

(2.20)

There is a minus sign because of the convention that positive current is a ﬂow of positive charges from left to right. If voltage decreases with increasing x, then the current is positive. In the limit ∆x → 0,

Ilong (x,

t)

=

−

πa2 rL

∂VM ∂x

(x,

t).

(2.21)

Let iion be the current per unit area due to ions ﬂowing into and out of the cell. Then the total ionic current that ﬂows across a membrane of radius a and length ∆x is given by Iion = (2πa∆x)iion.
Recall that the rate of change of the membrane potential is determined by the capacitance. The total capacitance of a membrane is equal to the speciﬁc

i i

i i

24

Chapter 2. The Hodgkin-Huxley equations

membrance capacitance cM multiplied by the total surface area of the membrane. Hence, for a cable of radius a and length ∆x, the total capacitance is given by
CM = (2πa∆x)cM and the amount of current needed to change the membrane potential at a rate ∂VM /∂t is

Icap

=

(2πa∆x)cM

∂VM ∂t

.

(2.22)

From Kirchhoﬀ’s law, the change in intracellular axial current is equal to the amount of current that ﬂows across the membrane. Hence,

Icap(x, t) + Iion(x, t) = Ilong(x + ∆x, t) − Ilong(x, t)

(2.23)

from it which it follows that

(2πa∆x)cM

∂VM ∂t

+ (2πa∆x)iion

=

πa2 rL

∂VM ∂x

(x

+

∆x,

t)

−

πa2 rL

∂VM ∂x

(x,

t)

We divide both sides of this equation by 2πa∆x and let ∆x → 0 to obtain the cable equation:

cM

∂VM ∂t

=

a ∂2VM 2rL ∂x2

− iion

(2.24)

For a passive cable, in which the resting potential is assumed to be zero,

iion = VM (x, t)/rM

(2.25)

where rM is the speciﬁc membrane resistance. Then (2.24) becomes

cM

∂VM ∂t

=

a ∂2VM 2rL ∂x2

−

VM rM

.

We can rewrite this equation as

(2.26)

τM

∂VM ∂t

=

λ2

∂2VM ∂x2

− VM

(2.27)

where

λ=

arM 2rL

and

τM = cM rM

(2.28)

are the space or length constant and the membrane time constant, respectively. Note that the space constant depends on the geometry of the cable, that is the cable’s diameter; however, the time constant does not.
Later, we shall give a detailed analysis of solutions to the cable equation and properties of passive dendrites. For now, it is instructive to consider steady state solutions. Suppose, for example, we consider a semi-inﬁnite cable (deﬁned for x > 0) and we inject a step of current, I0, at x = 0. As t → ∞, the solution

i i

i i

2.8. The squid action potential

25

VM (x, t) approaches a steady-state solution Vss(x) that does not depend on time.

Setting

∂VM ∂t

=0

in

(2.27),

we

ﬁnd

that

Vss

satisﬁes

λ2

d2Vss dx2

− Vss

=

0.

(2.29)

In order to solve this equation, we need boundary conditions. Recall from (2.21)

that

IL

=

−

πa2 rL

∂VM ∂x

.

It follows that Vss must satisfy the boundary condition

dVss dx

(0)

=

−

rL πa2

I0.

(2.30)

The solution of (2.29), (2.30) is

Vss(x)

=

λrL πa2

I0 e−x/λ .

(2.31)

Note that the membrane potential decays exponentially. The distance at which the potential has decayed to 1/e is the space constant λ. Since the space constant is proportional to the square root of the cable’s radius, we conclude that thicker axons or dendrites have longer space constants than narrower processes. That is, thicker processes transmit signals for greater distances. As we discuss later, this is important because it inﬂuences the ability of the neuron to spatially summate incoming synaptic potentials. Moreover, the electrotonic, or passive, conduction plays an important role in the propagation of the action potential. Thicker cells with a longer space constant are more easily excited and are able to generate faster action potentials.
The input resistance is deﬁned to be the steady-state membrane potential, evaluated at x = 0, divided by the injected current. That is,

Rinp

=

Vss(0)/I0

=

rLλ

=

1 πa3/2

rM rL/2.

(2.32)

Note that the input resistance of the cable varies with the -3/2 power of the cable radius. Therefore, the input conductance is directly proportional to the 3/2 power of the cable radius. The input resistance is important because it is something that can be measured experimentally. Since it is also possible to measure the space constant λ, one can compute rM and rL from experimental data.

2.8 The squid action potential
We have so far viewed the membrane as a passive cable. However, linear cables cannot transmit information over long distances unless the cable has an enormous diameter. For example, the squid axon is more than 5 centimeters long, has a diameter of about a half a millimeter, a resting membrane resistance of rM =700

i i

i i

26

Chapter 2. The Hodgkin-Huxley equations

Ω cm2 and a transmembrane resistance of rL=30 Ω cm. Thus, the space constant for the squid axon is λ = 5.4 mm. This is an order of magnitude smaller than the length. If the potential at one end of the axon is held at 120 mV above rest, then the potential at the other end is about 10 µV above rest, a 10000-fold decrement. In order for neural signals to reach any distance, there must be another way to carry them so that they do not degrade.
Nature has solved this problem by inserting voltage-gated channels into the membranes of many cell types. These channels are proteins which selectively let diﬀerent ion species into the cell. Furthermore, the permeability of the channels depends on the local environment near the channel. In particular, for voltage gated channels, whether the channel is open or closed depends on the local potential near the channel. It is the opening and closing of voltage-gated channels that is responsible for the generation of the action potential that propagates along the axon.
Hodgkin and Huxley (1952) were the ﬁrst to provide a comprehensive, quantitative description of the regenerative currents generating the action potential. The choice of the squid axon was fortuitous since the electrical properties rely primarily on sodium and potassium ions. Consider the equivalent circuit shown in Figure 2.6 and assume that the cell is isopotential. Then the membrane potential satisﬁes

cM

dV dt

= −gNa(V

− ENa) − gK (V − EK ) − gL(V

− EL).

Here, we write V instead of VM . IL ≡ gL(V − EL) is called the leak current. It corresponds to passive ﬂow of ions through nongated channels. The leak conductance, gL, is constant. Since most nongated channels are permeable to K+ ions, EL is close to EK . The conductances gNa and gK may change with time since these correspond to the opening and closing of Na+ and K+ channels, respectively. At rest, gK is about 30-fold bigger than gNa so that the resting state is near EK at about -65 mV. Suppose that we could increase the conductance of gNa 100-fold. Then the resting potential would be much closer to the Nernst potential of sodium, which is about +55 mV. Thus the ampliﬁcation of the potential, such as during an action potential, involves changes in the relative conductances of the dominant ionic species. Hodgkin and Huxley’s insight was that voltage-gated channels provide the substrate for this dynamic regulation of the conductances.
The basic mechanisms underlying action potentials are the following. At rest, most of the sodium channels are closed so the membrane potential is determined primarily by the K+ Nernst potential. If the cell is depolarized above some threshold, then sodium channels open and this further depolarizes the cell. This allows even more sodium channels to open, allowing for more sodium ions to enter the cell and forcing the cell towards the sodium Nernst potential. This is the up-stroke of the action potential. The sodium channel is transient so that even when depolarized, the Na+ channels eventually shut down. In the meantime, the depolarization opens potassium channels and potassium ions exit the cell. This hyperpolarizes the cell as the membrane potential moves toward the potassium equilibrium potential. Until the voltage-gated potassium channels close up again, the membrane is refractory. During this time, pumps exchange excess sodium ions inside the cell with excess

i i

i i

2.8. The squid action potential

27

I(t)

CM

gL

gK gNa

EL

EK ENa

Figure 2.6. Equivalent circuit underlying the Hodgkin-Huxley equations.

V
ENa

Na+ channels close

Na+ channels open

K+ channels open

Vrest EK

time

Refractory period

Figure 2.7. The action potential. During the upstroke, sodium channels open and the membrane potential approaches the sodium Nernst potential. During the downstroke, sodium channels are closed, potassium channels are open and the membrane potential approaches the potassium Nernst potential.

potassium ions outside of the cell. Only a very small change in the percentage of the concentration of Na+ ions
is needed to generate an action potential. From the exercises, we ﬁnd that approximately 53 million Na+ ions must diﬀuse across the membrane to depolarize it from -60 to +50 mV. This inﬂux in Na+ ions represents only a .012% change in the internal Na+ concentration which is typically around 12 mM. Hence, changes in
local charge separation, not in concentration, are required for an action potential.

i i

i i

28

Chapter 2. The Hodgkin-Huxley equations

2.9 Voltage-gated channels

In the Hodgkin-Huxley model, each channel is viewed as a transmembrane protein

that forms a pore through which ions can diﬀuse down their concentration gradients.

The pores have gates that can be either open or closed; the probability that a gate

is open or closed depends on the membrane potential. The gate model can be

summarized by the diagram:

C

⇀ ↽βα((VV

) )

O

(2.33)

where C and O correspond to the closed and open states, respectively, and α(V )

and β(V ) are the voltage-dependent rate constants at which a gate goes from the

open to closed and closed to open states, respectively. If we let m be the fraction

of open gates, then 1 − m is the fraction of closed gates, and, from the law of mass

action,

dm dt

=

α(V

)(1 − m)

− β(V )m

=

(m∞(V

) − m)/τ (V )

(2.34)

where

m∞(V )

=

α(V ) α(V ) + β(V

)

and

τ (V

)

=

α(V

)

1 +

β(V

).

(2.35)

It is easy to solve this equation if V is constant. The solution starting at m(0) is

m(t) = m∞(V ) + (m(0) − m∞(V ))e−t/τ(V ).

Note that the solution approaches the steady-state m∞(V ) at a rate determined by the time-constant τ (V ).
One must obtain expressions for the voltage-dependent rate constants α and β. In the Hodgkin-Huxley model, these functions were derived by ﬁtting the data. Borg-Graham and others have suggested a simple formulation based on thermodynamics. The idea is that the probability of opening or closing a channel depends exponentially on the potential. Thus,

α(V ) = Aα exp(−BαV ) and β(V ) = Aβ exp(−BβV ).

(2.36)

From this, we ﬁnd that

m∞(V )

=

1 1 + exp(−(V

−

Vh)/Vs)

where Vh, Vs are constants. We leave as an exercise the calculation of these constants in terms of the constants A and B. The time constant, τ (V ) will generally be a skewed bell-shaped function of V. If Bβ = −Bα, then τ (V ) is a hyperbolic secant.

2.10 Hodgkin-Huxley model
We are now ready to derive the Hodgkin-Huxley model for the propagation of an action potential along the squid’s giant axon. As in Section 2.7, we view the axon as a cylinder of ﬁxed radius, a, so the membrane potential depends on the spatial

i i

i i

2.10. Hodgkin-Huxley model

29

variable x and time t. Here we assume that there are voltage-gated K+ and Na+ channels and a leak current. Then balancing currents, as in (2.23), we have

IL = Icap + Iion

(2.37)

or, using (2.6) and (2.24),

a ∂2VM 2rL ∂x2

=

cM

∂VM ∂t

+ IK

+ INa + IL.

(2.38)

If each ionic current is Ohmic, then this can be written as

cM

∂VM ∂t

=

a ∂2VM 2rL ∂x2

− gK (VM

− EK ) − gNa(VM

− ENa) − gL(VM

− EL).

(2.39)

To complete the model, we need to describe how one computes the membrane

conductances gK , gNa and gL. Note that the voltage-gated conductances gK and gNa change with time during an action potential.

Hodgkin and Huxley used two experimental methods in order to separate

the ionic currents and compute how the K+ and Na+ conductances depend on

voltage. The ﬁrst was a simple feedback circuit called the voltage-clamp that allows

the experimenter to hold the membrane potential at a constant or holding level

VC . The voltage clamp does so by injecting a current into the axon that is equal

and opposite to the current ﬂowing through the voltage-gated channels. Electrical

details can be found in Johnston and Wu. Note that the voltage-clamp separates the

total membrane current into its ionic and capacitive components. Recall that the

capacitive current satisﬁes Icap = CM dVM /dt. If the membrane potential is ﬁxed at some constant, then the capacitive current must be zero. Moreover, the total

current can be made spatially uniform by inserting a highly conductive axial wire

inside

the

ﬁber;

the

axon

is

then

said

to

be

space-clamped.

In

this

case,

∂ 2 VM ∂x2

= 0.

It then follows that any changes in current must be due either to the leak or to the

opening and closing of voltage-gated membrane channels.

We ﬁrst consider how the voltage-clamp can be used to determine the leak-

conductance, gL. Note that most of the voltage-gated channels are closed at rest. Moreover, if we hyperpolarize the cell, then we may assume that all of the voltage-

gated channels are closed. It follows that if the membrane potential is clamped at

some suﬃciently strong hyperpolarized level, then the total current is given by the

leak; that is,

IM ≈ gL(VC − EL).

From this equation, we can easily solve for gL. Figure 2.8 shows the results of a voltage-clamp experiment when the mem-
brane potential is clamped at 0 mV. Note that there is an inward current followed
by an outward current. This result suggests that the depolarizing voltage step turns on two voltage-gated channels. The inward current is due to the inﬂux of Na+ ions, while the outward current is due to the outward ﬂow of K+ ions. It is not clear,
however, how these two separate ions contribute to the total membrane current.
For this it is necessary to isolate the two voltage-gated currents.

i i

i i

30

Chapter 2. The Hodgkin-Huxley equations

IK

IM

I
Na

V = 0 mV
C

0

1

2

3

4

5

6

time (msec)

Figure 2.8. Numerically computed voltage-clamp experiment. The membrane potential is stepped from rest to 0 mV. This results in an inward current followed by an outward current. The separate potassium and sodium currents are also shown.

Hodgkin and Huxley were able to isolate the K+ current by replacing Na+ ions
in the external bathing solution with a larger, impermeant cation. This eliminated the inward Na+ current. Now there are dozens of compounds that selectively block
diﬀerent currents, many derived from natural toxins. (For example, the compound
tetrodotoxin, which blocks sodium channels, comes from the Paciﬁc puﬀerﬁsh, a tasty, if slightly dangerous, Japanese delicacy called fugu.) Once Na+ is removed,
the voltage-clamp can be used to determine how IK depends on the membrane potential. That is, one holds the membrane potential at various levels and determines the time-course of the total membrane current IM . If Na+ is removed, then the potassium current is computed by subtracting the leak current from IM .
It is also now possible to block K+ channels using the drug tetraethylammo-
nium. However, this was not available to Hodgkin and Huxley. However, if IK and IL are known, then one computes INa simply by subtracting IK and IL from IM . Once these currents are determined, we can calculate the IK and INa conductances using Ohm’s law. That is,

gK (t)

=

IK (t) (VM − EK )

and

gN a(t)

=

IN a (t) (VM − EN

a

)

.

(2.40)

Figure 2.9 shows the IK and INa conductances for diﬀerent levels of the holding potential. Note than gNa turns on more rapidly that gK . Moreover, the Na+ channels begin to close before the depolarization is turned oﬀ, while the K+ channels remain open as long as the membrane is depolarized. This suggests that the Na+
channel can exist in three states: resting, activated and inactivated. When the cell is depolarized, the Na+ channels switch from the resting (closed) to the activated
(open) state. If the depolarization is maintained, then the channel switches to the
inactivated (closed) state.

i i

i i

2.10. Hodgkin-Huxley model

31

V (mV)
C

40 20
0 −20 −40 −60

30
g
K 20
10
0
40
g
Na 20

0

0

1

2

3

4

5

6

7

time (msec)

Figure 2.9. Numerically computed voltage-clamp experiment. The membrane potential is stepped to diﬀerent values and the resulting potassium and sodium conductances are computed.

A physical interpretation of the Na+ channel is shown in Figure 2.10. There are two gates in the sodium channel: a fast one (the activation gate) represented by the line and a slow one (the inactivation gate) represented by the ball. Both gates must be open for the channel to conduct Na+ ions. At rest, the activation gate is closed and the inactivation gate is open. When the membrane is depolarized, the activation gate opens which allows sodium into the cell. The inactivation gate (ball) closes at the higher potential so that the ﬂow of sodium is transient. Hodgkin and Huxley used a more complicated voltage clamp protocol, ﬁrst stepping to a ﬁxed voltage and then apply brief voltage steps to probe the fast activation and slow inactivation gates. Details can be found in Kandel/Schwartz/Jessell.
Using the voltage-clamp data, Hodgkin and Huxley derived expressions for the K+ and Na+ conductances. They proposed that

gK = g¯K n4 and gNa = g¯Nam3h

(2.41)

where g¯K and g¯Na are maximum conductances and n, m and h are gating variables that take values between 0 and 1. Hence, n4 represents the probability that a potassium channel is open: the potassium channel has 4 independent components each of which are identical. The probability that the sodium activation gate is open is m3 and the probability that the sodium inactivation gate is open is 1 − h. Each of the gating variables satisﬁes a ﬁrst order diﬀerential equation of the form (2.34). That is, they satisfy equations of the form:

dn dt

=

αn(V

)(1

−

n)

−

βn(V

)n

=

(n∞(V ) − n)/τn(V )

dm dt

=

αm(V

)(1

−

m)

−

βm(V

)m

=

(m∞(V ) − m)/τm(V )

dh dt

=

αh(V

)(1

−

h)

−

βh(V

)h

=

(h∞(V ) − h)/τh(V ).

i i

i i

32
V(t) I Na
V rest

Chapter 2. The Hodgkin-Huxley equations

A

D

B
V

h = h0

C
V 0

I peak

h

(V)

Figure 2.10. The Hodgkin-Huxley sodium channel. (A-C) Voltage clamp dynamics. (D) Physical model of the channel. If the voltage step is small (A), then the Na-channel’s activation gate (line) is closed but the inactivation gate (ball) is open. At intermediate steps (B), both gates are partially open. For large steps (C), the activation gate is open and the inactivation gate is closed.

If X = n, m or h, then

X∞(V

)

=

αX (V ) αX (V ) + βX (V

)

and

τX (V )

=

αX (V

1 ) + βX (V

).

(2.42)

To match the data, Hodgkin and Huxley chose the following parameters and gating functions: g¯Na = 120 mS/cm3, g¯K = 36 mS/cm3, g¯L = 0.3 mS/cm3, ENa = 50
mV, EK = -77 mV, EL = -54.4 mV,

αn(V ) = 0.01(V + 55)/(1 − exp(−(V + 55)/10)) βn(V ) = 0.125 exp(−(V + 65)/80) αm(V ) = 0.1(V + 40)/(1 − exp(−(V + 40)/10)) βm(V ) = 4 exp(−(V + 65)/18) αh(V ) = 0.07 exp(−(V + 65)/20) βh(V ) = 1/(1 + exp(−(V + 35)/10)).

In Figure 2.11, we plot the activation curves n∞(V ), m∞(V ) and h∞(V ) along with τn(V ), τm(V ) and τh(V ). Note that n∞ and m∞ are increasing functions that approach 0 for hyperpolarizing currents and approach 1 for depolarizing currents. Hence, n and m become activated when the membrane is depolarized. On the other
hand, h∞(V ) is a decreasing function so the sodium channels inactivate when the membrane is depolarized. It is also important to note that τm(V ) is considerably

i i

i i

2.11. The action potential revisited

33

steady state
τ (msec)

1

0.9

h

0.8

0.7

0.6
m
0.5

0.4

0.3

0.2

n

0.1

0

-100 -80 -60 -40 -20

0

20

40

V (mV)

9

8

h

7

6

n

5

4

3

2

1

m

0

-100 -80 -60 -40 -20

0

20

40

V (mV)

Figure 2.11. HH functions. Left shows the steady state opening of the gates and right shows the time constants.

1

0.8
m
n
0.6

0.4

h

n4

0.2
m3h

0

VC = 0 mV

0

1

2

3

4

5

6

time (msec)

Figure 2.12. Response of the activation and inactivation variables m, h, and n to a step in voltage.

smaller than τn or τh. Hence, sodium channels activate much faster than they inactivate or potassium channels open. In Figure 2.12, we show the response of m, h, and n to a step in voltage.

2.11 The action potential revisited
In summary, the Hodgkin-Huxley model is a system of four diﬀerential equations; there is one equation for the membrane potential and three equations for channel gating variables. In the case of a spaced-clamped squid axon, we write these

i i

i i

34

Chapter 2. The Hodgkin-Huxley equations

equations as:

cM

dV dt

= −g¯Nam3h(V

− ENa) − g¯Kn4(V − EK ) − g¯L(V − EL)

dn dt

=

φ[αn(V

)(1

− n) − βn(V )n]

dm dt

=

φ[αm(V )(1

−

m) − βm(V )m]

dh dt

=

φ[αh(V )(1

− h) − βh(V )h]

(2.43)

Here we added a parameter φ; this is the temperature factor. It is important to realize that the temperature at which an experiment is done can be very important. Since channels are stochastic in nature, they are sensitive to the temperature so that the rates of switching states depend exponentially on the temperature. Higher temperatures cause faster switching. Thus, there is a factor:

φ = Q(1T0 −Tbase)/10.

(2.44)

Q10 is the ratio of the rates for an increase in temperature by 10◦ C. For the squid, Tbase = 6.3◦ C and Q10 = 3.
Figure 2.13 shows solutions of these equations in response to diﬀerent levels of steps in currents. Note that there is “all-or-none” behavior: When the applied current is below some threshold, the membrane potential returns quickly to rest; when the current is above some threshold, there is an action potential. If the applied current is suﬃciently large and held for a suﬃciently long time, then the model generates a periodic response.

40
V (mV)
20
0
−20
−40
−60

0

10

20

30

40

time (msec)

40
V (mV)
20
0
−20
−40
−60
−80 0

50

100

150

time (msec)

Figure 2.13. Responses of the HH model to applied currents. Left: transient responses showing “all-or-none” behavior; Right: Sustained periodic response.
Figure 2.14 shows of an action potential along with plots of the Na+ and K+ conductances, gNa and gK . Here, we start with the cell at rest and then depolarize the cell by 10 mV at t = 0. The cell then generates a single action potential. In Section 2.8, we described the events underlying the action potential in terms of

i i

i i

2.11. The action potential revisited

35

20
VM
−20
−60

gNa gK

0

2

4

6

8

10

time (msec)

Figure 2.14. Solution of the Hodgkin-Huxley equations showing an action potential. Also shown are the sodium and potassium conductances.

the inward and outward ﬂow of sodium and potassium ions. Here we give a more
“mathematical” explanation in terms of the behavior of the dependent variables in
the diﬀerential equations.
When we depolarize the cell, we change the values of the activation curves:
n∞(V ) and m∞(V ) increase, while h∞(V ) decreases. Since n, m and h tend towards their activation curves, it follows that n and m initially increase, while h
decreases. That is, potassium channels open, while sodium channels both activate
and inactivate. However, τm is much smaller than both τh and τn. It follows that the Na+ channels activate much faster than they inactivate or K+ channels open. Therefore, the Na+ conductance, gNa = g¯Nam3h, increases faster than gK = g¯n4.
The increase in the Na+ conductance leads to a large increase in the Na+
current, INa = gNa(V − ENa). As long as the cell is near rest, the driving force V − ENa is large (recall that ENa ≈ +55mV ). Hence, the sodium current will dominate the equation for the membrane potential and V will increase towards the Na+ Nernst potential. As V increases, m∞(V ) increases further, leading to further increase in Na+ activation.
As V increases towards ENa, sodium channels inactivate. This is because h → h∞(V ) ≈ 0. Moreover, the sodium driving force V − ENa decreases. For both reasons, the Na+ current turns oﬀ. Meanwhile, the potassium channel activates because n → n∞(V ) ≈ 1. Moreover, the K+ driving force V − EK becomes very large. It follows that eventually, the potassium current dominates and the membrane potential must fall back towards the K+ Nernst potential. This corresponds
to the down-stroke of the action potential.
After the action potential, the cell is hyperpolarized with m∞ ≈ 0, n∞ ≈ 0 and h∞ ≈ 1. After some time, m, n and h approach their steady state values and

i i

i i

36

Chapter 2. The Hodgkin-Huxley equations

V
ENa

Na+ enters cell

V increases
Na+ channels activate: m

Na+ channels inactivate: h
K+ channels activate: n

Vrest EK

time

Na+ deactivates: m Na+ deinactivates: h K+ deactivates: n

Figure 2.15. Mechanisms underlying the action potential.
the cell returns to rest.
2.12 Bibliography
There are many standard neuroscience textbooks that present the biological aspects covered in this chapter in much more detail. These textbooks include Kandel, Schwartz and Jessell [28], Hille [22] and Martin [36]. The reader is also highly recommended to look at Hodgkin and Huxley’s original papers [1]. A review of these papers, along with a short history leading up to them, is given in Rinzel [42]. Excellent textbooks, which emphasize modeling and quantitative approaches, are Johnston and Wu [?], Koch [30], Jack et. al.[25], Izhikevich izhikevichbook, and Dayan and Abbott [10]. Keener and Sneyd [29] and Fall et. al. [14] give detailed introductions to mathematical aspects of cellular biophysics.
2.13 Exercises
1. Consider a passive, spherical cell with radius .003cm2, a resting membrane potential of −65mV , a membrane capacitance of 1µF/cm2 and a membrane resistance of Rm = 700Ωcm2. Suppose that the cell is injected with an applied current of 5nA/µm2 for two seconds and then turned oﬀ. What is the membrane potential at t = 1, t = 2 and t = 3?
2. Suppose that a passive axon has a diameter of half a millimeter, a resting membrane resistance of Rm = 700Ωcm2, and a transmembrane resistance of Ri = 30Ωcm. Compute the space constant. If the axon is 5 centimeters long and one end of the axon is held at 120 mV above rest, then what is the

i i

i i

2.13. Exercises

37

potential at the other end?
3. (Johnston and Wu, page 12) The membrane capacitance of a typical cell is 1 µF/cm2 and the concentration of ions inside and outside of the cell is about .5 M. Calculate the fraction of uncompensated ions on each side of the membrane required to produce 100 mV in a spherical cell with a radius of 25 µm.
4. Numerically solve the Hodgkin-Huxley equations. Start the system at rest and, at some later time, inject an applied current to generate an action potential. Plot the time courses of the sodium and potassium conductances.
5. Numerically perform space-clamp experiments. That is, start the HodgkinHuxley model at rest and, at some later time, change the membrane potential and keep it as some “clamped” level. Plot the sodium and potassium conductances for when the membrane potential is stepped to diﬀerent values.

i i

i i

38

Chapter 2. The Hodgkin-Huxley equations

i i

i i

Chapter 3

i i

Dendrites
In this chapter, we will derive mathematical theories for describing dendrites. Dendrites are very important for many reasons. Indeed, the majority of the total membrane area of many neurons is occupied by the dendritic tree. Dendrites enable neurons to connect to thousands of other cells, far more than would be possible with just a soma, as there is a huge membrane area to make connections. Dendrites may direct many subthreshold postsynaptic potentials (PSPs) towards the soma, which summates these inputs and determines if the neuron will ﬁre an action potential. In addition to the tree-like structure of dendrites, many dendrites have additional ﬁne structures at the ends of the branches called spines. During development, animals that are raised in rich sensory environments have more extensive dendritic tress and more spines.
3.1 Multiple compartments
A very useful way to treat complicated dendritic structures is the compartimental approach. Here one divides the dendritic tree into small segments or compartments that are all linked together. Examples are shown in Figure ??. Each compartment is assumed to be isopotential and spatially uniform in its properties. Diﬀerences in voltage and nonuniformity in membrane properties, including diameter, occur between compartments rather than within them.
As a simple example, consider the two-compartment model shown in Figure ??. An equivalent circuit for this model is shown in Figure ??. Each compartment is viewed as an isopotential cylinder with radius ai and length Li. Let Vi be the membrane potential of the ith compartment and let ci and rMi be the corresponding speciﬁc membrane capacitance and speciﬁc membrane resistivity, respectively. We assume that each compartment has an electrode current and the total electrode current is given by Ieilectrode. Finally, we assume that the intracellular, or longitudinal, resistivity is given by rL.
Now the capacitive and ionic currents for each compartment must be balanced
39

i i

40

Chapter 3. Dendrites

by the longitudinal and electrode currents. That is,

iicap + iiion = iilong + iielectrode

(3.1)

where iicap and iiion are the capacitve and ionic currents per unit area of membrane for compartment i. As before,

iicap

=

ci

dVi dt

and

iiion

=

Vi rM i

(3.2)

if we assume that the resting potential is 0. In order to compute iilong, we need to determine total axial resistance. Note that the total resistance between the centers

of the two comparments is simply the sum of the two resistances of the half-cylinders

that separate the compartment centers. That is the total resistance is given by:

Rlong

=

rLL1 2πa21

+

rLL2 2πa22

(3.3)

Using Ohm’s law, we can write the expressions for the current from comparments i

to compartment j as

i1long = g1,2(V2 − V1) and i2long = g2,1(V1 − V2).

(3.4)

The coupling terms g1,2 and g2,1 are obtained by inverting (3.3) and dividing by the surface area of the compartment of interest. That is,

g1,2

=

a1a22 rLL1(a22L1 + a21L2

and

g2,1

=

rLL1

a2a21 (a22L1 +

a21L2

.

Finally, to compute iielectrode, we divide the total electrode currents by the surface areas of the compartments. That is,

iielectrode

=

Ieilectrode Ai

where Ai = 2πaiLi is the surface area of compartment i. Putting this all together, we ﬁnd that the equations for two connected cylinders

are:

c1

dV1 dt

+

V1 rm1

= g1,2(V2 − V1) +

Ie1lectrode A1

c2

dV2 dt

+

V2 rm2

= g2,1(V1 − V2) +

Ie2lectrode A2

(3.5)

If instead of using conductances, gi,j, we use r1 = 1/g1,2 and r2 = 1/g2,1 then we can express this system as:

c1

dV1 dt

+

V1 rm1

=

V2 − V1 r1

+ i1

c2

dV2 dt

+

V2 rm2

=

V1 − V2 r2

+ i2

(3.6)

i i

i i

3.1. Multiple compartments

41

where ii = Ieilectrode/Ai. We can now explore the eﬀects of two compartments on the input resistance of
the “cell.” Suppose that we inject current into cell 1 only. Moreover, each cylinder is identical with the same length and radius. Then r1 = r2 ≡ r. What is the input resistance due to the coupling? To solve this, we must compute the steady state potential due to the coupling. Without loss in generality, deﬁne rM = rM1 = rM2. A simple bit of algebra shows that

V1/i1

=

rM (r + rM ) r + 2rM

and thus the ratio of the coupled to the uncoupled input resistance is:

Rinput,coupled Rinput,uncoupled

=1−

r

rM + 2rm

;

that is, the input resistance decreases. To get the same increment in potential the current required for the coupled system is more than the uncoupled system because some current is drained away by the second compartment.
In a similar way, we can derive a compartmental model for a general tree-like structure. A general algorithm for computing the correct equations is:

• For each cylinder, j, with radius and length aj and Lj in microns, compute

surface

area,

Aj

=

2πaj Lj

and

the

axial

resistance

factor:

Qj

=

. Lj
πa2j

• The membrane capacitance is Cj = cjAj × 10−8 and the membrane resistance is Rj = (rmj/Aj ) × 108.

•

The coupling resistance between compartment j and k is Rjk

=

rL 2

(Qj

+

Qk

)

×

104.

• The equations are then

Cj

dVj dt

=

−

Vj Rj

+
k

connected j

Vk − Vj Rjk

+ Ij .

The factors of 10±8 and 104 are the conversion from microns to centimeters. For
example, consider a two compartment model with (i) compartment 1 having a
length of 200µ and radius of 30µ and (ii) compartment 2 having a length of 20µ and radius of 20µ. Then, R1 = 2.65 × 107Ω, C1 = 3.77 × 10−10F ,R2 = 3.98 × 108Ω, C2 = 2.52 × 10−11F , and Rlong = 4.34 × 104Ω, thus

10

dV1 dt

=

−V1

+ 611(V2

− V1),

10

dV2 dt

=

−V2

+ 9181(V2

−

V1)

where the time is in milliseconds and the coupling coeﬃcients are dimensionless. Note how the ratio of the coupling strengths is the same as the reciprocal of the area ratios. The bigger compartment has a much greater eﬀect on the smaller compartment than vice versa.

i i

i i

42
A

Chapter 3. Dendrites

B 3
2
1
Figure 3.1. A. Branched dendrite converted to a series of cylinders for modeling. B. Simple 3 compartment model.
We also would like to remark that the standard units used in most compartmental models are µF/cm2, mS/cm2, and µA/cm2 for the capacitance, conductance, and applied current. Experimentalists don’t generally know the current density but only the total current injected. Typical currents injected into a cell are of the order of less than a nanoampere.
To generate arbitrary compartmental models, one needs only to compute the length, diameter, and the connectivity of the cylinders that make up the dendritic tree. The software NEURON enables an experimentalist to input a digitized picture of a neuron and the program will automatically produce a compartmental model of the neuron by linking together many cylinders.
3.1.1 Homework
1. Derive the diﬀerential equations for the three compartment model shown in ﬁgure 3.1 B, where you can take Rm,s = 10000Ω − cm2, Cm,s = 1µF/cm2, and Rlong,s = 100Ω − cm. The compartments have dimensions, (ℓj, ρj) = (50, 25), (100, 15), (80, 10) respectively. Compute the input resistance for a current applied to compartments 1 and 3 (the “soma” and the “distal dendrite.”)

i i

i i

3.1. Multiple compartments

43

2. Consider 3 identical compartments coupled in a chain by the same coupling resistance:

C

dV1 dt

=

−

V1 R

+ (V2

− V1)/Rcouple

+I

C

dV2 dt

=

−

V2 R

+ (V3

− 2V2 + V1)/Rcouple

C

dV3 dt

=

−

V3 R

+ (V2

− V3)/Rcouple.

Compute the input resistance. What do you think happens with more and more compartments?

3. Consider an semi-inﬁnite array of compartments with only the ﬁrst one receiving injected current. Can you prove that

V1/I1

=

1+

R

R Rcouple

(1

−

µ)

where

µ=1+z−

z2 + 2z,

z

=

R 2Rcouple

.

(Here is a hint. Show that the steady state voltages satisfy:

Vj+1 − 2(1 + z)Vj + Vj−1 = 0

except for j = 1. The general solution to this diﬀerence equation is just Vj = Aµj1 + Bµj2 where µ1,2 are roots to µ2 − 2(1 + z)µ + 1 = 0. One of these roots, say, µ2, is greater than 1 so that as j → ∞ you better choose B = 0.
Choose A so that the correct equation for V1 holds:

0

=

−

V1 R

+

V2 − V1 Rcouple

+ I.

)

4. Consider a general N -compartment model for a passive neuron with current injected into some or all of the compartments. This will obey the following diﬀerential equations:

Cj

dVj dt

= Ij +

gjk(Vk − Vj ) − gL,j(Vj − Vleak)

k

Suppose that gjk ≥ 0, Cj > 0, gL,j > 0. Prove that there is a unique equilibrium point to this and that it is asymptotically stable. (Hint: This is a diagonally dominant system.)

i i

i i

44

Chapter 3. Dendrites

5. Consider the inﬁnite linear array of cells:

τ

dV1 dt

= V0

− V1

+ β(V2

− V1)

τ

dVj dt

= −Vj

+ β(Vj+1 − 2Vj

+ Vj−1)

Find the steady state solution to this. (Hint: The second group of equations has the form Vj+1 = Vj(2 + 1/β) − Vj−1 which is a ﬁnite diﬀerence equation. The general solution to such equations is Vj = C1r1j + C2r2j. )

6. Consider a single compartment model with a sinusoidal current:

C

dV dt

= −gL(V

− Vleak) + I0 sin ωt.

Find the steady state solution to this equation.

7. Consider the single compartment model:

C

dV dt

= I − gL(V

− Vleak) − g(t)(V

− Vsyn)

where g(t) = 0 except when t ∈ [t1, t2] where it is g¯. Solve this equation assuming the cell starts from rest. For what values of Vsyn does V (t) increase above rest?

3.2 The cable equation.

Mathematically, dendrites and axons are regarded as continuous media rather than a series of compartments. Previously, we derived the cable equation for a simple cable in which the radius along the cable was assumed to be constant. Here we derive the cable equation for more general geometries. This is done by considering the limit as the number of compartments in an approximation of it tends to inﬁnity.
Suppose the cable is deﬁned on the interval (0, ℓ) with a circular cross-section and diameter d(x). We break the cable into n pieces and deﬁne xj = jh where h = ℓ/n. Each piece has a surface area Aj = πdjh where dj = d(xj ), and crossectional area, πd2j /4. Let cM and rM denote the speciﬁc membrane capacitance and resistance, and let rL be the longitudinal resistance. Then, neglecting the end points, the voltage satisﬁes:

cM

Aj

dVj dt

=

−

Vj rM /Aj

+

Vj+1 − Vj 4rLh/(πd2j+1)

+

Vj−1 − Vj 4rLh/(πd2j )

Note that we use the larger diameter for the transmembrane resistance; in simula-

tions, the average of the two would be preferred. Dividing by πh the coupling term

simpliﬁes to:

1 h

d2j+1(Vj+1 − 4rLh

Vj )

−

d2j (Vj − Vj−1) 4rLh

.

i i

i i

3.3. Linear cables with constant diameter.

45

As h → 0, this goes to the diﬀusion operator:

1∂ 4rL ∂x

d2

(x)

∂V ∂x

.

Thus, the cable equation has the form:

cm

∂V ∂t

=

−

V rM

+

1 4rL

∂ ∂x

d2(x)

∂V ∂x

.

(3.7)

We remark that the term

d2j (Vj−1 − Vj ) 4rLh

has dimensions of current and in the limit as h → 0 is called the longitudinal current:

IL

=

−

πd2(x) 4rL

∂V ∂x

.

(3.8)

If one is interested only in the passive cable and d(x) = d is constant, then

it is convenient to multiply both sides by rM and divide by d obtaining the linear

cable equation:

τ

∂V ∂t

=

−V

+

λ2

∂2V ∂x2

(3.9)

where

λ=

drM 4rL

(3.10)

is the space constant. Since λ depends on the diameter of the cable, this parameter

depends on the geometry of the cable. The quantity, τ = rM cM is the time constant and is independent of geometry. For example, if cM = 1µF/cm2, rM = 20000Ωcm2, rL = 100Ωcm and the diameter of the cable is 2 microns, then τ = 20 msec and λ = 1 mm.

3.3 Linear cables with constant diameter.

3.3.1 The inﬁnite cable

We ﬁrst consider the inﬁnite cable, so that −∞ < x < ∞, with some applied

current:

τ

∂V ∂t

+

V

(x,

t)

−

λ2

∂2V ∂x2

= rM I(x, t).

(3.11)

The current, I(x, t) has units of µA/cm2. Additionally, we also must provide an

initial voltage distribution, V (x, 0) = V0(x). We will solve this using Fourier transforms and then write the solution in terms of something called a Green’s function. Let

∞

Vˆ (k, t) =

e−ikxV (x, t) dx

−∞

i i

i i

46

Chapter 3. Dendrites

Vˆ0(k) = Iˆ(k, t) =

∞
e−ikxV0(x) dx
−∞ ∞
e−ikxI(x, t) dx
−∞

denote the Fourier transforms of V, V0, and I. Then Vˆ satisﬁes the diﬀerential equation

dVˆ dt

+ (1 + λ2k2)Vˆ /τ

= rM Iˆ/τ

Vˆ (0) = Vˆ0

where we have dropped the k dependence for simplicity. This is a linear ﬁrst order ODE so we can write the solution:

t
Vˆ (k, t) = e−(1+λ2k2)t/τ Vˆ0(k) + (rM /τ ) e−(1+λ2k2)(t−s)Iˆ(k, s) ds.
0

Recalling that the inverse Fourier transform is

V

(x,

t)

=

1 2π

∞
eikxVˆ (k, t) dk
−∞

we ﬁnd that V (x, t) is given by

V (x, t) =

∞ −∞

G(x

−

y,

t)V0(y)

dy

+

rM τ

t 0

∞
G(x − y, t − s)I(y, s) dy ds
−∞

where

G(x, t) =

1

e−t/τ e−x2/(λ2t/τ ).

4πλ2t/τ

(3.12)

Note that G(x, t) has dimensions of λ−1. Suppose that V0(x) = 0 (that is, the membrane is at rest) and at t = 0, the
membrane is perturbed by a delta function in space and time. That is, I(x, t) = I0δ(x)δ(t). Then

V (x, t) = rM I0 exp τ λ 4πt/τ

−

τ x2 4λ2t

exp

−

t τ

.

(3.13)

In the exercises below, you are asked to analyze this. One interesting point is that
at each spatial location x, the function V (x, t) reaches its maximum at a value t∗(x). You can obtain this expression using calculus and show that for x large, t∗(x) ≈ τ x/2λ, that is, the voltage is a rapidly decaying “wave”.

For another example, consider an inﬁnite cable with a step of constant applied

current at a single point: I(x, t) = I0δ(x). Plugging this into (3.12), we ﬁnd that

√

√

V

(x, t)

=

rM I0λ 4

e−(x/λ)erfc

x √τ − 2λ t

t/τ

− e(x/λ)erfc x √τ + 2λ t

t/τ

i i

i i

3.4. Finite and semi-inﬁnite cables.

47

where

erfc(x) = √2π

∞
e−y2 dy.
x

(3.14)

Note that erfc(0) = 1, erfc(∞) = 0 and erfc(−∞) = 2. If we let t → ∞ in (3.14) then V (x, t) approaches the steady state solution

Vss (x)

=

rM I0 e−|x|/λ. 2λ

Often a cable is described in terms of its electrotonic length which is L = ℓ/λ, where ℓ is the physical length and λ is the space constant.

3.4 Finite and semi-inﬁnite cables.
For the inﬁnite cable, the only physically reasonable boundary condition is that V (x) → 0 as |x| → ∞. However, for the ﬁnite and semi-inﬁnite cables there are several interesting boundary conditions that are often used:

• sealed end where no current can pass and so the longitudinal current IL = 0.

It

then

follows

from

(3.8)

that

∂V ∂x

(0)

=

0.

• current injected at one end where a current of magnitude I(t) is injected at,

say,

the

end

x=

0.

In

this

case,

∂V ∂x

(0)

=

4rL πd2

I

(t).

• voltage clamp in which the voltage is clamped to some ﬁxed level, so that V (0) = Vc, a constant.

• short circuit or open end where the voltage is clamped to 0.

• lumped soma where we regard the soma as a single compartment attached to the nerve cable. Suppose that the soma has total resistance Rs and capacitance Cs. Then the boundary condition at x = 0 is

V

(0, Rs

t)

+

CsVt(0,

t)

−

πd2 4rL

Vx(0,

t)

=

0

Note that the general steady-state equation, 0 = −V + λ2Vxx has solutions of the equivalent forms:
V (x) = A1e−x/λ + A2ex/λ V (x) = B1 cosh((l − x)/λ) + B2 sinh((l − x)/λ) V (x) = C1 cosh(x/λ) + C2 sinh(x/λ)
The constants are determined from the boundary conditions. First consider the semi-inﬁnite cable. This has a solution of the form V (x) = A exp(−x/λ). Suppose

i i

i i

48

Chapter 3. Dendrites

that we inject current, I0 into the end of the cable. Recall that the longitudinal current is I0 = −(πd2/4rL)dV /dx. Thus, we ﬁnd that

A

=

4λI0rL πd2

.

Recall that the input resistance, Rinp of a cable as the ratio of the steady state potential divided by the current injected. Thus, for the semi-inﬁnite cable,

Rinp

=

V (0)/I(0)

=

4λrL πd2

=

2√rM rL πd3/2

and the input conductance is given by

Ginp

=

1/Rinp

=

πd3/2 2√rM rL

.

For ﬁnite cables, it is convenient to use dimensionless space, X = x/λ and the electrotonic length, L = ℓ/λ. Assume that the voltage at X = 0 is V0. Then the general solution to the steady-state equation is:

V

(X )

=

V0

cosh(L − X) cosh L

+ +

BL BL

sinh(L sinh L

−

X)

where BL is an arbitrary constant. This general solution is equivalent to asserting that the boundary condition at X = 0 is V0 and that at X = L

BLV

(L)

+

dV dX

(L)

=

0.

The free parameter, BL, is the ratio of the terminal conductance for the cable, GL,

to that of the semi-inﬁnite cable, Ginp. That is, BL = GL/Ginp.

For example, if we want the sealed end condition at X = L we take BL = 0

so that

V

(X

)

=

V0

cosh(L − cosh L

X

)

.

If we want the open end conditions, we take BL = ∞ so that

V

(X

)

=

V0

sinh(L − X sinh L

)

.

If we choose BL = 1 then

V (X) = V0e−X

which is precisely the solution to the semi-inﬁnite cable. From these equations for the membrane potential, we can compute the input
resistance and input conductance of a ﬁnite-length cable. For example, consider the sealed end condition at X = L. Suppose that a current, I0, is injected into the other end at X = 0. Then the input resistance is given by

Rinp = V (0)/I0 = V0/I0.

i i

i i

3.5. Branching and equivalent cylinders.

49

d1 d0
d2

Figure 3.2. A simple dendritic tree.

Now, It follows that Hence,

I0

=

−

1 λrM

∂Vm∂X

=

V0 λrM

sinh(L − X) cosh(L)

I0

=

V0 λrM

tanh(L)

at

X =0

Rinp

=

λrM

1 tanh(l)

and

Ginp

=

λrM tanh(L)

3.5 Branching and equivalent cylinders.

The inﬁnite cable and the ﬁnite cable are simple idealizations of the multi-branched structure of true neurites. Here, we brieﬂy look at branch points and describe the Rall model for dendrites. Figure 3.2 hows a simple branched dendritic structure. Consider the cable with diameter d0, length ℓ0 and space constant λ0 which branches at x = x1 into two semi-inﬁnite cables with diameters d1 and d2 and space constants λ1 and λ2. The cable equation for such a structure can be solved on the individual segments coupled with continuity of the voltages and the conservation of current. Under certain constraints on the geometry, we can attain a stronger result than continuity of the voltage and its derivative that is important physically and allows us to signiﬁcantly simplify the problem. With these constraints on the geometry, we will show that having the branch point at x1 is exactly equivalent to extending branch d0 to inﬁnity.
Conservation of current implies that the current leaving the branch d0 equals the sum of the currents entering branches d1 and d2. That is,

πd20 4rL

V0′(x1)

=

πd21 4rL

V1′(x1

)

+

πd22 4rL

V2′(x1

).

(3.15)

Here we assume that the material properties of the cables are the same; only their geometry diﬀers. Now, if we let V0 ≡ V0(x1) = V1(x1) = V2(x1), then

V1(x) = V0eλ1x and V2(x) = V0e−λ2x

i i

i i

50

Chapter 3. Dendrites

for x > x1. Moreover, if Veq(x) is the membrane potential of the cable obtained by extending branch d0 to inﬁnity, then
Veq (x) = V0eλ0x.

Plugging these into (3.15), and recalling that λj ∝ dj, we ﬁnd that we can collapse the three cables 0, 1, and 2 into a single semi-inﬁnite cable with diameter d0 if

3

3

3

d02 = d12 + d22

(3.16)

Will Rall was the ﬁrst to recognize that if (3.16) is satisﬁed and the material properties of the cables are the same, then the three cables 0, 1 and 2 can be collapsed into an equivalent cylinder. For a complex structure, starting at the ends, we can recursively simplify the model to a single semi-inﬁnite cylinder. In the previous example, we considered only two branches at the branch point; however, we could have had any number of branches at each branch point as long as

3

3

dP2 =

dD2

where dP is the parent dendrite and dD are the daughter dendrites. If this condition holds at every branch point and the material properties of the cables are the same, then the entire dendritic tree can be reduced to an equivalent semi-inﬁnite cable.
We have so far assumed that the branches attached to the ﬁnal branch point extend to inﬁnity; that is, they correspond to semi-inﬁnite cables. A similar analysis holds if we assume that all of the branches have ﬁnite lengths. Here we must assume that all dendrites end at the same electrotonic length. Recall that the electronic length of a cable of length ℓ and space constant λ is ℓ/λ. Suppose, for example, that the cables 1 and 2 shown in Figure ?? have lengths ℓ1 and ℓ2. If we assume that ℓ1/λ1 = ℓ2/λ2, then we can collapse the three cables 0, 1 and 2 into a single cable of diameter d0 and electrotonic length equal to ℓ0/λ0 + ℓ1/λ1 = ℓ0/λ0 + ℓ2/λ2.

Example

In the ﬁgure 3.3, we depict a dendritic tree consisting of several branches with their lengths and diameters in microns. (a) Can they be reduced to an equivalent cylinder (b) What is the electrotonic length (c) What is the input conductance. Assume sealed ends for all terminal dendrites and assume that rM = 2000Ωcm2 and that rL = 60Ωcm.
Answer.
d3a/2 + d3b/2 + d3c/2 = 1 + 1 + 1 = 3 = 2.083/2 = d3d/2
d3d/2 + d3e/2 = 3 + 3 = 6 = 3.33/2 = d3f/2
so the 3/2 rule is obeyed. Clearly a,b,c are all the same electrotonic length. The space constants are:

λa = λb = λc = darM /4rL = 289µ

i i

i i

3.5. Branching and equivalent cylinders.

51

EXAMPLE
20 f
3.3

a
d
10 2.08

10
b
1
c

e
24 2.08

10 1

20

40

1.58

2.85

36.6

2

HOMEWORK

Figure 3.3. Example of the Rall reduction to an equivalent cylinder.

λd = λe = derM /4rL = 416µ

λf = df rM /4rL = 524µ

Thus, the total electrotonic length of abc with d is

Labcd

=

ℓa λa

+

ℓd λd

=

10 289

+

10 416

= .0586

Le

=

ℓe λe

=

24 416

=

.0576

which are close enough to be considered equal (2% diﬀerence). Thus, we can com-

bine the whole thing into an equivalent cylinder. The total electrotonic length is

then:

L=

Lf

+ Le

=

Lf

+ Labcd

=

ℓf λf

+ Le

= 0.096

≈ 0.1

i i

i i

52

Chapter 3. Dendrites

Finally, the input conductance is

which is

Gin

=

G∞

tanh(L)

=

√πd3/2 2 RM RA

tanh(L)

Gin

=

tanh(0.1)(3.√14159)(3.3 × 10−4)3/2 2 2000 × 60

=

2.7 × 10−9S

3.6 An isolated junction

The equivalent cylinder is a very useful method for reducing the analysis of complex

dendritic trees to a simpler model. However, there are limitations. For example,

one must assume that the so-called 3/2 law (see (3.16)) is satisﬁed. Another dif-

ﬁculty is related to the problem of determining the response of the dendritic tree

to an injected current. Consider, for example, the simple dendritic tree shown in

Figure 3.2. If the injection site is along the principle initial cylinder, then the equiv-

alent cylinder will determine how the membrane potential responses at this and the

daughter dendrites. However, if the injection site is along the daughter dendrites,

then, in order to use the equivalent circuit, one must assume that the current is

spread out evenly along all of the daughter dendrites that emerge from the same

junction point. One cannot use the equivalent circuit if only one of the daughter

dendrites receives input and the others receive none.

In this section, we consider a single isolated junction of three semi-inﬁnite

cables with a point source of current injection. We do not assume that the 3/2 law

holds. We note that a considerably more general analysis for dendritic trees with

complex geometries is given in [Rinzel/Rall].

We consider the branched cable shown in Figure ??. The three cables are

denoted as C0, C1 and C2. Assume that the diameters and speciﬁc membrane

resistance of the cables are di and rMi, i = 0, 1, 2, respectively. Let rL be the

longitudinal resistivity. We assume that the junction point is at x = 0. Moreover, x

will denote the distance along each cable to the junction point. Finally, we assume

that there is an electrode current at an isolated point along C0; the distance from

this point to the junction point is denoted as y. Note that C0 may be either the

parent dendrite or one of the daughter dendrites.

We derive the steady-state solution to this problem. Except at the junction

and the injection points, each membrane potential Vi(x) satisﬁes the steady-state

cable equation:

λi

∂2Vi ∂x2

−

Vi

=

0

where

λi =

di rM i 4rL

is the space constant of corresponding cable. We now need to determine the boundary conditions that must be satisﬁed. At the junction point, the three membrane

i i

i i

3.7. Exercises

53

potentials must be equal; moreover, the ﬂow of current must be conserved. Hence,

V0(0) = V1(0) = V2(0) and

d2i

dVi dx

(0)

=

0.

At the electrode site, the injection current is conserved and spreads towards (de-

creasing x) or away from (increasing x) the junction point. Recall that the lon-

gitudinal current is given by (3.8). It follows that the boundary condition at the

junction point is:

dV0 dx

(y−)

−

dV0 dx

(y+

)

=

4rL πd20

I0

where I0 is the total electrode current and the two terms on the left hand side represent the left-handed and right-handed derivatives of V0 at y, respectively.
We leave it as an exercise to demonstrate that the solution of this problem is given by:

V0(x)

=

I0 Rλ0 2

[exp(−|y

− x|/λ0)

+

(2p0

−

1)exp(−(y

+

x)/λ0)]

V1(x) = p1I0Rλ1 exp(−x/λ1 − y/λ0)

V2(x) = p2I0Rλ2 exp(−x/λ2 − y/λ0)

(3.17)

where, for i = 0, 1, 2,

pi

=

d31/2

d3i /2 + d32/2

+ d33/2

and

Rλi

=

4rLλi πd2i

.

An example is shown in Figure ??. If the injection site is along the thicker dendrite, then this has little eﬀect on the attenuation of the potential along the thin branches. However, if the injection since is along on of the thinner dendrites, then the big dendrite has a much greater eﬀect on the attenuation between the two thinner branches.

3.7 Exercises
1. (a) Plot proﬁles of V (x, t) for the response of an inﬁnite cable (3.13) at diﬀerent spatial locations as a function of time. (b) Compute the time at which V (x, t) reaches its maximum and show that for x large it is asymptotically linear in x. (c) Compute the maximum value of the voltage for each spatial position.
2. Compute the steady-state response of the cable to a sustained periodic input. That is I(x, t) = I0 sin(ωt)δ(x). (Hint: Everything will be easier if write the current as proportional to exp(iωt) and use the linearity of the cable to assume a solution of the form z(x) exp(iωt).. Then use the steady state inﬁnite cable result.) Compute the phase-shift as a function of the distance from the source. Plot the amplitude at x = 0 as a function of the frequency. Determine how quickly the amplitude falls oﬀ with distance as a function of frequency.

i i

i i

54

Chapter 3. Dendrites

3. Solve the cable equation τ vt = −v + vxx + I(x, t) on the ﬁnite interval 0 < x < L subject to the boundary conditions v(0) = 0 and vx(L) = 0. (Hint: You could compute a Green’s function for this, or you could expand it in an eigenfunction expansion by solving v′′ = βv with v(0) = 0 and v′(L) = 0.).
4. Consider a cable with electrotonic length L and a sealed end at x = L. Suppose V (0) = V0. Show that the input conductance at X = 0 is
GL = G∞ tanh(L).

5. Prove that the homogeneous solution to equation

1 d d2(x)dV d(x) dx dx

= V (x)

(3.18)

with boundary conditions dV /dx(0) = 0 and V (L) = 0 has no nonzero solutions. (Hint: Without loss of generality, you can assume V (0) > 0. Show that V (x) must be concave up in the interval (0, L).)

6. Numerically compute the solution to (3.18) with d(x) = 1 − cx/L where c < 1, V (0) = 1 and V ′(L) = 0. Compare the solutions for c = 0 to those with c = .95
when L = 10. Try c = −0.5 (corresponding to a fattening cable)

7. Do the equivalent cylinder reduction to the bottom dendrite in ﬁgure 3.3.

8. Advanced exercise. Consider a cable with three currents, as shown in ﬁgure equivcyl. Suppose that the concentrations of the ions are those given for the squid axon in table 2.3 and that the permeabilities are PK = 1, PCl = 0.1 and PNa = .03. Suppose the temperature is 20 C. Let I(V ) denote the total current as deﬁned by (2.3). Simulate the response to the following cable:

Cm

∂V ∂t

=

−I (V

)

+

K

∂2V ∂x2

to a current step at x = 0. You can make Cm = 1, K = 1 without loss of generality since these just set the time and space scales. Compare this to the passive linear conductance cable model. Convince yourself that there is very little diﬀerence. In particular, you might want to solve the steady state boundary value problem for, say, V (0) = V0 and Vx(L) = 0. You cannot do this analytically, but numerical solutions should be fairly simple.

3.8 Dendrites with active processes
We have, so far, primarily considered passive dendrites in which all of the conductances and currents are constant. However, it is now recognized that neurons may have active voltage-gated conductances along the dendritic trees and these active conductances may have a profound inﬂuence on the neuron’s ﬁring properties and how the neuron response to synaptic inputs. We note that active channels are typically unevenly distributed along the dendrites so, for example, there may be a higher

i i

i i

3.8. Dendrites with active processes

55

IS gc
I
Na
IK−DR SOMA

Id

I
Ca

IK−C

I
K−AHP

DENDRITE

Figure 3.4. Schematic of 2-compartment model showing applied currents and outward and inward currents to soma and dendrite compartments.
distribution of, say, sodium channels in the proximal region near the soma than in the distal region far from the soma. A useful way to model neurons with active dendrites is to use the multicompartment approach. Here we present an example of this due to Rinzel and Pinsky.
Pinsky and Rinzel developed a two-compartment model for CA3 hippocampal pyramidal neurons in a guinea pig. This work was motivated by an earlier, considerably more complex model of Traub which consisted of 19 compartments. The reduced Pinsky-Rinzel model contained elements of the full model which were thought to be essential and was capable of reproducing many of the important stimulus-response properties of the Traub model. By considering a minimal reduced model, Pinsky and Rinzel were able to explain how interactions between the somatic and dendritic compartments generate bursting with unusual wave-forms which do not seem to arise in single-compartment models. The reduced model is also considerably easier to implement computationally.
A schemata of the two-compartment model is shown in Figure 3.4. Motivated by Traub’s model, the fast spiking currents are restricted to the soma while most of the calcium and calcium modulated currents lie in the dendritic-like compartment. The soma-like compartment has two voltage-dependent currents, an inward sodium current and an outward delayed-rectiﬁer potassium current. The dendritic compartment has three voltage dependent currents. There is a fast calcium current and two types of potassium currents: a Ca-activated potassium current and a potassium afterhyperpolarization. Electrotonic coupling between the compartments is modeled using two parameters, gc and p, where gc represents the strength of coupling and p represents the percentage of total area in the some-like compartment. Finally, the model includes terms for applied current to the soma and dendrite.

i i

i i

56

Chapter 3. Dendrites

The model can generate bursting activity for appropriate values of the parameters. Figure 3.5 shows the wave-form of the spiking activity during a burst. This type of activity does not typically arise in single-compartment models; it results from interactions between the two compartments. Here we step through how this burst is generated; a more complete and detailed description is given in [?].
The burst shown in Figure 3.5 results from electrotonic interactions between soma and dendrite with signiﬁcant coupling current that ﬂows back and forth, alternately providing depolarizing or hyperpolarizing current to each compartment. The burst sequence is initiated by a somatic sodium spike. This is because INa is activated at lower voltages that ICa. The leading sodium action potential depolarizes the dendrite through the spread of electrotonic current. The soma then repolarizes, but only partially. This causes the dendritic membrane potential to fall below the threshold for calcium spike generation, thereby delaying the full dendritic spike. During this repolarization phase, current ﬂows into the soma from the dendrite which then initiates a second somatic spike. The second somatic spike stops the drain of coupling current from the dendrite, enabling the dendrite to undergo a full ICa-mediated voltage spike with accompanying rapid increase in Ca. The dendritic spike then provides depolarization which drives soma activity. We note that the calcium dendritic spikes are considerably broader than the somatic spikes. The broad dendritic spike leads to strong stimulation of the soma which leads to damped, high frequency spiking. The dendritic calcium spike, and hence the burst, is terminated by the calcium-dependent potassium current. This builds up on a slow time-scale during the dendritic spiking activity. Hence, the burst duration is primarily determined by the amount of time required for Ca to build up. We note that the length of the silent phase is determined by slow variables q and Ca mediating the outward potassium currents. Both of these currents must decrease before a somatic action potential can be initiated.

3.9 Bibliography
Much of the pioneering work on the modeling of dendrites was done by Wilfred Rall. Reviews of this material can be found in Rall [39] and Koch and Segev [31]. The book [45] was written in honor of Wilfred Rall and contains many of his original papers, along with commentaries by leading researchers in this ﬁeld. Other textbooks include Jack et. al. [25], Tuckwell [52], Johnston and Wu [26] and Koch [30].

i i

i i

3.9. Bibliography

57

Figure 3.5. Voltage and calcium traces of a bursting solution in the 2compartment model.

i i

i i

58

Chapter 3. Dendrites

i i

i i

Chapter 4

i i

Dynamics
4.1 Introduction to dynamical systems
Dynamical systems theory provides a powerful tool for analyzing nonlinear systems of diﬀerential equations, including those that arise in neuroscience. This theory allows us to interpret solutions geometrically as curves in a phase space. By studying the geometric structure of phase space, we are often able to classify the types of solutions that the model may exhibit and determine how solutions depend on the model’s parameters. For example, we can often predict if a model neuron will generate an action potential, determine for which values of the parameters the model will produce oscillations and compute how the frequency of oscillations depends on parameters.
In this chapter, we introduce many of the basic concepts of dynamical systems theory using a reduced 2-variable model: the Morris-Lecar equations. Although this model is considerably simpler than the Hodgkin-Huxley equations, it still exhibits many important features of neuronal activity. For example, the Morris-Lecar model generates action potentials, there is a threshold for ﬁring and the model displays sustained oscillations at elevated levels of an applied current. By considering a reduced model, we can more easily explain the geometric mechanisms underlying each of these phenomena. Moreover, we can introduce important mathematical concepts such as phase space analysis, bifurcation theory, oscillations and stability theory. Each of these concepts plays a fundamental role in the analysis of more complex systems discussed throughout the book.
4.2 The Morris-Lecar model
One of the simplest models for the production of action potentials is a model proposed by Kathleen Morris and Harold Lecar. The model has three channels: a potassium channel, a leak, and a calcium channel. In the simplest version of the model, the calcium current depends instantaneously on the voltage. Thus, the
59

i i

60

Chapter 4. Dynamics

Morris-Lecar equations (ML) have the form:

Cm

dV dt

= Iapp − gl(V

− EL) − gkn(V

− EK )

−gCam∞(V )(V − ECa) ≡ Iapp − Iion(V, n)

dn dt

=

φ(n∞(V

)

−

n)/τn(V

)

(4.1)

where

m∞(V )

=

1 2

[1

+

tanh((V

− V1)/V2)]

τn(V ) = 1/ cosh((V − V3)/(2V4))

n∞(V )

=

1 2

[1

+

tanh((V

− V3)/V4)].

Here, V1,2,3,4 are parameters chosen to ﬁt voltage clamp data. The solutions shown in Figure 4.1 demonstrate that the Morris-Lecar model
exhibits many of the properties displayed by neurons. Here the parameters are listed in Table 4.2 under the Hopf case. Figure 4.1A demonstrates that the model is excitable if Iapp = 60. That is, there is a stable constant solution corresponding to the resting state of the model neuron. A small perturbation decays to the resting state, while a larger perturbation, above some threshold, generates an action potential. The solution (V1(t), n1(t)) ≡ (VR, nR) is constant; VR is the resting state of the model neuron. The solution (V2(t), n2(t)) corresponds to a subthreshold response. Here, V2(0) is slightly larger than VR and (V2(t), n2(t)) decays back to rest. Finally, (V3(t), n3(t)) corresponds to an action potential. Here, we start with V3(0) above some threshold. There is then a large increase of V3(t) followed by V3(t) falling below VR and then a return to rest.
Figure 4.1B shows a periodic solution of (ML). The parameter values are exactly the same as before; however, we have increased the parameter Iapp, corresponding to the applied current. If we increase Iapp further, then the frequency of oscillations increase; if Iapp is too large, then the solution approaches a constant value.
In the following, we will show how dynamical systems methods can be used to mathematically analyze these solutions. The analysis is extremely useful in understanding when this type of model, for a given set of parameters, displays a particular type of behavior. The behavior may change as parameters are varied; an important goal of bifurcation theory, which we describe below, is to determine when and what types of transitions take place.

4.3 The phase plane

It will be convenient to write (4.1) as

dV dt

= f (V, n)

dn dt

=

g(V, n).

(4.2)

i i

i i

4.3. The phase plane

61

A) 40

20

V

V (t)

0

3

−20 V (t)
2
−40
VR
−60 V (t)
1

−80

0

40 time

80

B) 40
20
V
0

−20

−40

−60

0

100 time

200

300

Figure 4.1. Solutions of the Morris-Lecar equations. Parameters are listed in Table 4.2, the Hopf case. A) A small perturbation from rest decays to the resting state, while a larger perturbation generates an action potential. Here, Iapp = 60. B) A periodic solution of (ML). Here, Iapp = 100.

Table 4.1. Morris-Lecar parameters; the current, Iapp, is a parameter.

Parameter
φ
gCa V3 V4 ECa EK EL gK gL V1 V2 Cm

Hopf 0.04 4.4 2 30 120 -84 -60 8 2 -1.2 18 20

SNLC .067 4 12 17.4 120 -84 -60 8 2 -1.2 18 20

Homoclinic 0.23 4 12 17.4 120 -84 -60 8 2 -1.2 18 20

The phase space for this system is simply the (V, n)-plane; this is usually referred
to as the phase plane. If (V (t), n(t)) is a solution of (4.1), then at each time t0, (V (t0), n(t0)) deﬁnes a point in the phase plane. The point changes with time, so the entire solution (V (t), n(t)) traces out a curve (or trajectory or orbit), in the
phase plane. Of course, not every arbitrarily drawn curve in the phase plane corresponds
to a solution of the diﬀerential equations. What is special about solution curves is
that the velocity vector at each point along the curve is given by the right hand side of (4.1). That is, the velocity vector of the solution curve (V (t), n(t)) at a point (V0, n0) is given by (V ′(t), n′(t)) = (f (V0, n0), g(V0, n)). This geometric property – that the vector (f (V, n), g(V, n)) always points in the direction that the solution is

i i

i i

62

Chapter 4. Dynamics

ﬂowing – completely characterizes the solution curves. Two important types of trajectories are ﬁxed points (sometimes called equilib-
ria or rest points) and closed orbits. At a ﬁxed point, f (VR, nR) = g(VR, nR) = 0; this corresponds to a constant solution. Closed orbits correspond to periodic solutions. That is, if (v(t), n(t)) represents a closed orbit, then there exists T > 0 such that (V (t), n(t)) = (V (t + T ), n(t + T )) for all t.
A useful way to understand how trajectories behave in the phase plane is to consider the nullclines. The V-nullcline is the curve deﬁned by V ′ = f (V, n) = 0 and the n-nullcline is where n′ = g(V, n) = 0. Note that along the V-nullcline, the vector ﬁeld (f (V, n), g(V, n)) points either up or down and along the n-nullcline, vectors point either to the left or to the right. Fixed points are where the two nullclines intersect. The nullclines divide the phase plane into separate regions; in each of these regions, the vector ﬁeld points in the direction of one of the four quadrants: (I) f > 0, g > 0; (II) f < 0, g > 0; (III) f < 0, g < 0; or (IV) f > 0, g < 0.

Stability of ﬁxed points

One can determine the stability of a ﬁxed point by considering the linearization of the vector ﬁeld at the ﬁxed point. The linearization of (4.2) at a ﬁxed point (VR, nR) is the matrix

M=

∂f ∂∂Vg ∂V

(VR , (VR ,

nR) nR)

∂f ∂∂ng ∂n

(VR (VR

, ,

nR) nR)

.

The ﬁxed point is stable if both of the eigenvalues of this matrix have negative real part; the ﬁxed point is unstable if at least one of the eigenvalues has positive real part. For (ML), the linearization is given by

M=

−

∂

Iion (VR ∂V

,nR

)

/Cm

−gK(VR − EK )/Cm

φn′∞(VR)/τn(VR)

−φ/τn(VR)

≡

a c

b d

.

Moreover,

a

≡

−

∂Iion(VR, ∂V

nR)

/Cm

= (−gL − gK nR − gCam∞(VR) + (ECa − VR)gCam′∞(VR))/Cm.

We now ﬁnd conditions on the nonlinear functions in (4.1) for when the ﬁxed point is stable.
Suppose that the equilibrium voltage lies between EK and ECa, a reasonable assumption. Then b < 0, c > 0, and d < 0 in the linearization. Only a can be either negative or positive and the only term contributing to the positivity of a is the slope of the calcium activation function, m∞(V ). If a < 0, then the ﬁxed point is asymptotically stable since the trace of M is negative and the determinant is positive. (Recall that the trace is the sum of the eigenvalues and the determinant is the product of eigenvalues.) Note that the slope of the V-nullcline near the ﬁxed point is given by −a/b. Since b < 0, it follows that if this slope is negative then

i i

i i

4.3. The phase plane

63

the ﬁxed point is stable; that is, if the ﬁxed point lies along the left branch of the V-nullcline, then it is stable.
Now suppose that the ﬁxed point lies along the middle branch of the Vnullcline, so that a > 0. Note that the slope of the n-nullcline, −c/d, is always positive. If the slope of the V-nullcline is greater than the slope of the n-nullcline, (i.e., −a/b > −c/d) then ad − bc < 0. In this case, the determinant is negative and the ﬁxed point is an unstable saddle point. In contrast, if the slope of the n-nullcline is greater than that of the V-nullcline, then the ﬁxed point is a node or a spiral. We leave it as an exercise to show that the ﬁxed point is a spiral if the parameter φ is suﬃciently small. In this case, the stability of the ﬁxed point is determined by the trace of M : the ﬁxed point is stable if a + d < 0 and it is unstable if a + d > 0. In summary, if the ﬁxed point lies along the middle branch of the V-nullcline, then it is unstable if either the slope of the V-nullcline at the ﬁxed point is suﬃciently large, or φ is suﬃciently small. Note that φ governs the speed of the potassium dynamics.

Excitable systems
Recall that for the parameters given in Table 4.2, the Hopf case, the system is excitable. As Figure 4.1A demonstrates, a small perturbation in voltage from the resting state decays back to rest, while a suﬃciently large perturbation in voltage continues to increase and generates an action potential.
Phase plane analysis is very useful in understanding what separates the ﬁring of an action potential from the subthreshold return to rest in this model. The projection of the solutions shown in Figure 4.1A onto the phase plane are shown in Figure 4.2A. This ﬁgure also shows the V - and the n-nullclines. Note that the V -nullcline separates points along trajectories in which V ′ < 0 and V ′ > 0. In particular, V increases below the V -nullcline and V decreases above the V nullcline. We further note that the V -nullcline is ’cubic-shaped’. This suggests that a perturbation from rest that lies to the ’left’ of the middle-branch of the V nullcline will return quickly to rest, while a perturbation that lies to the ’right’ of the V -nullcline will initially display an increase in membrane potential, corresponding to an action potential, before returning to rest. Therefore, the middle-branch of the V -nullcline in some sense separates the ﬁring of an action potential from the subthreshold return to rest.
This analysis can be made more precise if we assume that the parameter φ is small. Looking at Table 4.2, it can be seen that φ is relatively smaller in the Hopf case than in the other two cases. For small φ, n will not change much so let’s hold it at rest. Figure 4.3 shows the phase plane with a horizontal line drawn through the ﬁxed point. If n does not change much, then the dynamics are governed by the behavior on the phase-line n = nR. Since the V -nullcline intersects this line at 3 points, there are three equilibria to the system when n is held constant. The resting state (and true equilibrium of the full system) VR is stable. There are two additional equilibria (which are not equilibria of the full model, just the model when n is held at its resting value): Vθ, which is unstable and Ve, which is stable. On this line, if the voltage is perturbed past Vθ then it will jump to the right ﬁxed

i i

i i

64

Chapter 4. Dynamics

An 0.5 0.4

V’=0

0.3

0.2

0.1
0 n’=0

-0.1

-60

-40

-20

0

V

20

40

Cn 0.6 0.5

V’=0 SLC

0.4

0.3
ULC
0.2

0.1

n’=0

0

-60

-40

-20

0

V

20

40

Bn 30 20 10 0 -10 -20 -30 -40 -50 -60 0

50

100

150

200

V

Dn 0.6 V’=0 0.5

0.4

SLC

0.3

0.2

0.1

n’=0

0

-60

-40

-20

0

V

20

40

Figure 4.2. Phaseplanes and time series for the ML model in the Hopf regime. (A) I = 60; an excitable system with threshold at about 20 mV. Nullclines are included as well, (B) Starting at n = nrest and varying V from -20 to -20.1 mV; (C) I = 90 showing bistability between a stable limit cycle (SLC) and a ﬁxed point, separated by the unstable limit cycle (ULC); (D) I = 95, the ﬁxed point is stable and only a limit cycle remains.

point, Ve. Otherwise, it will decay to rest, VR. This shows that for small φ, the “threshold” voltage for generating an action potential is roughly the intersection of the horizontal line through the rest state and the middle branch of the V -nullcline. Since experimentalists can only move the voltage through current injection, we can use this to estimate the magnitude of a current pulse needed to cross threshold. (See exercise 2 below.)
We note that the peak of the action potential occurs at some latency after the initial perturbation, but this latency can never get very large. The action potential itself is graded and takes on a continuum of peak values, as shown in Figure 4.2B. If φ is not “small” and it is increased, then the spike amplitudes are even more graded than those shown in Figure 4.2B. Recall that φ is related to the temperature of the preparation. Thus, increasing the temperature of a neuron should lead to a much less sharp threshold distinction and graded action potentials. Indeed, Cole et al demonstrated this in the squid.

i i

i i

4.4. Bifurcation analysis

65

n 0.5

0.45

0.4

0.35

0.3

0.25

0.2

0.15

0.1

0.05

0

-60 -40 -20

0

20

40

60

V

Vr Vt

Ve

Figure 4.3. Threshold construction for the ML model.

Oscillations
We expect the phase plane to change if a parameter in the equations changes. Figure 4.2D shows the phase plane corresponding to the periodic solution shown in Figure 4.1B. Here, Iapp = 100. Note that the periodic solution corresponds to a closed curve, or limit cycle. In general, whenever we wish to ﬁnd periodic solutions of some model, we look for closed orbits in phase space. In Figure 4.2D, there is a unique ﬁxed point; this is where the nullclines intersect. This ﬁxed point is unstable, however.
If we change Iapp to 90, then the model is bistable and the phase plane is shown in Figure 4.2C. Note that there exist both a stable ﬁxed point and a stable limit cycle. Small perturbations from rest will decay back to the stable ﬁxed point, while large perturbations will approach the stable periodic solution. Note that there also exists an unstable periodic solution. This orbit separates those initial conditions that approach the stable ﬁxed point from those that approach the stable limit cycle.
It is often diﬃcult to show that a given model exhibits stable oscillations, especially in higher dimensional systems such as the Hodgkin-Huxley model. Limit cycles are global objects, unlike ﬁxed points that are local. In order to demonstrate that a given point is on a periodic solution, one must follow the trajectory passing through that point and wait to see if the trajectory returns to where it started. This is clearly not a useful strategy for ﬁnding periodic solutions. A powerful method for locating oscillatory behavior is bifurcation theory, which we describe in the following section.
4.4 Bifurcation analysis
Bifurcation theory is concerned with how solutions change as parameters in a model are varied. For example, in the previous section we showed that the Morris-Lecar equations may exhibit diﬀerent types of solutions for diﬀerent values of the applied current Iapp. If Iapp = 60, then there is a stable ﬁxed point and no oscillations, while if Iapp = 100, then the ﬁxed point is unstable and there does exist a stable

i i

i i

66

Chapter 4. Dynamics

limit cycle. Using bifurcation theory, we can classify the types of transitions that take place as we change parameters. In particular, we can predict for which value of Iapp the ﬁxed point loses its stability and oscillations emerge. There are, in fact, several diﬀerent types of bifurcations; that is, there are diﬀerent mechanisms by which stable oscillations emerge. The most important types of bifurcations can be realized by the Morris-Lecar model. These are described below.

The Hopf bifurcation
In Figure 4.4, we choose the parameters as in Table 1, the Hopf regime, and show the bifurcation diagram for (ML) as the current Iapp is varied. For each value of Iapp, there is a unique ﬁxed point, (VR(Iapp), nR(Iapp)). In Figure 4.4A, we plot VR vs. Iapp. The ﬁxed point is stable for Iapp < 94 ≡ I1 and Iapp > 212 ≡ I2; otherwise, it is unstable. A Hopf bifurcation takes place at Iapp = I1 and Iapp = I2. By this we mean the following: Recall that a ﬁxed point is stable if all of the eigenvalues of the linearization have negative real part; the ﬁxed point is unstable if at least one of the eigenvalues has positive real part. The ﬁxed point loses stability, as a parameter is varied, when at least one eigenvalue crosses the imaginary axis. If the eigenvalues are all real numbers, then they can cross the imaginary axis only at the origin in the complex plane. However, if an eigenvalue is complex, then it (and its complex conjugate) will cross the imaginary axis at some point that is not at the origin. This latter case corresponds to the Hopf bifurcation and it is precisely what happens for the example we are considering. In this example, (I1, VR(I1), nR(I1)) and (I2, VR(I2), nR(I2)) are called bifurcation points. Sometimes, I1 and I2 are also referred to as bifurcation points. The Hopf Bifurcation Theorem states that (if certain technical assumptions are satisﬁed) there must exist values of the parameter Iapp near I1 and I2 such that there exist periodic solutions that lie near the ﬁxed points (VR(Iapp), nR(Iapp)). A more precise statement of the Hopf bifurcation theory can be found in numerous texts on dynamical systems.
The curves in Figure 4.4A represent ﬁxed points and periodic solutions of the Morris-Lecar model. This diagram was generated using the numerical software XPPAUT. The curve above the ﬁxed point curve represents the maximum voltages on the periodic orbits and the curve below the ﬁxed point curve represents the minimum voltages. The solid curves represent stable solutions and the dashed curves represent unstable solutions. The bifurcation diagram shows many interesting and important features. Note that the periodic solutions near the two bifurcations points are unstable. These unstable, small amplitude periodic solutions lie on the same side of the bifurcation points as the stable ﬁxed points. These are both examples of subcritical Hopf bifurcations. At a supercritical Hopf bifurcation, the small amplitude periodic solutions near the Hopf bifurcation point are stable and lie on the opposite side as the branch of stable ﬁxed points.
If 88.3 < Iapp < I1 and I2 < Iapp < 217, then (ML) is bistable. For these values of Iapp, there exists both a stable ﬁxed point and a stable periodic solution. The phase plane for Iapp = 95 is shown in Figure 4.2C. Note that small perturbations of initial conditions from the resting state will decay back to rest; however, large perturbation from rest will generate solutions that approach the stable limit cycles.

i i

i i

4.4. Bifurcation analysis

67

AV 40 20 0 -20 -40 -60 50

100

150

200

curreni t

B20
15
ω
10

5

0

250

50

100

150

200

current

C phi 0.5 0.45

0.4

0.35

0.3

0.25

0.2

0.15

0.1

0.05

0

250

60 80 100 120 140 160 180 200 220 240

i

Figure 4.4. Bifurcation diagram for the ML model in the Hopf regime. (A) Voltage as a function of current. The curves above and below the ﬁxed point curve correspond to the maximum and minimum voltages along periodic orbits. Solid curves represent stable solutions and dashed curves represent unstable solutions. Arrows shown at Iapp = 60, 90 and 100 correspond to the solutions shown in Figure 4.1, Figure 4.2A and Figure 4.2B, respectively. (B) Frequency (Hz) versus current. (C) Two-parameter bifurcation showing the curve of Hopf bifurcations as φ and Iapp vary.

Figure 4.4B shows the frequency of the periodic solutions versus current. Note that the frequency lies in a narrow range between 7-16 Hz. In particular, the frequency does not approach zero as Iapp approaches the bifurcation points. This is a general property of periodic solutions that arise via the Hopf bifurcation. In the next section, we shall consider another mechanism for the generation of stable limit cycles. In that mechanism, the frequency does approach zero.
Finally, we can ask what happens if we change the speed of the potassium kinetics. Figure 4.4C shows a two-parameter diagram with φ along the vertical axis and Iapp along the horizontal axis. This shows the locus of Hopf bifurcations in these two parameters. For ﬁxed values of φ below about 0.4, there are two currents at which the Hopf bifurcation occurs. Inside the curve, the rest state is stable. One can numerically show that the Hopf bifurcation is subcritical outside the interval, 124.47 < Iapp < 165.68; inside this interval, the bifurcation is supercritical. The reader can choose, for example, φ = .35 and show that both Hopf bifurcations are supercritical; the only oscillations are stable and have small amplitude.
Saddle-node on a limit cycle
The Hopf bifurcation is the best known mechanism through which one can go from a stable ﬁxed point to an oscillation. Importantly, the ﬁxed point persists through the bifurcation. Furthermore, the limit cycles which bifurcate are small amplitude and local, in the sense that it lies close to the branch of ﬁxed points (although, as we saw in the ML model, the bifurcation is subcritical at low currents and thus bifurcating periodic orbits are unstable). Another mechanism through which an oscillation can emerges from a ﬁxed point is called a saddle-node on a limit cycle or SNLC. It is also called a saddle-node inﬁnite cycle or SNIC. This is an example of a global bifurcation.

i i

i i

68

Chapter 4. Dynamics

The behavior of the ML model with these parameters is quite diﬀerent as is seen by looking at Figure 4.5. First, unlike Figure 4.2B, the action potentials appear to occur with arbitrary delay after the end of the stimulus. Secondly, the shape of the action potentials is much less variable. The reason for this can be understood by looking at the phase plane in Figure 4.5B. Unlike the Hopf case, here there are three ﬁxed points, only one of which (labeled N ) is stable. The middle ﬁxed point is a saddle point (labeled S). Thus, the linearized system at this ﬁxed point has one positive and one negative eigenvalue. Associated with these eigenvalues are the stable and unstable manifolds. These manifolds consist of trajectories that approach the saddle point in either forward or backward time, respectively. The two branches of the unstable manifold, Σ+, form a loop with the stable node N and the saddle point S. This loop in the plane plane constrains the spike shape; since trajectories cannot cross, any trajectory starting outside the loop must remain outside of it. Thus, the spike height cannot fall below a certain level. More importantly, the stable manifold, Σ−, forms a hard threshold that is precisely determined. This contrasts with the pseudothreshold we saw in the Hopf case. Any perturbation which drives the potential to the right of Σ− results in a spike and any to the left leads to a return to rest without a spike.
Figure 4.5 also explains the delay to ﬁring. Suppose that a stimulus drives the voltage to a point exactly on the unstable manifold Σ−. Then, the trajectory will go to the saddle point where it will remain. The closer a perturbation gets to Σ− (but to the right of it), the longer the delay to spike. Indeed, the spike with the longest delay in Figure 4.5A stays at a nearly constant voltage close to the value at the saddle-point before ﬁnally ﬁring.
Like the Hopf case, as current is increased, the model ﬁres repetitively. A typical limit cycle is shown in Figure 4.5D. Figure 4.6A shows the bifurcation diagram as the current is increased. The steady-state voltage shows a region where there are three equilibria for Iapp between about -15 and +40. Only the lower ﬁxed point is stable. As Iapp increases, the saddle-point and the stable node merge together at a saddle-node bifurcation, labeled SN2. When Iapp = ISN2, the invariant loop formed from Σ+ becomes a homoclinic orbit; that is, it is a single trajectory that approaches a single ﬁxed point in both forward and backward time. This type of homoclinic orbit is sometimes called a saddle-node homoclinic orbit or a SNIC. As Iapp increases past Iapp = ISN2 , the saddle-point and node disappear; the invariant loop formed from Σ+ becomes a stable limit cycle. The branch of limit cycles persists until it meets with a branch of unstable periodic solutions emerging from a subcritical Hopf bifurcation.
Figure 4.6B shows the frequency of the oscillations as a function of the current. Unlike Figure 4.4B, the frequency for this model can be arbitrarily low and there is a much greater dynamic range. Note that the nullclines in Figure 4.5C can be very close to touching each other and thus create a narrow channel where the ﬂow is extremely slow. This suggests why the frequency of ﬁring can be arbitrarily low. Moreover, as Iapp → ISN2, the limit cycles approach a homoclinic orbit. We expect that the frequency should approach zero as Iapp → ISN2 . In an exercise below, the reader shows that the frequency scales as the square root of Iapp − ISN2 and develops the theta model.

i i

i i

4.4. Bifurcation analysis

An 30
V 20
10 0
-10 -20 -30 -40 -50
0
Cn
n 0.4

-23

-24

20

40

-24.25

-24.277

-24.5

60

80

V
t

100

120

140

n’=0

0.3
0.2 V’=0
0.1

0

-0.1 -60 -50 -40 -30 -20 -10 0 10 20 30 V
V

69

Bn 0.6 0.5
n 0.4
0.3 0.2 0.1
0 -0.1 -0.2
-60 -50 -40 -30 -20 -10 0 10 20 30
VV

Dn
n 0.4

n’=0

0.3
V’=0
0.2

0.1

0

-0.1 -60 -50 -40 -30 -20 -10 0 10 20 30
VV

Figure 4.5. Dynamics of the ML model with saddle-node dynamics. A) The delay to spike can be arbitrary but the spike height is invariant. B) and C) Phase-plane explaining A). The ﬁxed points N, S, and U are, respectively a stable node (the rest state), a saddle-point, and an unstable node. Σ± are the stable (−) and unstable (+) manifolds of S. D) There exists a stable limit cycle for suﬃcient current; the nullclines are also shown.

Saddle-homoclinic bifurcation
By changing the rate of the potassium channel, φ, we can alter the dynamics of the model so that the SNIC is replaced by another type of global bifurcation; this is called a saddle-homoclinic bifurcation. In both types of bifurcations, the frequency of oscillations approach zero as the current approaches the bifurcation value. However, there are important diﬀerences.
Since φ only changes the rate of n, it has no eﬀect on the number and values of the ﬁxed points, only their stability. Figure 4.7 shows the bifurcation diagram for the model when φ is increased from 0.067 to 0.23. As before, the ﬁxed points are lost at a saddle-node bifurcation. The Hopf bifurcation on the upper branch occurs at a much lower value of current than in Figure 4.6 but the branch of periodic orbits is still subcritical. The main diﬀerence is that the stable branch of periodic orbits does not terminate on the saddle node as in Figure 4.6. Rather it terminates on an orbit that is homoclinic to one of the saddle points along the middle branch of

i i

i i

70

Chapter 4. Dynamics

A
VV
40

B
ω 30
25

20 SN1
0

20

H

15

-20

SN2

-40

-20

0

20

40

60

80

100

120

I* i

I

10
5
0 30 40 50 60 70 80 90 100 110 120
I

C
phi
φ
0.8
0.6
0.4

SN1 TB

SN2

0.2

H

0

-20

0

20

40

60

80

100

120

Ii

Figure 4.6. Bifurcation for the ML model with saddle-node dynamics. A) Voltage vs current showing saddle-nodes, SN1,2 and Hopf H bifurcations. B) Frequency as a function of current. C) Two-parameter bifurcation diagram showing the curves of Hopf and saddle-node bifurcations as the rate, φ, of the potassium channel varies. The Hopf curve meets the left-most saddle-node curve at a double zero eigenvalue characterizing a Takens-Bogdanov bifurcation (TB).

A

B

C

20
V 10 0 -10 -20

20
V 10
0
-10

Hc

45
ω 40 35 30 25

20

-30

-20

15

-40

-30

10

-50 -40

5

-60

0

-10

0

10

20

30

40

50

25

30

35

40

45

50

33

34

35

36

37

38

39

40

41

I

I

I

Figure 4.7. Bifurcation for the ML model with increased φ. A) Voltage vs current. B) Zoom in of A) showing the homoclinic orbit (Hc). The vertical line at Iapp = 37 shows tristability. (C) Frequency versus current; note the much steeper approach to I∗ than in Figure 4.6.

ﬁxed points. Like the SNIC, this homoclinic orbit has an inﬁnite period. However, the periods of the limit cycles approach inﬁnity quite diﬀerently than before. In exercise ??? you are asked to show that the period scales as

T

∼

ln

Iapp

1 − IHc

where IHc is the current at which there is a saddle-homoclinic orbit. The frequency T −1 approaches zero much more rapidly than the SNIC case.
Figure 4.8 shows the phase plane for the membrane model near the critical current, IHc. There are three ﬁxed points. The lower left ﬁxed point is always stable, the middle point is a saddle, and the upper right point is an unstable spiral. For Iapp < IHc (panel A), the right branch of the unstable manifold of the saddle wraps around and returns to the stable ﬁxed point. The upper branch of the

i i

i i

4.4. Bifurcation analysis

71

A 0.5

0.4

0.3
n
0.2

0.1

0

-0.1

-40

-30

V -20

-10

0

10

20

B 0.5

0.4

0.3
n
0.2

0.1

0

-0.1

-40

-30

-20

-10

0

10

20

V

C 0.5

0.4

0.3
n
0.2

0.1
0
-0.1 -40

***** ** **

-30

-20

-10

0

V

10

20

Figure 4.8. Phaseplane for the ML system near the homoclinic bifurcation showing A) Iapp < IHc, B) Iapp ≈ IHc and C) Iapp > IHc. . Perturbations from rest that lie in the starred region shown in C) will approach the stable limit cycles.

stable manifold wraps around the spiral (in negative time). Note that the unstable manifold passes on the outside of the stable manifold. In Figure 4.8B, the stable and unstable manifolds meet and form the homoclinic orbit at Iapp = IHc. For Iapp > IHc, the unstable manifold passes inside the stable manifold and wraps around a stable limit cycle. Thus, this model has a regime of bistability where there is a stable ﬁxed point and a stable periodic orbit. Unlike the bistability in the Hopf case, the stable limit cycle does not surround the stable ﬁxed point. In the Hopf case, an unstable periodic orbit acted to separate the stable ﬁxed point from the stable limit cycle. In the present set of parameters, the stable manifold of the middle ﬁxed point separates the two stable states. In order to get onto the limit cycle, it is necessary to perturb the potential into the starred region in Figure 4.8C. Consider a brief current pulse which perturbs the voltage. If this pulse is weak, the system returns to rest. If it is very strong and passes the starred region, then the model will generate a single spike and return to rest. However, for intermediate stimuli (like the baby bear’s porridge – just right), the system will settle onto the stable limit cycle.
Finally, we look closely at the bifurcation diagram, Figure 4.7B. Near Iapp = 38, there are two stable ﬁxed points as well as a stable limit cycle. Thus, the model is actually “tristable”. The reader is urged to explore this aspect of the model more carefully in exercise *

Class I and class II
The ML model illustrates several important features of neuronal ﬁring. Three different mechanisms for switching from rest to repetitive ﬁring were illustrated. In particular, the most common mechanisms are through the Hopf and SNIC bifurcations. In the 1940’s Hodgkin classiﬁed three types of axons according to their properties. He called these Class I-II; with Class III being somewhere in between the ﬁrst two classes which we describe:

i i

i i

72

Chapter 4. Dynamics

Class I. Axons have sharp thresholds, can have long latency to ﬁring, and can ﬁre at arbitrarily low frequencies;
Class II. Axons have variable thresholds, short latency, and a positive minimal frequency.
From this description, we can see that these two classes fall neatly into the dynamics of the SNIC and the Hopf bifurcations, respectively. Rinzel and Ermentrout (1989) were the ﬁrst to note this connection. Now there are many papers which classify membrane properties as Class I or Class II and mean SNIC and Hopf respectively.
Tateno et al (2004) have characterized regular spiking (RS) neurons (excitatory) and fast spike (FS) neurons (inhibitory) in rat somatosensory cortex using this classiﬁcation. (Note that many authors call the dynamics Type I,II instead of Class I,II.) Figure 4.9 show some properties of cortical neurons. RS neurons appear to be Class I; the minimal frequency is close to zero. Note that RS neurons do not seem to have subthreshold oscillations (not shown). In contrast, FS neurons appear to be Class II; they have a minimum frequency of around 15 Hz. They also exhibit subthreshold oscillations. Near the critical current, they seem to switch back and forth between rest and ﬁring. This suggests the possibility of a narrow range of bistability consistent with the subcritical Hopf bifurcation.
T. Tateno, A. Harsch, and H. P. C. Robinson Threshold Firing FrequencyCurrent Relationships of Neurons in Rat Somatosensory Cortex: Type 1 and Type 2 Dynamics J Neurophysiol, Oct 2004; 92: 2283 - 2294.

4.5 Bifurcation analysis of the Hodgkin-Huxley equations
We now consider the spaced-clamped Hodgkin-Huxley model (2.43). In the previous chapter, we discussed the response to a brief current pulse. Figure 2.13 shows the eﬀects of a brief current pulse at amplitudes ranging from 1-5 µA/cm2. There appears to be a very sharp transition between an action potential and a minimal response. A constant current can induce the membrane to oscillate repeatedly as seen in the right panel of Figure 2.13.
We can get a more global picture of the dynamics of the equations by looking at a bifurcation diagram. Figure 4.10A shows the behavior of the voltage as a function of the applied current, Iapp. Lines represent ﬁxed points and circles represent periodic orbits. The frequency of the oscillations is shown in Figure 4.10C. The range is from about 40 Hz to about 150 Hz.
Note that there is a unique equilibrium point for all Iapp. At Iapp ≈ 10, the rest state loses stability at a Hopf bifurcation. At a large value of Iapp ≈ 154 there is another Hopf bifurcation. From the ﬁgure, it seems clear that the bifurcation is subcritical at the low current and supercritical at the high current. At the lower Hopf bifurcation, there is a subcritical branch of unstable periodic orbits. Hence, the transition from resting behavior to oscillations is Class II.
Figure 4.10B shows a blowup of the region near this Hopf bifurcation. Evidently, there are values of Iapp near 7.88 where there are four diﬀerent limit cycles.

i i

i i

4.5. Bifurcation analysis of the Hodgkin-Huxley equations

73

A

B

C

Figure 4.9. From Tateno etal; Properties of RS and FS neurons in cortex. A. Firing rate versus current for RS neurons. (Note that these cells have spikefrequency adaptation so that the inter-spike interval (ISI) is not constant. Thus, this shows the ISI after several spikes as well as the steady-state.) (B) Same as A for FS neurons. (C) Mixture of spikes and subthreshold oscillations near the critical current for FS.

i i

i i

74

AV 40
20
0
-20
-40
-60
-80 0
C
Frequency

50

100

150

200

i0

150

100

50

0

0

20

40

60

80

100

120

140

i0

Chapter 4. Dynamics

BV
40

20

0

-20

-40

-60

-80

6

7

8

9

10

11

12

i0

Dn
0.8

0.7

0.6

0.5

0.4

0.3

-80

-60

-40

-20

0

20

40

V

Figure 4.10. Bifurcation diagram for the HH model. A) V versus Iapp, the applied current; B) Expanded view of A); C) Frequency as a function of current; D) (V, n)−phase plane projection showing 4 diﬀerent limit cycles.

Figure 4.10D shows the projection of these limit cycles in the (V, n)−plane. Guckenheimer and Oliva (2002) provide convincing numerical evidence for chaotic behavior near this lower current value. The chaos that they compute is unstable so that it will not be observed in simulations. For large values of current, the rest-state stabilizes again through a supercritical Hopf bifurcation.
The apparent fact that there is a unique equilibrium point for all Iapp has never been rigorously proved for the HH equations. At equilibrium, each of the gating variables m, n and h can be written as a function of V so that we ﬁnd:

Iapp = g¯L(V − EL) + g¯Nam3∞(V )h∞(V )(V − ENa) +g¯Kn4∞(V )(V − EK ) ≡ F (V ).

(4.3)

The statement that there is a unique equilibrium is a statement that F (V ) is monotone for all V . Since this monotonicity depends very much on the details of the steady-state gate functions, it is not likely that any general theory of the monotonicity of F exists. We leave it as an exercise to show that if |V | is large enough, then there is a unique value of Iapp for which there exists an equilibrium.
If we assume that the function F (V ) is monotone, then it is possible to rigorously prove the existence of the two Hopf bifurcation points. Troy (1979) proved under fairly general assumptions that there are two values of the current Iapp at which the rest state loses stability at a pair of imaginary eigenvalues. Thus, from the Hopf bifurcation theorem, he was able to conclude that there is a branch of periodic solutions emerging from the ﬁxed points. A rigorous proof of the direction

i i

i i

4.5. Bifurcation analysis of the Hodgkin-Huxley equations

75

of the bifurcation remains an open question. Troy’s proof relies on an analysis of the linearized equations and application
of Hurwitz’ criteria to the characteristic polynomial. We can sketch out some of the details. Troy’s assumption that the function F (V ) is monotone implies that for each Iapp, there is a unique V that satisﬁes (4.3). Furthermore, this implies that there are never any zero eigenvalues of the linear system (see exercise ***). The linearization about the ﬁxed point leads to a matrix with a very special form. It is zero except along the diagonal, across the ﬁrst row, and down the ﬁrst column:

 −FV

M

=

 



m′∞/τm h′∞/τh

n′∞/τn

−Fm −1/τm
0
0

−Fh 0
−1/τh 0

−Fn 

0 0

 

.



−1/τn

The characteristic polynomial for such matrices (which are called mammillary because they resemble a mammal with many suckling babies; here the voltage is the mother and the gates are the babies) is easy to compute and the result is a fourthorder polynomial of the form:

PM (λ) = λ4 + a3λ3 + a2λ2 + a1λ + a0.

The coeﬃcients are messy, but straightforward to compute. The Hopf bifurcation
occurs when there are imaginary roots. The Routh-Hurwitz criterion provides the
simplest test for this condition. (see Digression). For a 4th order polynomial, there will be a Hopf bifurcation if a0 > 0, a3 > 0, a3a2−a1 > 0, and R ≡ a3a2a1−a21−a23a0 vanishes. Thus, Troy uses assumptions on the shapes of the gating functions to prove
that there is a Hopf bifurcation by showing that the quantity R changes sign.

Digression. The Routh Hurwitz Criterion. Consider the polynomial:

P (λ) = λn + an−1λn−1 + . . . a1λ + a0.

(4.4)

The Routh-Hurwitz determinants provide a simple way to tell of the real parts of the roots of P are negative. We deﬁne an = 1 and aj = 0 for j > n or for j < 0. We will form a series of matrices containing the coeﬃcients aj:

H1 = an−1

H2 =

an−1 an−3

 an−1 H3 =  an−3
an−5

1 an−2
1 an−2 an−4

0 an−1  an−2

and so on up to Hn. Each matrix is square and the ﬁrst column contains every other coeﬃcient, an−1, an−3, . . . . The roots of P (λ) have negative real parts if an only if det Hj > 0 for j = 1, . . . , n. For example:
n = 1. a0 > 0

i i

i i

76

Chapter 4. Dynamics

n = 2. a0 > 0 and a1 > 0;
n = 3. a0 > 0, a2 > 0, a1a2 − a0 > 0. n = 4. a0 > 0,a3 > 0, a3a2 − a1 > 0, a3a2a1 − a21 − a23a0 > 0. We note the following:
• det Hn = a0det Hn−1 so that this means a0 > 0 is necessary. If a0 = 0 then there is a zero eigenvalue.
• If det Hn−1 = 0, a0 > 0 and det Hj > 0 for j < n − 1, then there are imaginary roots.
These two criteria allow us to determine where possible saddle-node (eigenvalue 0) and Hopf (imaginary eigenvalues) bifurcations occur. End digression.

4.6 Reduction of the HH model to a 2-variable model
We have seen that two-dimensional models, such as the Morris-Lecar equations, exhibit many important features of the more complicated Hodgkin-Huxley equations. The Morris-Lecar equations generate action potentials, there is a threshold for ﬁring and, depending on parameters, there are several mechanisms for the generation of oscillatory behavior. In this section, we shall describe two ways in which dynamical systems methods have been used to formally reduce the four-dimensional HodgkinHuxley model to a two-dimensional system of equations. Reduction methods will be very useful in later sections when we consider networks of neurons.
Rinzel (Federation Proceedings ??) developed a simple method based on two observations. The ﬁrst is that τm(V ), the voltage-dependent time constant for the gating variable m, is much smaller than both τh and τn. Because τm is small, m(t) is very close to m∞(V (t)). If we replace m by m∞(V ) in the voltage-equation, then this reduces the HH-model by one equation. The second observation, ﬁrst observed by Krinskii and Kokoz (1973), is that (n(t), h(t) lies nearly along a line n = b − rh where b and r are constants. Figure 4.11 shows these curves at three diﬀerent currents. The slope and the intercept depend somewhat on the current, but Rinzel ignored this. Hence, we replace n by b − rh in the voltage-equation and obtain the reduction to a two-dimensional model. We leave the analysis of this model as an exercise.
A common method for comparing parameters which have diﬀerent units is to render the model in terms of dimensionless variables. Kepler et al (1992) describe a method for comparing the time scales of all the gating variable. Each voltagedependent gate x(t) satisﬁes an equation of the form
x′ = (x∞(V ) − x)/τx(V ).
The functions x∞(V ) are monotonic, so that they are invertible. Thus, Kepler et al introduce a new variable Vx for each gate, where x(t) = x∞(Vx(t)). They obtain an

i i

i i

