{"indexedPages":14,"totalPages":14,"version":"263","text":"IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 44, NO. 9, SEPTEMBER 1997\n\n867\n\nLocalization of Brain Electrical Activity via Linearly Constrained Minimum Variance Spatial Filtering\nBarry D. Van Veen,* Member, IEEE, Wim van Drongelen, Moshe Yuchtman, and Akifumi Suzuki\n\nAbstract— A spatial ﬁltering method for localizing sources of brain electrical activity from surface recordings is described and analyzed. The spatial ﬁlters are implemented as a weighted sum of the data recorded at different sites. The weights are chosen to minimize the ﬁlter output power subject to a linear constraint. The linear constraint forces the ﬁlter to pass brain electrical activity from a speciﬁed location, while the power minimization attenuates activity originating at other locations. The estimated output power as a function of location is normalized by the estimated noise power as a function of location to obtain a neural activity index map. Locations of source activity correspond to maxima in the neural activity index map. The method does not require any prior assumptions about the number of active sources of their geometry because it exploits the spatial covariance of the source electrical activity. This paper presents a development and analysis of the method and explores its sensitivity to deviations between actual and assumed data models. The effect on the algorithm of covariance matrix estimation, correlation between sources, and choice of reference is discussed. Simulated and measured data is used to illustrate the efﬁcacy of the approach.\nIndex Terms— Dipole localization, EEG localization, linearly constrained minimum variance ﬁlter, MEG localization, reference electrode, spatial ﬁltering.\nI. INTRODUCTION\nIN current clinical practice, neural activity in the brain is often recorded from scalp electrodes. The ongoing electroencephalogram and the potentials evoked by stimulation reﬂect activity from groups of neurons located in the head. Finding the sources responsible for generating this activity is a central issue in neurophysiology. Knowledge of the anatomical correlate of recorded activity is essential for diagnosis and treatment. Currently, more detailed anatomical information about abnormally active areas is obtained by implanting depth electrodes in several locations. Clinically and experimentally, one would like to avoid recording inside neural tissue, because the technique is invasive, delicate, and time consuming. Moreover, one cannot have depth electrodes at all potentially active sites, so one can overlook areas of interest.\nThese reasons have motivated many studies that attempt to formalize a relationship between electromagnetic activity\nManuscript received January 17, 1996; revised May 1, 1997. Asterisk indicates corresponding author.\n*B. D. Van Veen is with the Department of Electrical and Computer Engineering, University of Wisconsin, 1415 Engineering Drive, Madison, WI 53706 USA (e-mail: vanveen@engr.wisc.edu).\nW. van Drongelen and M. Yuchtman are with Nicolet Biomedical, Inc., Madison, WI 53744-4451 USA.\nA. Suzuki is with the Department of Surgical Neurology, Research Institute for Brain and Bloodvessels, Akita 010 Japan.\nPublisher Item Identiﬁer S 0018-9294(97)06114-4.\n\nin the head and external recordings of the generated ﬁeld [1]–[15]. These models represent underlying neural activity by either a charge or current dipole. Starting from a known activity pattern in the brain, one can calculate the electromagnetic ﬁeld generated outside the brain in a unique fashion. This so-called forward solution depends on a number of parameters related to the geometry of the anatomical model and the electromagnetic properties of the different tissues. Some studies use a spherical model describing the head [1], [2], [5]–[8], while others reﬁne the geometric representation by using ﬁnite element or boundary element methods [3], [4], [9], [13]. The experimental and clinical problem, however, is the inverse problem: the ﬁeld is sampled at different sensor locations and the underlying activity pattern must be determined. A given set of measurements cannot generate a unique solution for the activities inside the head. To obtain a single inverse solution for a given recording, additional constraints are introduced. A problem common to all methods is determining the number of active areas that contribute to the signal studied. Some authors assume a single generator at every time instant (see e.g., [1]); others use a linear decomposition of a recorded interval as a tool to estimate the number of active sites (see e.g., [8]).\nIn this paper, we develop a localization method based on the principles of spatial ﬁltering. Spatial ﬁlters are designed that pass brain electrical activity from a speciﬁed location while attenuating activity originating at other locations. The power at the output of a spatial ﬁlter is an estimate of the neural power originating within the spatial passband of the ﬁlter. A map of neural power as a function of location is obtained by designing multiple spatial ﬁlters, each with a different passband, and depicting output power as a function of passband location. This spatial ﬁltering approach represents an adaptation of the multiple window minimum variance spectrum estimation method proposed by Liu and Van Veen [16] and falls within the general category of linearly constrained minimum variance (LCMV) ﬁltering. Spatial ﬁltering or “beamforming” using LCMV methods has been widely applied in radar and sonar [17]. Early work on LCMV beamforming includes [18] and [19].\nThe map of neural power would appear to provide a useful metric for source localization by associating sources with regions of large neural power. However, we show that noise introduces a spatially non uniform component to the neural power map that depends on the measurement sites. Hence, noise may cause false detection of sources or missed detection of actual sources in the neural power map. This problem is\n\n0018–9294/97$10.00 © 1997 IEEE\n\nAuthorized licensed use limited to: Hong Kong Baptist University. Downloaded on December 06,2023 at 03:32:49 UTC from IEEE Xplore. Restrictions apply.\n\n868\n\nIEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 44, NO. 9, SEPTEMBER 1997\n\nmitigated by normalizing the neural power map by an estimate of the noise power map to obtain a neural activity index. Localization is accomplished by identifying local maxima in the neural activity index as sources.\nThe present approach does not require any prior assumptions about the number or spatial distribution of active sources. Indeed, under the appropriate conditions both the number and locations of sources can be determined. Distributed sources such as dipole sheets can also be identiﬁed given adequate signal-to-noise ratio (SNR). Prior source information is not required because the localization is performed using the spatial covariance matrix of the surface data. Guidelines for estimating the spatial covariance matrix from measured data are discussed.\nTheoretical considerations in applying the LCMV method to neurophysiology were previously reported in [11] and [20]. Related ideas have also been reported in the literature. An application of spatial ﬁltering to monitoring speciﬁc regions of the brain has been discussed by Spencer et al. [21]. Dale and Sereno [12] require estimates of dipole variance needed in their constrained linear approach to solving the inverse problem. The method used to estimate the dipole variance is based on the MUSIC algorithm [10] and is similar in certain aspects to the approach taken here. Description of the similarities and differences is provided in the discussion section. van Drongelen et al. [22] use the LCMV localization technique with simulated and measured electrophysiological data in order to explore the method’s resolving power and ability to detect multiple sources. In the present paper, we provide a detailed exposition of the LCMV method and study the sensitivity of the approach to deviation between the actual and assumed data models.\n\nproblem. That is, the ﬁrst column of\n\nis the potential at\n\nthe electrodes due to a dipole source at location having\n\nunity moment in the direction and zero moment in\n\nand directions. Similarly, the second and third columns\n\nrepresent the potential due to sources with unity moment in\n\nand directions, respectively. Note that this model for\n\nthe data applies to electric, magnetic, or combined electric\n\nand magnetic measurements. Only the elements of\n\ndepend on the particular sensing modality. In a physical sense,\n\nrepresents the material and geometrical properties of the\n\nmedium in which the sources are submerged.\n\nThe medium is linear so the potential at the scalp is the\n\nsuperposition of the potentials from many active neurons.\n\nSuppose is composed of the potentials due to active dipole\n\nsources at locations\n\nand noise. Then\n\n(1)\n\nwhere\n\nis the dipole moment at location and is\n\nthe measurement noise. For very large the sum may be\n\nrepresented as an integral over the volume containing possible\n\nsources. Note that does not contain any temporal information\n\nsince it is obtained by sampling all electrodes at a single time\n\ninstant. It represents the spatial distribution of potential at the\n\nmeasurement sites at the sampling time.\n\nThe electrical activity of an individual neuron is assumed\n\nto be a random process inﬂuenced by external inputs to the\n\nneuron. Hence, we model the dipole moment as a random\n\nquantity and describe its behavior in terms of mean and\n\ncovariance. Speciﬁcally, we denote the moment mean vector\n\n, and covariance matrix\n\nas\n\nII. DATA MODEL\n\nThe LCMV approach is based on source and head models\n\nthat relate the underlying neural activity to the distribution of\n\npotential (electric, magnetic, or both) measured at the surface.\n\nThis section develops these models and relates them to the\n\nﬁrst- and second-order statistics of the data. For notation,\n\nlower- and upper-case boldface symbols represent vector and\n\nmatrix quantities, respectively. Superscript denotes matrix\n\ntranspose and superscript matrix inverse. The trace of the\n\nmatrix is written as tr .\n\nThe current dipole is a key component of our model relating\n\nthe surface measurements to the underlying neural activity. An\n\nindividual active neuron is reasonably modeled as a current\n\ndipole. Active areas in the cortex can be modeled by an\n\nequivalent electrical dipole. The relationship between dipole\n\nmodels and the surface recordings is obtained as follows.\n\nLet be an\n\nvector composed of the potentials\n\nmeasured at the electrode sites at a given instant in\n\ntime associated with a single dipole source. If this source\n\nhas location represented by the 3 1 vector , then\n\nwhere the elements of the 3 1 vector\n\nare the , and components of the dipole moment at\n\nthe instant in time is measured and the columns of the\n\ntransfer matrix\n\nrepresent solutions to the forward\n\n(2) (3)\n\nAssuming the noise is zero mean (\n\n) with covariance\n\nmatrix and that the moments associated with different\n\ndipoles are uncorrelated, that is\n\n(4)\n\nthen\n\n(5)\n\n(6)\n\nrepresent the mean and the covariance matrix of the observed data vector , respectively.\nThe variance associated with a particular source is a measure of the strength of the source and is deﬁned as the sum of the variance of each component of the dipole moment or\n\nVar\n\ntr\n\n(7)\n\nAuthorized licensed use limited to: Hong Kong Baptist University. Downloaded on December 06,2023 at 03:32:49 UTC from IEEE Xplore. Restrictions apply.\n\nVAN VEEN et al.: LOCALIZATION OF BRAIN ELECTRICAL ACTIVITY\n\n869\n\nWe estimate this variance by determining how much of the covariance matrix is consistent with the transfer matrix for a given location.\nElectrical data is collected as a potential measured with respect to a reference electrode. Our experience indicates that the LCMV method is generally insensitive to the choice of reference electrode. This observation is based on obtaining virtually identical results when using the same data set but recomputing the potentials with respect to differing electrodes (see, e.g., Section V-B). However, it is straightforward to preprocess the data to guarantee that all results are independent of the reference electrode.\nThe effect of the reference is to add a constant, unknown potential to each electrode. This is expressed mathematically as follows. If and are potentials measured at the same set of electrodes with respect to different reference electrodes, then\n\non the basis of their spatial location. This concept completely parallels the more familiar temporal ﬁltering, where one discriminates between signals based on their temporal frequency content. Hence, a “narrowband” spatial ﬁlter passes signals originating from a small “passband” volume while attenuating those originating from other locations. Temporal ﬁltering involves operating on time samples of a signal; spatial ﬁltering involves processing spatial samples of a signal. In the present application, the spatial samples are elements of the data vector and the spatial ﬁlter is implemented as a weighted combination of these samples. The goal is to design a bank of spatial ﬁlters where each ﬁlter passes signals originating from a speciﬁed location within the brain while attenuating signals from other locations. A display of the variance or power at the output of each ﬁlter as a function of the ﬁlter’s spatial “passband” location provides an estimate of the distribution of activity within the brain.\n\n(8)\nwhere is a vector of all ones and is the unknown difference in potential between the two reference electrodes. The effect of the reference is eliminated if we apply a transformation to the data that is orthogonal to the vector. Deﬁne an by\nmatrix satisfying\n\nrank\n\n(9)\n\nThat is, the\n\nlinearly independent columns of all\n\nsum to zero. Such a is easily constructed using a matrix\n\northogonalization procedure, such as the QR decomposition.\n\nNote that (9) implies\n\n. Hence, reference free\n\ndata is obtained as\n\nA. Filter Design\n\nThe signal at each location in the brain consists of the three\n\ncomponent dipole moment. Hence, we construct three spatial\n\nﬁlters for each location, one for each component of the dipole\n\nmoment. Deﬁne the spatial ﬁlter for the narrowband volume\n\nelement centered on location as the\n\nmatrix\n\nand let the three component ﬁlter output be the inner product\n\nof\n\nand\n\n(11)\n\nAn ideal narrowband spatial ﬁlter satisﬁes\n\n(12)\n\n(10)\n\nSubstitution of (1) into (10) indicates that the transfer\n\nmatrices\n\nmust also be modiﬁed by the transformation\n\n. Speciﬁcally,\n\n. A second consequence of\n\nremoving the reference is the loss of one degree of freedom,\n\nas manifest in the reduction from dimensional data vectors\n\nto\n\ndimensional data vectors . This loss is a result\n\nof ignoring all components of the data that lie in the one\n\ndimensional space spanned by . Components in this space\n\nare of marginal utility anyway, since one can never determine\n\nwhether they are associated with an actual source or whether\n\nthey are a consequence of the reference choice. Furthermore,\n\nfor modest values of ( ) the loss of this single degree of\n\nfreedom does not appear to have a signiﬁcant impact on the\n\npotential performance of the LCMV method. The derivation\n\nand discussion that follows is applicable whether or not the\n\ndata is preprocessed to be reference free. For ease of exposition\n\nwe use and\n\n.\n\nIII. LINEARLY CONSTRAINED MINIMUM VARIANCE LOCALIZATION\nThe LCMV approach is based on the concept of spatial ﬁltering. Spatial ﬁltering refers to discrimination of signals\n\nwhere represents the volume of the brain. If (12) is satisﬁed,\n\nthen in the absence of noise (\n\n) the ﬁlter output is\n\n, the dipole moment at the location of interest.\n\nAs in temporal ﬁltering, it is generally impossible to have\n\ncomplete attenuation in the stop band. Unit response in the\n\npass band is insured by requiring\n\n(13)\n\nZero response at any point in the stop band implies must also satisfy\n\n(14)\n\nProvided\n\nand the columns of\n\nand\n\nare linearly independent, it is mathematically possible to\n\nsimultaneously satisfy (13) and (14). However, if\n\nand\n\nare very similar (nearly linearly dependent columns),\n\nthen\n\nwill have a large norm, resulting in large gain\n\nto noise and to sources at locations other than or .\n\nFurthermore, each column of\n\nonly has degrees of\n\nfreedom. The pass band constraint (13) uses up three of these,\n\nand each independent null uses an additional three so at most\n\none could achieve simultaneous nulls at\n\nlocations\n\nhaving linearly independent transfer matrices\n\n.\n\nAuthorized licensed use limited to: Hong Kong Baptist University. Downloaded on December 06,2023 at 03:32:49 UTC from IEEE Xplore. Restrictions apply.\n\n870\n\nIEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 44, NO. 9, SEPTEMBER 1997\n\nGiven the limitations on the stopband attenuation, one\n\nnaturally asks how to design a ﬁlter that is optimal in some\n\nsense. The LCMV approach offers a guiding philosophy for\n\ndesigning an optimal ﬁlter. The idea is to ﬁnd a\n\nthat\n\nminimizes the variance at the ﬁlter output while satisfying\n\nthe linear response constraint (13). Hence, the name linearly\n\nconstrained minimum variance. The constraints insure that the\n\nsignals of interest are passed by the ﬁlter. Minimization of\n\nvariance optimally allocates the stop band response of the\n\nﬁlter to minimize the contribution to the ﬁlter output due to\n\nsignals in the stop band. This strategy only forces the stopband\n\nresponse to be small at a location if there is signiﬁcant\n\nenergy originating from .\n\nThe LCMV problem is posed mathematically as\n\ntr\n\nsubject to\n\n(15)\n\nAlternatively, substituting for , (15) is expressed as\n\ntr\n\nsubject to\n\n(16)\n\nThe solution to (16) may be obtained using the methods of Lagrange multipliers and completing the square. Let be a 3 3 matrix of Lagrange multipliers. The cost function in (16) is augmented with the inner product of the Lagrange multipliers and the constraint to obtain the Lagrangian\n\ntr\n\n(17)\n\nwhere the arguments ( ) and ( ) are omitted for clarity. Noting that tr tr for any square matrix , we rewrite (17) as\n\ntr (18)\nIt is easy to verify that (18) can be expressed as the perfect square in\n\ntr (19)\n\nOnly the ﬁrst term in the brackets is a function of matrix is positive deﬁnite so the minimum of attained by setting the ﬁrst term to zero, that is\n\n. The is\n\n(20)\n\nThe Lagrange multiplier matrix is now obtained by substi-\n\ntuting in the constraint\n\nto obtain\n\n(21)\n\nor\n\n(22)\n\nSubstituting (22) into (20) yields the solution (23)\n\nB. LCMV Localization\nUsing (23) in (11) gives an estimate of the moment at location . The estimated variance or strength of the activity at is the value of the cost function in (15) and (16) at the minimum. After some algebra we obtain\n\nVar\n\ntr\n\n(24)\n\nTo perform localization, we estimate the variance or strength as a function of location within the volume of the brain. This is accomplished by evaluating (24) as a function of . Regions of large variance presumably have substantial neural activity, while regions with small variance can be considered inactive. We refer to (24) as the estimated “spatial spectrum” of the neural activity. It corresponds to the multiple window minimum variance spectrum estimator described in [16].\nThis approach does not assume that all sources of activity in the brain are represented by equivalent dipoles, but rather that any source can be explained as a weighted combination of dipoles. Hence, the geometry of sources is not restricted to points, but may be distributed in nature. The source distribution is directly represented by the distribution of signiﬁcant variance values. Furthermore, this approach does not require speciﬁcation or determination of the number of dipole sources to ﬁt to the data. Note that anatomical information is easily included by only evaluating (24) at locations corresponding to physically realistic source locations.\nThe resolution of detail in the spatial spectrum is ultimately limited by the minimum “width” or spatial extent of the ﬁlter’s passband. Two distinct sources that are located within the passband of a particular ﬁlter cannot be resolved. The spatial extent of the passband depends on the transfer matrices\n, which in turn depend on the number of electrodes, their distribution, and source location. Simulations indicate that superﬁcial activity can be resolved with much greater detail than deep activity. The resolution also depends on the SNR associated with the feature of interest. This is a consequence of the variance minimization procedure used to determine the spatial ﬁlters. As SNR increases, resolution increases. Note that since our analysis is covariance based, SNR is deﬁned as the variance of the source divided by the variance of the noise. This is in contrast to the more usual notion of SNR employed in electroencephalogram (EEG) and evoked potential (EP) analysis, the ratio of the source amplitude to the noise standard deviation.\n\nC. The Neural Activity Index and Noise\n\nThe SNR of measured data is often small, so the noise com-\n\nprises a signiﬁcant component of the estimated neural activity\n\nobtained using (24). Noise that appears spatially concentrated\n\nor non uniformly distributed in the spatial spectrum will\n\ninterfere with localization of actual neural sources. Consider\n\nthe estimated spatial spectrum assuming\n\nis due entirely\n\nAuthorized licensed use limited to: Hong Kong Baptist University. Downloaded on December 06,2023 at 03:32:49 UTC from IEEE Xplore. Restrictions apply.\n\nVAN VEEN et al.: LOCALIZATION OF BRAIN ELECTRICAL ACTIVITY\n\n871\n\nto uncorrelated noise,\n\n. In this case, (24) simpliﬁes to\n\nVar\n\ntr\n\n(25)\n\nHence, the noise spatial spectrum depends on the transfer\n\nmatrices\n\n. Note that for locations far from any\n\nelectrode, the elements of\n\nare generally quite small,\n\nso\n\nwill have large elements, resulting in\n\na large value for Var . In contrast, for locations close\n\nto an electrode,\n\nwill have several large elements and\n\nwill have generally have small elements,\n\nresulting in a small value for Var . Because deep source\n\nlocations are relatively far from electrodes, noise generally has\n\na dome shaped spatial spectrum with the peak of the dome\n\ncentered at the deepest locations. This dome may be warped\n\nsigniﬁcantly if the electrodes are distributed nonuniformly, or\n\nif the geometry of the head is assumed to be very nonuniform.\n\nThe LCMV spatial spectrum is not linear, that is, the spatial\n\nspectrum due to a sum of signals is not the sum of the\n\nindividual spatial spectra. This is a consequence of the inverses in (24). However, application of the matrix inversion lemma1\n\nto (6) and substitution into (24) indicates that (24) always\n\ncontains an additive noise component of the form\n\nD. Correlated Sources Recall that the moments associated with distinct dipoles\nwere assumed to be uncorrelated [see (4)]. The presence of correlation between distinct sources can lead to reduction of the estimated variance for the sources that are correlated.\nLetting (28)\nbe the cross covariance between sources at and , the output variance at location is given as tr\ntr\n\ntr\n\n(26)\n\nThis corresponds to the noise spatial spectrum in the absence of other signals. Due to the relatively low SNR’s associated with typical data, the noise spatial spectrum may obscure the spatial spectrum of the neural activity of interest. This problem is reduced by normalizing the estimated spatial spectrum of the data by the estimated noise spatial spectrum to obtain the normalized estimate\n\ntr\n\nVar\n\n(27)\n\ntr\n\nWe term this estimate the neural activity index.\n\nThe numerator of (27) is an estimate of the source plus\n\nnoise variance at and the denominator is an estimate of\n\nthe noise variance at ; hence, the neural activity index may\n\nbe interpreted as an estimate of the source to noise variance\n\nas a function of location. The normalization is a function of\n\nlocation so the relative levels of estimated neural activity at\n\ndifferent locations is changed. In principle, the absolute level\n\ncan still be determined by reversing the normalization after\n\nspeciﬁc features are identiﬁed.\n\nThe neural activity index requires knowledge the noise\n\ncovariance matrix . may be estimated from data that is\n\nknown to be source free, such as pre stimulus data in a EP’s\n\nexperiment. Alternatively, if the noise is assumed uncorrelated\n\nbetween channels, then\n\n. Note that the absolute level of\n\nthe noise is not required, it is only the shape or form of the\n\nnoise covariance that is needed. Changing the absolute level\n\nmodiﬁes the entire estimate by a common constant.\n\nA B 1 The matrix inversion lemma states that if and are two positive\n\n2 A = B CDC D deﬁnite M M matrices related by\n\n+\n\nT , where is\n\nA B 0 B C D 2 C B C C C B 2 an0ot1he=r pos0it1ive\n\n0 0 deﬁnite N N 1 ( 1+\n\nmTatrix0a1nd)01 is Tan\n\n0M 1:\n\nN matrix, then\n\n(29)\n\nHere, we have used\n\nto simplify (29).\n\nThe cross terms in the second through ﬁfth lines on the right-\n\nhand side of (29) are not guaranteed to be positive for all\n\n. Recall that the LCMV criterion chooses a\n\nto minimize (29). The minimum is generally obtained with a\n\nthat would make the cross terms in the second through\n\nﬁfth lines negative. If this occurs, then the estimated variance\n\nof the source at tr\n\n, is signiﬁcantly\n\nless than its true value, tr\n\n. The spatial ﬁlter exploits\n\nthe correlation between sources to minimize output variance\n\nby canceling the correlated portion of the source of interest.\n\nCorrelated source cancellation is a phenomenon that is well\n\nknown in adaptive beamforming applications of the LCMV\n\nmethod for radar and sonar [23].\n\nPerfect correlation between spatially distinct sources in the\n\nbrain is unlikely, although partial correlation is expected in\n\ncertain situations, such as when several brain areas react to\n\nan external stimulus or become activated by a common third\n\nactive area. We explore the performance of the LCMV method\n\nin the presence of correlated source activity in the simulation\n\nsection. The results indicate that the method is robust to\n\nmoderate levels of correlation between sources.\n\nIV. ESTIMATING THE COVARIANCE MATRIX\n\nThe spatial spectrum estimate (24) and neural activity index\n\n(27) require knowledge of the data covariance matrix\n\n.\n\nAuthorized licensed use limited to: Hong Kong Baptist University. Downloaded on December 06,2023 at 03:32:49 UTC from IEEE Xplore. Restrictions apply.\n\n872\n\nIEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 44, NO. 9, SEPTEMBER 1997\n\nIn practice,\n\nis unknown and must be estimated from the\n\navailable data. One estimate is the sample covariance matrix\n\n(30)\n\nwhere\n\n(31)\n\nis the sample mean and\n\nare observations\n\nof the phenomena to be localized. Note that these observations\n\nmust all correspond to the same underlying spatial spectrum,\n\nthat is, the data must be wide sense stationary. If the data set\n\ncontains observations associated with different spatial spectra,\n\nthe estimated spatial spectrum derived using the covariance\n\nestimate (30) will correspond to a mixture of the underlying\n\nspatial spectra.\n\nThe number of observations must at minimum exceed\n\nthe number of elements in each data vector, , for\n\nto\n\nbe nonsingular. Since\n\nis constructed from random data,\n\nit is a random quantity. Randomness in\n\nwill introduce\n\nrandomness into the estimated spatial spectrum. Excessive\n\nrandomness may obscure features of interest or result in false\n\nrecognition of nonexistent sources. This randomness decreases\n\nas increases. Statistical analyzes assuming independent\n\nGaussian distributed observations for related problems [16],\n\n[24] have shown that for a given true covariance matrix the\n\nratio of to determines the randomness in the estimated\n\nspatial spectrum. A common rule of thumb in such problems is\n\nto choose several times as large as . Hence, if\n\nelectrodes are used, then on the order of 300–400 independent\n\nobservations should be used to construct\n\nThis guideline may be difﬁcult to satisfy in some appli-\n\ncations. For example, in some patients it may be difﬁcult to\n\nidentify several hundred epileptic spikes. An alternative is to\n\nuse multiple observations or samples in time from each single\n\nevent, such as a spike, to construct\n\n. In this approach\n\nthe variability used for localization is due in part to the time\n\nvariation of the event. If multiple samples in time are used\n\nto construct the covariance matrix, then one must assume that\n\nthe data is wide sense stationary over the time interval, that\n\nis, that all data is associated with the same underlying spatial\n\nspectrum. A second concern with using multiple time samples\n\nis possible reductions in the degree of statistical independence\n\nbetween adjacent observations. Any statistical dependence will\n\nincrease the number of observations needed to maintain com-\n\nparable levels of randomness in the covariance matrix estimate.\n\nIf multiple observations of an event are available and the\n\ndata is temporally stationary, then one can ask whether the best\n\nperformance is obtained using time samples of an averaged\n\nevent or using time samples of all observations to estimate\n\nthe covariance matrix. The answer to this question is complex\n\nand in general requires complete statistical characterization of\n\nneural activity. A signiﬁcant factor is the relative variability\n\nof the noise to that of signal or sources over both time and\n\nfrom observation to observation. Averaging procedures reduce\n\nboth the variance associated with sources and the variance\n\nassociated with the noise. If the decrease in noise variance obtained by averaging is greater than the decrease in signal variance, then averaging is advantageous. For example, if the signal variability is primarily over time and not from one observation to another, then at low SNR averaging improves performance since it reduces the noise variability but does not decrease the temporal variability of the signal. A lesssigniﬁcant factor is the reduced the number of data vectors available for estimating the covariance matrix when averaging is used. With fewer data vectors the randomness in the covariance matrix estimate would tend to increase. However, averaging also changes the underlying true data covariance matrix by reducing the noise component, an effect that tends to reduce the randomness in the estimated covariance matrix.\nOur simulations demonstrate that the LCMV approach is effective when the primary variability is over time or from one observation to another (see Section V-D). The method for determining the estimated covariance matrix may be changed to exploit the underlying mechanism for signal and noise variability.\n\nV. EXAMPLES\n\nIntuitively, one might assume that the quality of the results\n\nobtained with the spatial ﬁltering approach is determined by\n\na number of factors including the SNR of the measurements,\n\nthe number and distribution of sensors, and in general the\n\nmatch between the assumptions in the model and reality. In\n\nthis section, we explore the results obtained by the spatial\n\nﬁltering method when some of the parameters are varied\n\nand certain assumptions are partially violated. To exclude the\n\neffects of model geometry and allow for quantitative control\n\nof certain variables, we study the effects in a number of\n\nsimulations where the measurements and the transfer function\n\nare generated with the same model. Other parameters such as\n\nsignal-to-noise, electrode positions, and number of electrodes\n\nare kept close to realistic values. The performance under\n\nrealistic conditions is evaluated using data collected from a\n\npatient with implanted depth electrodes.\n\nThe physical model for the head is a three-shell sphere. The\n\nouter shell models the skin, the middle shell represents the\n\nskull surrounding the centrally located brain tissue. The surface\n\npotential of the outer layer was calculated with the algorithm\n\ndescribed in [6]. With the exception of the simulations with\n\nvariable reference electrode, all simulations assume a reference\n\nat an inﬁnite distance with zero potential. The electrode\n\nlocations are determined by mapping standard 10–20 system\n\nplus extended positions [25] onto a spherical head. The outer\n\nradius of the assumed head is 8.25 cm; the middle and\n\nouter shells are 0.3-cm and 0.7-cm thick, respectively. The\n\nconductivity ratio between bone and soft tissue is 0.0125.\n\nThe transfer matrices\n\nare calculated for horizontally\n\nlocated cross sections at 1-cm intervals. In each of the sections,\n\ntransfer functions are determined on a uniform grid with\n\n0.25-cm spacing in each direction. The neural activity index\n\nlandscape and contour plots represent horizontal cross sections\n\nof the head. The vertical location of each cross section is\n\nrepresented by a position on a -axis, with increasing height\n\nAuthorized licensed use limited to: Hong Kong Baptist University. Downloaded on December 06,2023 at 03:32:49 UTC from IEEE Xplore. Restrictions apply.\n\nVAN VEEN et al.: LOCALIZATION OF BRAIN ELECTRICAL ACTIVITY\n\n873\n\ncorresponding to increasing values. Within each cross section the -axis is front–back with front positive and the\n-axis is right–left with left positive.\n\nA. Neural Activity Index and Electrode Distribution\n\nIn many laboratories, the distribution of the recording\n\nelectrodes is adapted to the assumed localization of the neural\n\ndysfunction. As described in Section III-C, the noise dis-\n\ntribution is related to electrode positions. For this reason,\n\nwe evaluate performance of the algorithm with different 32-\n\nchannel electrode montages: one with a homogeneous elec-\n\ntrode distribution and the other with all electrodes on one half\n\n(a)\n\nof the sphere. In the homogeneous distribution the selection\n\nis: Fp1, Fp2, AF3, AF4, F7, F3, Fz, F4, F8, FC5, FC1, FC2,\n\nFC6, T3, C3, Cz, C4, T4, CP5, CP1, CP2, CP6, T5, P3, Pz,\n\nP4, T6, PO3, PO4, O1, Oz, O2; the other distribution contains\n\nonly frontally located positions: Fp1, Fpz, Fp2, AF7, AF3,\n\nAFz, AF4, AF8, F7, F5, F3, F1, Fz, F2, F4, F6, F8, FT7,\n\nFC5, FC3, FC1, FCz, FC2, FC4, FC6, FT8, T9, T3, C5, C3,\n\nC1, Cz.\n\nThe noise spatial spectrum computed using (24) in the\n\nhorizontal section at the center of the sphere (\n\ncm) is\n\nshown in Fig. 1. The covariance matrix represents white noise\n\n. The result for the symmetrical electrode positions\n\n[Fig. 1(a)] shows a dome shaped noise distribution, while the\n\nfrontally located electrode distribution generates more noise\n\n(b)\n\nin the occipital area [Fig. 1(b)]. In cases with a low SNR this\n\nmontage dependent noise distribution presents a problem since\n\nit may obscure actual sources. For this reason, we normalize\n\nthe spatial spectrum by the noise spatial spectrum to obtain\n\nthe neural activity index (27). The neural activity indexes for\n\nboth montages are identical, and depicted in Fig. 1(c).\n\nB. Dependence on Reference Choice\n\nChoice of reference electrode is always an issue in clinical\n\nneurophysiology. One is most likely to detect activity standing\n\nout against the background when the signals are recorded with\n\na reference that is remote. If the reference is close to the\n\nactivity, the signal will appear in all recorded channels and\n\nprevent easy localization based on visual inspection.\n\nWe simulated several cases in which we evaluated spatial\n\nﬁlter output having a pair of sources separated by 3 cm at a\n\ndepth of 0.75 cm from the surface of the inner sphere and\n\nlocated in a horizontal section at\n\ncm. The SNR (vari-\n\nance) was set at 9.5. We evaluated three different situations: 1)\n\nreference at inﬁnity; 2) reference being the closest positioned\n\nelectrode; 3) using the most remotely located electrode as the\n\nreference. The homogeneous 32-channel montage described\n\nin the previous subsection was employed. The neural activity\n\nindex varied only slightly; the sources were detected in the\n\ncorrect locations in all three cases. In the different situations,\n\nthe maximum values of the neural activity index varied by\n\nonly 10%. The largest difference was found between the close\n\nreference and the two other situations; with the close reference\n\nresulting in a higher peak value. The landscapes of the neural\n\nactivity index plotted on a relative scale were very similar in\n\n(c)\nFig. 1. The relationship of electrode distribution to the noise spatial spec-\nXY trum. In (a) and (b), the noise spatial spectrum is depicted in the horizontal\ncross section ( plane) through the center of a spherical head model. In case (a) the electrodes are distributed homogeneously over the spherical surface. The resulting spatial spectrum is characterized by a dome shape. In (b), the electrodes were located in a set on one side. The maximum spatial spectrum is found on the side of the head opposite the electrode set. Electrode location dependent differences in the noise spatial spectrum are equalized by computing a neural activity index (27). The result of this normalization is shown in (c).\nall three cases. Minor differences in the landscape can only be detected by superimposing the plots.\nC. Correlated Sources\nWe previously noted that correlation between sources may lead to degraded algorithm performance. For this reason, we examined the effect of uncorrelated, partially correlated and completely correlated source activity in two different\n\nAuthorized licensed use limited to: Hong Kong Baptist University. Downloaded on December 06,2023 at 03:32:49 UTC from IEEE Xplore. Restrictions apply.\n\n874\n\nIEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 44, NO. 9, SEPTEMBER 1997\n\nsimulations, one with two sources having a small interdistance\n\nand another with two sources having a large interdistance. The\n\nsources are located in the inner sphere at\n\ncm: the close\n\nsources have\n\ncoordinates of 1.375, 6.375, and 1.625,\n\n6.375; the distant sources have\n\ncoordinates of 1.375,\n\n6.375, and 1.375, 6.375. The correlation between the sources\n\nwas varied by assuming the dipole moments and were\n\nrelated by\n\n(32)\n\nHere, determines the degree of correlation between the\n\nsources and represents the uncorrelated component. We\n\nconsidered cases in which the sources are uncorrelated (\n\n), partially correlated (\n\n), and completely correlated\n\n(\n\n). The uncorrelated component was adjusted in each\n\ncase to obtain a SNR of ten.\n\nThe result of these simulations is shown in Fig. 2. The ﬁrst\n\ncolumn of landscape plots [Fig. 2(a)–(c)] shows the effects of\n\ncorrelation for the closely spaced dipoles. In the uncorrelated\n\ncase the two peaks can be distinguished clearly [Fig. 2(a)].\n\nWith moderate correlation increases the peaks start to merge\n\n[Fig. 2(b)] and in the fully correlated case [Fig. 2(c)] only\n\none peak located in the middle is evident. For remote sources\n\nthe result is somewhat different. The noncorrelated situation\n\ngenerates two distinct peaks in the landscape of the neural\n\nactivity index [Fig. 2(d)]. As illustrated in Fig. 2(e), partial\n\ncorrelation decreases the height of each peak, but still allows\n\ndetection of the dipole locations. Fully correlated distant\n\nsources have a tendency to cancel each other in the neural\n\nactivity index [see Fig. 2(f), note that the scale has changed].\n\nD. Covariance Matrix Estimation—Mean and Variance\n\nA major difference between this method and most currently\n\navailable techniques is the use of (co)variance instead of signal\n\namplitude. As described previously, the covariance matrix can\n\nbe estimated in different ways. One can use observations from\n\na recording at time instants that one believes are comparable;\n\ne.g., peaks in different spikes or EP responses. Alternatively,\n\nif one has reason to believe that a certain area is active over\n\na given time interval, one can select a sequence of sampled\n\npoints. Both approaches can also be combined by selecting\n\na window of measured values over comparable epochs in\n\na signal. In each case, we assume the observations used to\n\nestimate the covariance matrix represent brain activity at the\n\nsame locations.\n\nWe used simulations to examine the efﬁcacy of different\n\napproaches for selecting the observations used to estimate\n\nthe covariance matrix. A single dipole at\n\ncm,\n\ncm, and\n\ncm was used to generate data for\n\nthe homogeneous 32-channel montage described previously.\n\nThe source consisted of a dipole moment whose time variation\n\nis represented by 75 samples taken from one cycle of a\n\nsinusoid plus a random component. Noise was added to obtain\n\na SNR of approximately ten. Two different situations are\n\nconsidered: one in which the sinusoidal amplitude variation\n\ncontributes 20% of the total source power and a second in\n\nwhich the sinusoidal amplitude variation represents 80% of\n\nthe total source power. The random component of the source\n\ngenerates the remaining power. In each of the situations we generated 75 repetitions. Three different techniques were used to estimate the covariance matrix from the 75 repetitions of the 75 time points: 1) using all 75 time points of all 75 repetitions; 2) using a single time point (the ﬁfth) in the 75 repetitions; and 3) using all 75 time points after averaging the 75 repetitions.\nThe results of the simulation are shown in Fig. 3. Fig. 3(a)–(c) represents the results for the dipole with a relatively high amplitude, and Fig. 3(d)–(f), the dipole with a high variance component. The ﬁrst row of Fig. 3 [(a), (d)] depicts the results when all time points of all repetitions are used to estimate the covariance matrix. In this case, there is no difference between the high amplitude and high variance cases. Use of a single observation gives best results when the signal has a high variance component as illustrated in Fig. 3(e). Estimating the covariance matrix from the average of the repetitions works best with the large amplitude component case, although excellent results are also obtained in the high variance case [Fig. 3(c) and (f)].\nE. Localization of Stimulus Electrode Positions in the Brain\nThe simulations presented thus far use the same model geometry to generate the data and the transfer matrices. This facilitates examination of effects that cannot be controlled or measured in a realistic situation. However, in a realistic situation the modeled geometry is only an approximation to the actual geometry. We now explore the sensitivity of the method to deviations between actual and assumed geometry by using actual neurophysiological data. This implies we must relate the locations of sources identiﬁed in our spherical model to their actual location in the human head. In most neurophysiological recordings, the real source location(s) is/are unknown. Recorded data can be used to verify localization algorithms only in unusual cases. The best example of such exceptional data is where the source is artiﬁcially planted in the brain.\nWe obtained this type of data from a patient that had a possibility of epilepsy after craniotomy for clipping an intracranial aneurysm. Electrodes were inserted during craniotomy and used to monitor EEG after surgery. Stimulation was performed with informed consent of the patient. A stimulus pulse was delivered between different sets of electrodes to induce neural activity. One series of pulses were delivered between the two most “proximal” electrodes (set 1); the other between the most “distal” pair (set 2). The X rays from a lateral and fronto-dorsal view are shown in Fig. 4(a) and (b). The position of set 1 is medial, slightly occipital and approximately 1 cm lower than set 2. The EEG and stimulus pulse were measured using only 20 channels (the 10–20 positions plus Oz) with linked ears as a reference; the data was ampliﬁed by 20 000 and ﬁltered to pass components between 1 and 90 Hz. As can be seen in the example of set 1 data depicted in Fig. 4(c), the amplitude of the generated signal is slightly higher than the surrounding EEG; a situation comparable to an epileptic spike. To remove signals from other EEG sources, the data was highpass ﬁltered at 40 Hz; the result shown in Fig. 4(d). Nineteen samples from seven pulses were used to estimate the covariance matrix.\nThe contour plots of the neural activity index for sets 1 and 2 are shown in Fig. 4(e) and (f). The peaks associated with\n\nAuthorized licensed use limited to: Hong Kong Baptist University. Downloaded on December 06,2023 at 03:32:49 UTC from IEEE Xplore. Restrictions apply.\n\nVAN VEEN et al.: LOCALIZATION OF BRAIN ELECTRICAL ACTIVITY\n\n875\n\n(a)\n\n(d)\n\n(b)\n\n(e)\n\n(c)\n\n(f)\n\nFig. 2. The effect of correlation between sources on the neural activity index. The two correlated sources are closely spaced in (a)–(c) and relatively distant in (d)–(f). The sources are uncorrelated in (a) and (d), partially correlated in (b) and (e), and fully correlated in (c) and (f). Sources can be detected from the distribution of peaks in the neural activity index provided some uncorrelated activity is present [(a), (b), (d), and (e)]. When the sources are fully correlated it is no longer possible to detect distinct source locations [(c) and (f)]. Sources that are closely spaced tend to merge (c), while the distant sources nearly completely cancel each other (note the scale differences between the plots).\n\nAuthorized licensed use limited to: Hong Kong Baptist University. Downloaded on December 06,2023 at 03:32:49 UTC from IEEE Xplore. Restrictions apply.\n\n876\n\nIEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 44, NO. 9, SEPTEMBER 1997\n\n(a)\n\n(d)\n\n(b)\n\n(e)\n\n(c)\n\n(f)\n\nFig. 3. The effect of using different estimates of the covariance matrix. The neural activity index in a horizontal section 1cm above the center of the sphere is depicted. The dipole moment of the source has a repeatable sinusoidal component plus a random component. In (a)–(c), 80% of the activity is the repeatable component and 20% random. In (d)–(f), the repeatable component is 20% with 80% random. The data consist of 75 time points from 75 trials. In (a) and (d) the covariance matrix is estimated using the entire data record, in (b) and (d) a single time point in each trial is used, while in (c) and (e) the 75 time points in the average over the trials is used. The scale of the neural activity index is adjusted in each case. There is no difference between the primarily repeatable and the primarily random case [(a), (d)] when the entire data set is employed. Selecting a single point in each trial works best if the source is primarily random (e). Averaging reduces the trial to trial variability in the source as well as the noise and gives the best result when the source is dominated by a repeatable component (c), although excellent results are obtained in the random component case (f), since averaging does not reduce the source randomness within the trial.\n\nthe sources are relatively diffuse due to the limited resolution available with only 20 electrodes. The superﬁcially located peak associated with set 2 is sharper than the peak associated with the deeper activity in the set 1 data. Measurements necessary to register the source locations indicated on the X\n\nray with the coordinates of our spherical head model were not available, so we compare the relative positions of the actual and estimated sources to the 10–20 system electrode locations. The correspondence is very good. Viewed laterally on a Front-Back axis, the sources are located between the\n\nAuthorized licensed use limited to: Hong Kong Baptist University. Downloaded on December 06,2023 at 03:32:49 UTC from IEEE Xplore. Restrictions apply.\n\nVAN VEEN et al.: LOCALIZATION OF BRAIN ELECTRICAL ACTIVITY\n\n877\n\n(a)\n\n(b)\n\n(c)\n\n(d)\n\nFig. 4. Localization of stimulus electrodes implanted in the brain. The electrode positions within the brain are shown in lateral view (a) and frontal view (b) X-ray images. The stimulus electrodes for set 1 are lower, somewhat more medial and occipital than the set 2 electrodes. (c) Example of the data generated in response to stimulus of electrode pair set 1. (d) The solution is based on a spherical model. The maximum activity in set 1 is found 1 cm below the center of the sphere while the set 2 maximum is located 1 cm higher. The relative positions of the maxima and the position of each maxima relative to the surface electrode positions agree well with the anatomical positions of the stimulus electrodes.\n\ntemporal (T4) and frontal (F8) electrodes. On an Up-Down axis the set 1 and set 2 sources are slightly below and above the temporal electrodes (T4), respectively. In the frontal plane on a right–left axis, both sources are on the right side; set 2 close to the line that connects Fp2 and O2. The relative positions of the set 1 and set 2 sources are also as expected: the set 1 source is found deeper, more medial and occipital than the set 2 source.\nVI. DISCUSSION\nThe LCMV spatial ﬁltering method described herein is attractive because one does not have to determine the number\n\nof active sources a priori. The requirement of knowing the number of active sources a priori, or estimating the number from the data is a major limitation in most proposed source localization algorithms, for example [1], [5], [7], [8], [10], [26], and [27]. When the number of estimated sources is less than the true number of active areas such algorithms will typically detect resultant activity somewhere in between the actual areas. A trivial example of such a mislocalization is single dipole localization performed on bilateral somatosensory stimulation. Both hemispheres are active from approximately 20 ms after bilateral stimulation of the wrist. However, it is well known that single dipole analyzes performed on the so\n\nAuthorized licensed use limited to: Hong Kong Baptist University. Downloaded on December 06,2023 at 03:32:49 UTC from IEEE Xplore. Restrictions apply.\n\n878\n\nIEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 44, NO. 9, SEPTEMBER 1997\n\n(e)\n\n(f)\n\nFig. 4. (Continued.) Localization of stimulus electrodes implanted in the brain. Contour plots of the neural activity index in a horizontal cross section are shown in (e) (set 1) and (f) (set 2). The solution is based on a spherical model. The maximum activity in set 1 is found 1 cm below the center of the sphere while the set 2 maximum is located 1 cm higher. The relative positions of the maxima and the position of each maxima relative to the surface electrode positions agree well with the anatomical positions of the stimulus electrodes.\n\ncalled N20 yield a resultant source whose anatomical correlate\n\nis the medial ﬁssure between the hemispheres. In this example,\n\nthe error is easy to correct by assuming two active areas. In\n\nmany other situations such an easy correction is not feasible\n\nbecause an educated guess of the number of active areas cannot\n\nbe made. The examples in Section V and [22] illustrate that\n\ndistinct peaks in the neural activity index can actually indicate\n\nthe number of sources under certain conditions.\n\nThe localization technique presented here is closely related\n\nto the adaptive ﬁltering approach of Spencer et al. [21]. They\n\ndescribe a method for monitoring the time series associated\n\nwith a component of a current dipole source vector at a given\n\nlocation. An LCMV criterion is used to determine the adaptive\n\nﬁlter coefﬁcients, resulting in an expression equivalent to (23).\n\nSynthetic data is used to illustrate the potential effectiveness\n\nof the approach.\n\nOur work is also related to that of Dale and Sereno [12].\n\nFirst of all, they also employ covariance information for\n\nlocalization, assuming sources are zero mean. Second, they\n\nestimate the dipole strength as a function of location using a\n\nlinear function of the sensor data. However, instead of using\n\nan LCMV criterion to ﬁnd the linear operator, they minimize\n\nthe expected error between the estimated and actual solution.\n\nThe linear operator is then dependent on the dipole and noise\n\ncovariance matrices which are unknown. They propose either\n\nassuming a form for these covariance matrices a priori, or\n\nattempt to estimate them from the sensor covariance. The\n\ndipole variance is estimated using a modiﬁcation of the multi-\n\nple signal classiﬁcation (MUSIC) algorithm [10] in which the\n\nprojection of gain vectors onto each eigenvector is weighted\n\nby the reciprocal of the corresponding eigenvalue. The gain\n\nvector is determined from the transfer matrix\n\nand a\n\npriori knowledge of the dipole orientation. The functional form\n\nof the neural activity index (27) is similar to their modiﬁcation\n\nof the MUSIC algorithm in the special case\n\n. We do not\n\npresuppose knowledge of the dipole orientation and thus the\n\nneural activity index depends on all columns of\n\nrather\n\nthan a gain vector.\n\nThe LCMV approach is easily modiﬁed to incorporate prior\n\nknowledge of dipole orientation. Let\n\nbe the gain vector\n\nassociated with a dipole at location . We now design a single\n\nspatial ﬁlter\n\nto minimize output variance subject to a\n\nunit gain constraint on the response to the dipole of interest,\n\nresulting in the LCMV problem\n\nsubject to\n\nThe neural activity index associated with this problem is then\n\nVar\n\nThis corresponds exactly to the MUSIC based variance esti-\n\nmator of Dale and Sereno [12] when\n\n. Note that our\n\nderivation of the neural activity index using principles of spa-\n\ntial ﬁltering offers insight into performance and characteristics\n\nthat are not evident from the MUSIC-based variance estimator\n\nderivation. This variance estimator contains contributions due\n\nto the dipole source at , other dipoles that leak through\n\nthe spatial ﬁlter sidelobes, and noise. The effect of these\n\ntwo contaminants on the linear operator used to perform\n\nlocalization in [12] and the ultimate localization performance\n\nhas not been reported.\n\nAs in any approach, the LCMV spatial ﬁltering method de-\n\nscribed here is developed assuming a model for the underlying\n\nneural activity. Our results suggest that the algorithm is robust\n\nto many violations of the underlying assumptions.\n\nThe effect of correlation between sources is evaluated\n\nusing analysis and simulations. The simulation results (Fig. 2)\n\nindicate that localization of correlated sources is possible\n\nas long as some of the source activity is uncorrelated. If\n\nthere is a high correlation between sources, one may obtain\n\nresultant activity in between the real active areas [Fig. 2(c)],\n\nsimilar to the resultant activity in other localization algorithms\n\nAuthorized licensed use limited to: Hong Kong Baptist University. Downloaded on December 06,2023 at 03:32:49 UTC from IEEE Xplore. Restrictions apply.\n\nVAN VEEN et al.: LOCALIZATION OF BRAIN ELECTRICAL ACTIVITY\n\n879\n\nassociated with under estimation of the number of sources. In our case, the algorithm effectively treats closely spaced correlated sources as a single source. Alternatively, the activity level is generally underestimated if the correlated sources are relatively distant [Fig. 2(f)]. Although some correlation in neural activity in the brain is expected, perfect correlation between spatially disparate is unlikely. Hence, we believe that the partially correlated cases in Fig. 2(b) and (e) are realistic. While partial correlation decreases the estimated activity level, power of the ﬁlter output, different sources still may be distinguished given a reasonable SNR and enough electrodes.\nThe LCMV approach is an attempt to exploit variable features in the data. Neural responses, as all physiological processes, are not perfectly reproducible. The variability in subaverages of an EP and in spike and seizure activity in an electroencephalogram are likely due to both variability in the underlying signal as well as surrounding ongoing activity. The method is robust to the source of variability used for localization, whether epoch to epoch variations or variation over time. This allows considerable ﬂexibility in obtaining data with which to estimate the covariance matrix. For example, in situations with low SNR such as an evoked response, averaging can be used to reduce noise. Averaging also reduces signal epoch to epoch variability, but will not reduce the temporal variation associated with the repeatable component of the response. This temporal variation can be used for localization by estimating the covariance matrix with temporal samples. We have illustrated the effect of using epoch to epoch variability and temporal variability to estimate the covariance matrix in simulations by varying the relative contributions of source amplitude and variance (Fig. 3). In general, the best method for estimating the covariance matrix depends on the source’s relative components of temporal and epoch to epoch variability and the noise statistics.\nWe have assumed that the data used to estimate the covariance matrix results from a stationary source distribution. If different source distributions are represented in the covariance matrix, the neural activity index will represent a combined activity pattern. For example, suppose one source is active in the ﬁrst part of the data and two others are active in the second part. The neural activity index based on the combined data will in general indicate three active sources. If many active areas are present, the neural activity index will likely indicate a broad region of activity and individual sources will not be evident. The method cannot resolve differences in the underlying activity distributions once the corresponding data is combined into a single covariance matrix estimate. Determining whether a data set corresponds to a stationary spatial source distribution is beyond the scope of the present work. One may assume that similar areas of the brain are involved in different subaverages of a EP because the activity is stimulus related. During an epileptic discharge it may be necessary to compare the topography of a series of spikes before concluding that different spikes originate from the same underlying source distribution.\nThe data generated by implanted electrodes was chosen to have approximately the same order of magnitude as the spontaneous electrical activity [see Fig. 4(c)] in order to\n\napproximate a typical epileptic discharge. This assumption on\n\nthe relative magnitude of an epileptic discharge is supported\n\nby data described in van Drongelen et al. [22]. The primary\n\npurpose of this data set is to demonstrate the methods ability\n\nto localize when there are deviations between the actual\n\nand assumed head geometry (see Fig. 4). The sources were\n\nlocalized in a diffuse area because only 20 electrodes were\n\nused. While increasing the number of electrodes would lead\n\nto improved resolving capability, it would also increase the\n\nsensitivity to deviations between actual and assumed geome-\n\ntries. High-resolution results when the spatial ﬁlter is able to\n\ndiscriminate between signals with subtle differences in their\n\ntransfer matrices due to location. Modeling errors also lead to\n\nsubtle differences in transfer matrices. When modeling errors\n\nare present, the spatial ﬁltering constraint no longer insures\n\nthat a source at a given location is passed with unit gain\n\nbecause the actual and modeled transfer matrices differ. If\n\nthe electrode array has high enough resolution to discriminate\n\nbetween actual and modeled transfer matrices, then the spatial\n\nﬁlter will attenuate the source, resulting in underestimation\n\nof source power. Hence, the importance of accurate head\n\nmodeling increases with increasing numbers of electrodes.\n\nIn this particular data set, the errors introduced by assuming\n\na spherical model should be minimal because the sources are\n\ncentrally located. Note that our spatial ﬁltering approach for\n\nsolving the inverse problem is not limited to a particular head\n\nmodel for solving the forward problem. Indeed, as in most\n\napproaches to solving the inverse problem, use of a more\n\nrealistic head model will lead to more accurate localization\n\nresults.\n\nFinally, we demonstrated in Section V-B that the choice\n\nof reference does not impact the accuracy of the solution\n\nprovided the\n\nis determined with respect to the chosen\n\nreference. In clinical EEG, the reference choice often plays\n\nan important role in distinguishing relevant activity from\n\nbackground signals. Our method may resolve some of these\n\nissues since it appears to generate reference independent\n\nsolutions. We note that our method may also be applied to\n\nthe so-called bipolar montage that is often used to distinguish\n\nlocally generated signals from noise. This montage does not\n\nemploy a common reference, but rather each electrode is\n\nreferenced to its neighbor; in effect, a spatial derivative is\n\ncomputed. The spatial ﬁltering approach can be applied to\n\nsuch data by determining\n\nin a bipolar fashion. That\n\nis, the columns of\n\nrepresents the differences between\n\nneighboring electrodes associated with a unit dipoles oriented\n\nin the , and coordinate directions at location .\n\nThe results presented in this paper suggest that the spatial\n\nﬁltering approach has considerable potential as a source lo-\n\ncalization tool. The method gives good results under realistic\n\nconditions and is robust to deviations in the assumed signal\n\nmodel. Additional experience with real data is needed to fully\n\nvalidate the effectiveness of this technique.\n\nREFERENCES\n[1] D. H. Fender, “Source localization of brain electrical activity,” in Methods of Analysis of Brain Electrical and Magnetic Signals. EEG Handbook, revised series, A. S. Gevins and A. Remonds, Eds. Amsterdam: Elsevier, 1987, vol. 1, pp. 355–403.\n\nAuthorized licensed use limited to: Hong Kong Baptist University. Downloaded on December 06,2023 at 03:32:49 UTC from IEEE Xplore. Restrictions apply.\n\n880\n\nIEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING, VOL. 44, NO. 9, SEPTEMBER 1997\n\n[2] R. N. Kavanagh, T. M. Darcey, D. Lehman, and D. H. Fender, “Evaluation of methods for three-dimensional localization of electrical sources in the human brain,” IEEE Trans. Biomed. Eng., vol. BME-24, pp. 421–429, 1987.\n[3] J. W. H. Meijs, “The inﬂuence of head geometries on electro- and magnetoencephalograms,” Ph.D. thesis, Enschede, Netherlands, 1988.\n[4] P. L. Nunez, “Methods to estimate spatial properties of dynamic cortical source activity,” in Functional Brain Imaging, G. Pfurtscheller and F. Lopes da Silva, Eds. Toronto: Hans Huber, 1988, pp. 3–10.\n[5] J. C. de Munck, “A mathematical and physical interpretation of the electromagnetic ﬁeld of the brain,” Ph.D. thesis, University of Amsterdam, Amsterdam, the Netherlands, 1989.\n[6] Y. Salu, L. G. Cohen, D. Rose, S. Sato, C. Kufta, and M. Hallett, “An improved method for localizing electric brain dipoles,” IEEE Trans. Biomed. Eng., vol. 37, pp. 699–705, 1990.\n[7] M. Scherg, “Fundamentals of dipole source potential analysis,” in Auditory Evoked Magnetic Fields and Electric Potentials. Advances in Audiology, F. Grandori, M. Hoke, and G. L. Romani, Eds. Basel, Switzerland: Karger, 1990, vol. 6, pp. 40–69.\n[8] M. Scherg, “Functional imaging and localization of electromagnetic brain activity,” Brain Topogr., vol. 5, pp. 103–111, 1992.\n[9] Y. Yan, P. L. Nunez, and R. T. Hart, “Finite-element model of the human head: Scalp potentials due to dipole sources,” Med., Biol. Eng. Comput., vol. 29, pp. 475–481, 1991.\n[10] J. C. Mosher, P. S. Lewis, and R. M. Leahy, “Multiple dipole modeling and localization of spatio-temporal MEG data,” IEEE Trans. Biomed. Eng., vol. 39, pp. 541–557, 1992.\n[11] B. Van Veen, J. Joseph, and K. Hecox, “Localization of intra-cerebral sources of electrical activity via linearly constrained minimum variance spatial ﬁltering,” in Proc. IEEE Workshop on Statistical Signal and Array Processing, Oct. 1992, pp. 526–529.\n[12] A. M. Dale and M. I. Sereno, “Improved localization of cortical activity by combining EEG and MEG with MRI cortical surface reconstruction: A linear approach,” J. Cognitive Neurosci., vol. 5, no. 2, pp. 162–176, 1993.\n[13] B. J. Roth, M. Balish, A. Gorbach, and S. Sato, “How well does a three-sphere model predict positions of dipoles in a realistically shaped head?” Electroenceph. Clin. Neurophysiol., vol. 87, pp. 175–184, 1993.\n[14] A. Amir, “Uniqueness of the generators of brain evoked potential maps,” IEEE Trans. Biomed. Eng., vol. 41, pp. 1–11, 1994.\n[15] Z. Zhang and D. L. Jewet, “DSL and MUSIC under model misspeciﬁcation and noise-conditions,” Brain Topogr., vol. 7, pp. 151–161, 1994.\n[16] T. C. Liu and B. Van Veen, “Multiple window based minimum variance spectrum estimation for multidimensional random ﬁelds,” IEEE Trans. Signal Processing, vol. 40, pp. 578–589, Mar. 1992.\n[17] B. Van Veen and K. Buckley, “Beamforming: A versatile approach to spatial ﬁltering,” IEEE ASSP Mag., vol. 5, pp. 4–24, Apr. 1988.\n[18] R. T. Lacoss, “Adaptive combining of wideband array data for optimal reception,” IEEE Trans. Geosci. Electron., vol. GE-6, pp. 78–86, May 1968.\n[19] O. L. Frost, “An algorithm for linearly constrained adaptive array processing,” Proc. IEEE, vol. 60, pp. 926–935, Aug. 1972.\n[20] B. Van Veen, J. Joseph, and K. Hecox, “Method and apparatus for localization of intracerebral sources of electrical activity,” US Patent 5 263 488, Nov. 23, 1993.\n[21] M. E. Spencer, R. M. Leahy, J. C. Mosher, and P. S. Lewis, “Adaptive ﬁlters for monitoring localized brain activity from surface potential time series,” in Conf. Rec. 26th Annu. Asilomar Conference on Signals, Systems, and Computers, Nov. 1992, pp. 156–161.\n[22] W. van Drongelen, M. Yuchtman, B. Van Veen, and A. van Huffelen, “Spatial ﬁltering applied in source localization of electrical activity in the brain,” Brain Topogr., vol. 9, pp. 39–49, 1996.\n[23] B. Widrow, K. M. Duvall, P. P. Gooch, and W. C. Newman, “Signal cancellation phenomena in adaptive arrays: Causes and cures,” IEEE Trans. Antennas Propagat., vol. AP-30, pp. 469–478, May 1982.\n[24] J. Capon and N. R. Goodman, “Probability distributions for estimators of the frequency-wavenumber spectrum,” Proc. IEEE, vol. 58, pp. 1785–1786, Oct. 1970.\n[25] M. S. Buchsbaum, E. Hazlett, N. Sicotte, R. Ball, and S. Johnson, “Geometric and scaling issues in topographic electroencephalography,” in Topographic Mapping of Brain Electrical Activity, F. H. Duffy, Ed. Boston, MA: Butterworths, 1986, pp. 325–337.\n[26] J. C. de Munck, “The estimation of time varying dipoles on the basis of evoked potentials,” Electroenceph. Clin. Neurophysiol., vol. 77, pp. 156–160, 1990.\n[27] M. Scherg, “From EEG source localization to source imaging,” Acta Neurol. Scand., Supplement, vol. 152, pp. 29–30, 1994.\n\nBarry D. Van Veen (S’81–M’86) was born in Green Bay, WI. He received the B.S. degree from Michigan Technological University, Houghton, in 1983 and the Ph.D. degree from the University of Colorado, Fort Collins, in 1986, both in electrical engineering. He was an ONR Fellow while working on the Ph.D. degree.\nIn the spring of 1987, he was with the Department of Electrical and Computer Engineering at the University of Colorado–Boulder. Since August of 1987, he has been with the Department of Electrical and Computer Engineering at the University of Wisconsin–Madison and is currently a Professor. His research interests include signal processing for sensor arrays, nonlinear systems, adaptive ﬁltering, acoustical, and biomedical applications of signal processing. Dr. Van Veen was a recipient of the 1989 Presidential Young Investigator Award and the 1990 IEEE Signal Processing Society Paper Award. He is currently an Associate Editor for the IEEE TRANSACTIONS ON SIGNAL PROCESSING and served on the IEEE Signal Processing Society’s Technical Committee on Statistical Signal and Array Processing from 1991 through 1997.\nWim van Drongelen was born in Vlissingen, The Netherlands, in 1953. He studied biophysics at Leiden University, Leiden, Netherlands. After a period in the Laboratoire d’Electrophysiologie, Universite Claude Bernard, Lyon, France, he received the M.S. degree. In 1980, he received the Ph.D. degree.\nFrom 1977, he worked for The Netherlands Organization for the Advancement of Pure Research (ZWO) in the Department of Animal Physiology, Wageningen, Netherlands. He worked for the HBO Institute Twente, Netherlands. He taught neurophysiology and neuroanatomy and founded a Medical Technology Department. In 1986, he started to work for Nicolet Instrument, the Netherlands, as a Benelux Application Engineer. From 1990 to 1993, he was international Application Specialist and he managed the Dutch ofﬁce of Nicolet Instrument. In 1993, he relocated to Madison, WI. He is Senior Application Engineer with the Engineering Department of Nicolet Biomedical, Inc. His ongoing research interests are in source localization, pattern recognition algorithms, and application of electrophysiology in monitoring.\nMoshe Yuchtman was born in Tel Aviv, Israel, in 1948. He received the B.Sc. degree from Tel Aviv University in 1972. He received his M.Sc. degree in neurobiology from the Hebrew University in Jerusalem, Israel, in 1976. In 1982, he received the M.Sc. degree in speech and hearing science from the University of Illinois, Urbana-Champaign. He worked as a Research Associate with the Speech Research Laboratory of the University of Indiana, Bloomington, between 1984 and 1987.\nSince 1987, he has been with Nicolet Biomedical as an Application Research Engineer. He has been involved in the development of applications of signal processing in neurophysiology and speech perception.\nAkifumi Suzuki was born in Ooshima, Tokyo, Japan, in 1949. He received the M.D. degree from the Prefectural University of Mie in 1974. He specialized in surgery and neurosurgery with the Matsuka Central Hospital and the Research Institute for Brain and Blood Vessels, Akita, Japan. In 1980, he was a board qualiﬁed neurosurgeon. He received the D.MSc. degree from the Tohoku University, Japan, in 1982.\nCurrently, he has several functions with the Research Institute for Brain and Bloodvessels, Akita, Japan. He is Director of the Department of Cerebral Apoplexy, Chief of Neurosurgery, Chief Researcher of Surgical Neurology, and Chief of the Intensive Care Unit. He is author of more than 100 scientiﬁc articles. Dr. Suzuki has received several awards for his work. Among them are: special symposist in the 50th Memorial Congress of the Japan Neurosurgical Society and the Nakamura Memorial Prize, and fellowship in the American College of Angiology.\n\nAuthorized licensed use limited to: Hong Kong Baptist University. Downloaded on December 06,2023 at 03:32:49 UTC from IEEE Xplore. Restrictions apply.\n\n"}