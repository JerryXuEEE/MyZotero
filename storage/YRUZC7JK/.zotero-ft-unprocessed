{"indexedPages":100,"totalPages":442,"version":"238","text":"第1章 绪 论\n\n1. 1 引言\n\n傍晚小街路面上沁出微雨后的湿润，和熙的细风吹来，抬头看看天边的晚 霞 7 嗯，明天又是一个好夭气.走到水果摊旁，挑了个根蒂蜷缩、敲起来声音浊 响的青绿西瓜，一边满心期待着皮薄肉厚瓢甜的爽落感，一边愉快地想着，这学 期狠下了工夫，基础概念弄得清清楚楚，算法作业也是信手拈来，这门课成绩一 定差不了!\n\n希望各位在学期结束时有这样的感觉.作为开场，我们先大致了解一下什\n么是\"机器学习\" (machine learning).\n\n回头看第一段话，我们会发现这里涉及很多基于经验做出的预判.例如，为 什么看到微温路面、感到和风、看到晚霞，就认为明天是好天呢?这是因为在 我们的生活经验中已经遇见过很多类似情况，头一天观察到上述特征后，第二 天天气通常会很好.为什么色泽青绿、根蒂蜷缩、敲声浊晌，就能判断出是正 熟的好瓜?因为我们吃过、看过很多西瓜，所以基于色泽、根蒂、敲声这几个 特征我们就可以做出相当好的判断.类似的，我们从以往的学习经验知道，下足 了工夫、弄清了概念、做好了作业，自然会取得好成绩.可以看出，我们能做出 有效的预判?是因为我们已经积累了许多经验，而通过对经验的利用?就能对新 情况做出有效的决策.\n\n上面对经验的利用是靠我们人类自身完成的.计算机能帮忙吗?\n\n[Mitchell , 1997J 给出了 一个更形式化的定义假 设用 P 来评估计算机程序 在某任务类 T 上的性能， 若一个程序通过利用经验 E 在 T 中任务丰获得了性 能改善，则我们就说关于 T 和 P ， 该程序对 E 进行\n了学习\n\n机器学习正是这样一门学科，它致力于研究如何通过计算的手段，利用经 验来玫善系统自身的性能在计算机系统中，\"经验\"通常以\"数据\"形式存 在，因此?机器学习所研究的主要内容，是关于在计算机上从数据中产生\"模\n型\" (model) 的算法，即\"学习算法\" (learning algorithm). 有了学习算法，我\n们把经验数据提供给它，它就能基于这些数据产生模型;在面对新的情况时(例 如看到一个没剖开的西瓜)，模型会给我们提供相应的判断(例如好瓜) .如果说 计算机科学是研究关于\"算法\"的学问，那么类似的，可以说机器学习是研究 关于\"学习算法\"的学问.\n\n例如 [Hand et a l., 2001].\n\n本书用\"模型\"泛指从数据中学得的结果有文献用\"模型\"指全局性结 果(例如一棵决策树)，而用\"模式\"指局部性结呆(例如 A条规则).\n\n2\n\n第 1 章绪论\n\n1. 2 基本术语\n\n要进行机器学习，先要有数据.假定我们收集了一批关于西瓜的数据，例 如(色泽=青绿;根蒂=蜷缩;敲声=浊响)， (色泽=乌黑;根蒂:稍蜷;敲声=沉 闷)， (色泽=浅自;根蒂t硬挺;敲声=清脆)，……，每对括号内是一条记录，\n\"_，，意思是\"取值为\"\n\n有时整个数据集亦称一 个\"样本\"因为它可看 作对样本空间的一个采样， 通过上下文可判断出\"样 本\"是指单个示例还是数 据集\n\n这组记录的集合称为一个\"数据集\" (data set) ，其中每条记录是关于一\n个事件或对象(这里是一个西瓜)的描述，称为一个\"示例\" (instance) 或\"样 本\" (samp1e). 反映事件或对象在某方面的表现或性质的事项，例如\"色泽\"\n\"根蒂\" \"敲声\"，称为\")副主\" (attribute) 或\"特征\" (feature); 属性上的取\n值，例如\"青绿\" \"乌黑\"，称为\")副主值\" (attribute va1ue). 属性张成的空 间称为\"属性空间\" (attribute space) 、 \"样本空间\" (samp1e space) 或\"输入\n空间\"例如我们把\"色泽\" \"根蒂\" \"敲声\"作为三个坐标轴，则它们张成\n\n一个用于描述西瓜的三维空间，每个西瓜都可在这个空间中找到自己的坐标位\n\n置.由于空间中的每个点对应一个坐标向量，因此我们也把…个示例称为一个\n\n\"特征向量\" (feature vector).\n\n一般地，令 D = {X l， 町 \"..， Xm } 表示包含 m 个示例的数据集，每个\n示例由 d 个属性描述(例如上面的西瓜数据使用了 3 个属性)，则每个示例\n\nXi = (Xi1; Xi2; . . . ; Xid) 是 d 维样本空间 X 中的一个向量 ， Xi ε X ， 其中 Xij 是\n凯在第 j 个属性上的取值(例如上述第 3 个西瓜在第 2 个属性上的值是\"硬\n\n挺\" ), d 称为样本院的\"维数\" (dimensionality).\n\n训练样本亦称\"如11 练示\n例\" (training instance) 或\n\"切|练例\"\n学习算法通常有参数需 设置，使用不同的参数值 和(或)训练数据，将产生 不同的结果\n将 \"Iabel\" 译为\"标 记\"而非\"标签\"是考 虑到英文中 \".Iabel\" 既可 用作名词、也可用作动词\n\n从数据中学得模型的过程称为\"学习\" (le缸ning) 或\"训练\" (training) ,\n这个过程通过执行某个学习算法来完成.训练过程中使用的数据称为\"训练\n数据\" (training data) ，其中每个样本称为一个叮 11 练样本\" (training samp1e) , 训练样本组成的集合称为\"训练集\" (training set). 学得模型对应了关于数据\n的某种潜在的规律，因此亦称\"假设\" (hypothesis); 这种潜在规律自身，则称 为\"真相\"或\"真实\" (ground-truth) ，学习过程就是为了找出或逼近真相.本 书有时将模型称为\"学习器\" (learner) ，可看作学习算法在给定数据和参数空 间上的实例化.\n如果希望学得一个能帮助我们判断没剖开的是不是\"好瓜\"的模型，仅 有前面的示例数据显然是不够的要建立这样的关于\"预测\" (prediction) 的 模型，我们需获得训练样本的\"结果\"信息，例如\" ((色泽:青绿;根蒂二蜷缩; 敲声=浊响)，好瓜)\" .这里关于示例结果的信息，例如\"好瓜\"，称为\"标 记\" (labe1); 拥有了标记信息的示例，则称为\"样例\" (examp1e). 一般地，用\n\n1.2 基本术语\n\n3\n\n若将标记看作对象本身 的一部分，则\"样例\"有 时也称为\"样本\"\n亦称\"负类\"\n\n(Xi ， Yi) 表示第 4 个样例 7 其中执 εy 是示例 Xi 的标记 ， Y 是所有标记的集合， 亦称\"标记空间\" (label 吕p叩a肮ce叫)或\"输出空间\n若我们欲预测的是离散值，例如\"好瓜\" \"坏瓜\"，此类学习任务称为 \"分类\" (classification); 若欲预测的是连续值?例如西瓜成熟度 0.95 、 0.37 ，\n此类学习任务称为\"回归\" (regression). 对只涉及两个类别的\"二分 类\" (binary cl嗣sification)任务，通常称其中一个类为 \"Æ类\" (positive cl甜的? 另一个类为\"反类\" (negative class); 涉及多个类别时，则称为\"多分 类\" (multi-class classificatio叫任务.一般地，预测任务是希望通过对训练 集 {(X1' Y1) , (X2 ,Y2) ,..., (Xm, Ym)} 进行学习，建立一个从输入空间 X 到输出\n空间 y 的映射 f: X 叶 y. 对二分类任务，通常令 Y = {-1 ，十 1} 或 {O ， l}; 对\n多分类任务， IYI >2; 对回归任务， Y= lR，lR为实数集.\n\n亦称\"测试示例\"\n(testing instance) 或\"测 试例\"\n\n学得模型后，使用其母行预测的过程称为\"测试\" (testing) ，被预测的样本\n称为喇试样本\" (testing sample). 例如在学得 f 后，对测试例 X ， 可得到其预\n测标记 ν = f(x).\n\n否则标记信息直接形成 了簇划分，但也有例外情 况，参见 13.6 节\n亦称啃导f币学习\"和\n‘无导师学习\n史确切地说，是\"未见\n示例\" (unseen instance).\n现实任务中样本空间的 规模通常很大(例如 20 个 属性 1 每个属性有 10 个可 能取佳，则样本空间的规 模已达 1020 ).\n\n我们还可以对西瓜做\"聚类\" (clustering) ，即将训练集中的西瓜分成若干 组，每组称为 A个\"簇\" (cluster); 这些自动形成的簇可能对应一些潜在的概念 划分，例如\"浅色瓜\" \"深色瓜 程有助于我们了解数据内在的规律?能为更深入地分析数据建立基础.需说明 的是，在聚类学习中，\"浅色瓜\" \"本地瓜\"这样的概念我们事先是不知道的， 而且学习过程中使用的训练样本通常不拥有标记信息.\n根据训练数据是否拥有标记信息，学习任务可大致划分为两大类\"监督\n学习\" (supervised learning) 和\"无监督学习\" (unsupervised learning) ，分类\n和回归是前者的代表，而聚类则是后者的代表.\n需注意的是，机器学习的目标是使学得的模型能很好地适用于\"新样本\"， 而不是仅仅在训练样本上工作得很好;即便对聚类这样的无监督学习任务，我 们也希望学得的簇划分能适用于没在训练集中出现的样本.学得模型适用于 新样本的能力，称为\"泛化\" (generalization) 能力.具有强泛化能力的模型能 很好地适用于整个样本空间.于是，尽管训练集通常只是样本需间的一个很小 的采样，我们仍希望它能很好地反映出样本空间的特性，否则就很难期望在训 练集上学得的模型能在整个样本空间上都工作得很好.通常假设样本空间中全\n体样本服从 A个未知\"分布\" (distribution) Ð ， 我们获得的每个样本都是独立 地从这个分布上采样获得的，即\"独立同分布\" (independent and identically\ndistributed ，简称 i.i.d.). 一般而言，训练样本越多，我们得到的关于 D 的信息\n\n4\n\n第 1 章绪论\n\n越多，这样就越有可能通过学习获得具有强泛化能力的模型.\n\n1. 3 假设空间\n归纳 (induction) 与横绎 (deductio丑)是科学推理的两大基本手段.前者是从 特殊到一般的\"泛化\" (generalization) 过程，即从具体的事实归结出一般性规 律;后者则是从一般到特殊的\"特化\" (specializatio叫过程，即从基础原理推演 出具体状况.例如，在数学公理系镜中，基于一组公理和推理规则推导出与之 相洽的定理，这是演绎;而\"从样例中学习\"显然是一个归纳的过程?因此亦称\n\"归纳学习\" (inductive learni吨) .\n归纳学习有狭义与广义之分?广义的归纳学习大体相当于从样例中学习， 而狭义的归纳学习则要求从训练数据中学得概念 (concept) ，因此亦称为\"概念 学习\"或\"概念形成\"概念学习技术目前研究、应用都比较少，因为要学得 泛化性能好且语义明确的概念实在太困难了，现实常用的技术大多是产生\"黑 箱\"模型.然而，对概念学习有所了解，有助于理解机器学习的一些基础思想.\n概念学习中最基本的是布尔概念学习?即对\"是\" \"不是\"这样的可表示 为 0/1 布尔值的目标概念的学习.举一个简单的例子，假定我们获得了这样一 个训练数据集:\n表1. 1 西瓜数据集\n编号色泽根蒂敲声好瓜 1 青绿蜷缩浊响 是\n2 乌黑蜷缩浊响 是 3 青绿硬挺清脆 否 4 乌黑稍蜷沉闷 否\n\nJt一般的情况是考虑形\n如 (A^B)V(C^D) 的析 合范式\n\n这里要学习的目标是\"好瓜\"暂且假设\"好瓜\"可由\"色泽\" \"根蒂\" \"敲声\"这三个因素完全确定?换言之，只要某个瓜的这三兰个属性取值明确了?\n我们就能判断出它是不是好瓜.于是?我们学得的将是\"好瓜是某种色泽、某\n种根蒂、某种敲声的瓜\"这样的概念'用布尔表达式写出来则是\"好瓜忡(色\n^ 泽=?η) 八(根蒂 =7η) (敲声 =7η)\n务就是通过对表1.1的训练集进行字学罗习'把\"?\"确定下来.\n\n读者可能马上发现，表1. 1 第一行: \" (色泽=青绿)八(根蒂:蜷缩)八(敲\n声=浊响)\"不就是好瓜吗?是的，但这是·个己见过的瓜，别忘了我们学习的 目的是\"泛化\"?即通过对训练集中瓜的学习以获得对没见过的瓜进行判断的\n\n1.3 假设空间\n\n5\n\n\"记住\"训练样本，就 是所谓的\"机械学习\" [Cohen and Feigenbaum. 1983]. 或称\"死记硬背式 学习\"参见1. 5 节.\n这里我们假定训练样 本不含噪声，并且不考虑\n\"非青绿\"这样的 -，A 操 作由于训练集包含正例， 因此 g 假设自然不出现.\n\n能力.如果仅仅把训练集中的瓜\"记住\"，今后再见到一模一样的瓜当然可判\n^ ^ 断，但是，对没见过的瓜，例如\"(色泽=浅白) (根蒂=蜷缩) (敲声=浊晌)\"\n怎么办呢?\n我们可以把学习过程看作一个在所有假设 (hypothesis) 组成的空间中进行\n搜索的过程，搜索目标是找到与训练集\"匹配\"但t) 的假设，即能够将训练集中 的瓜判断正确的假设.假设的表示一旦确定，假设空间及其规模大小就确定了.\n^ 这里我们的假设空间由形如\"(色泽=?)八(根蒂=?) (敲声=?)\"的可能取值\n所形成的假设组成.例如色泽有\"青绿\" \"乌黑\" \"浅白\"这三种可能取值; 还需考虑到，也许\"色泽\"无论取什么值都合适，我们用通配符\"*\"来表示，\n^ 例如\"好瓜件(色泽= *) (根蒂口蜷缩)八(敲声=浊响)\" ，即\"好瓜是根蒂蜷\n缩、敲声浊响的瓜，什么色泽都行\"此外，还需考虑极端情况:有可能\"好 瓜\"这个概念根本就不成立，世界上没有\"好瓜\"这种东西;我们用 m 表示这 个假设.这样，若\"色泽\" \"根蒂\" \"敲声\"分别有3 、 2 、 2 种可能取值，则我\n们面临的假设空间规模大小为 4 x 3 x 3 + 1 = 37. 图1. 1 直观地显示出了这个\n西瓜问题假设空间.\n\n(色泽兰兰青绿;根蒂=蜷缩;敲声=*)\n7\nLs色泽二青绿;根蒂 z蜷缩;敲声=浊响) 11 (色泽=青绿;根蒂 z蜷缩;敲声二沉闷)\n\n固1. 1 西瓜问题的假设空间\n\n有许多可能的选择，如 在路径上自顶向下与自底 向上同时进行，在操作土 只删除与正例不一致的假 设等\n\n可以有许多策略对这个假设空间进行搜索，例如自顶向下、从一般到特殊， 或是自底向上、从特殊到一般，搜索过程中可以不断删除与正例不一致的假 设、和(或)与反例→致的假设.最终将会获得与训练集一致(即对所有训练样本 能够进行正确判断)的假设，这就是我们学得的结果.\n需注意的是，现实问题中我们常面临很大的假设空间?但学习过程是基于 有限样本训练集进行的，因此，可能有多个假设与训练集一致，即存在着一个与\n训练集一致的\"假设集合\"，我们称之为\"版本空间\" (version space). 例如，\n在西瓜问题中，与表1. 1 训练集所对应的版本空间如图1. 2 所示.\n\n6\n\n第 1 章绪论\n\n图1. 2 西瓜问题的版本空间\n\n1. 4 归纳偏好\n\n通过学习得到的模型对应了假设空间中的一个假设.于是，图1. 2 的西瓜 版本空间给我们带来一个麻烦:现在有三个与训练集一致的假设，但与它们 对应的模型在面临新样本的时候，却会产生不同的输出.例如，对(色泽口青绿; 根蒂=蜷缩;敲声=沉闷)这个新收来的瓜，如果我们采用的是\"好瓜村(色 泽= *)八(根蒂=蜷缩)八(敲声=*)\"，那么将会把新瓜判断为好瓜，而如果采 用了另外两个假设，则判断的结果将不是好瓜.那么，应该采用哪一个模型(或 假设)昵?\n\n尽可能特殊即\"适用情 形尽可能少\" .尽可能一 般即\"适用情形尽可能\n多\"\n对\"根蒂\"还是对\"敲 声\"灵重视，.看起来和属 性选择，亦称\"特征选 择\" (feature selection) 有 关，但需注意的是，机器学 习中的特征选择仍是基于 对训练样本的分析进行的， 而在此处我们并非基于特 征选择做出对\"根蒂\"的 重视，这里对\"根蒂\"的 信赖可视为基于某种领域 知识而产生的归纳偏好­ 关于特征选择方面的内容 参见第 11 幸\n\n若仅有表1. 1 中的训练样本，则无法断定上述三三三个假设中明哪F 一个\"更好 然而，对于一个具体的学习算法而言?它必须要产生一个模型.这时，学习算 法本身的\"偏好\"就会起到关键的作用.例如，若我们的算法喜欢\"尽可能特\n殊\"的模型，则它会选择\"好瓜件(色泽= *)八(根蒂=蜷缩)八(敲声=浊晌)\" ;\n但若我们的算法喜欢\"尽可能一般\"的模型，并且由于某种原因它更\"相信\"\n^ 根蒂，则它会选择\"好瓜件(色泽= *) (根蒂=蜷缩)八(敲声= *)\" .机器学习\n算法在学习过程中对某种类型假设的偏好，称为\"归纳偏好\" (inductive bias) ,\n或简称为\"偏好\"\n任何一个有效的机器学习算法必有其归纳偏好，否则它将被假设空间中看 似在训练集上\"等效\"的假设所迷惑，而无法产生确定的学习结果.可以想象， 如果没有偏好，我们的西瓜学习算法产生的模型每次在进行预测时随机抽选 训练集上的等效假设，那么对这个新瓜\"(色泽=青绿;根蒂口蜷缩;敲声=沉 闷)\" ，学得模型时而告诉我们它是好的、时而告诉我们它是不好的，这样的学 习结果显然没有意义.\n归纳偏好的作用在图1. 3 这个回归学习图示中可能更直观.这里的每个训 练样本是因中的一个点 (x ， y) ， 要学得一个与训练集一致的模型，相当于找到一 条穿过所有训练样本点的曲线.显然，对有限个样本点组成的训练集，存在着 很多条曲线与其一致.我们的学习算法必须有某种偏好，才能产出它认为\"正 确\"的模型.例如，若认为相似的样本应有相似的输出(例如，在各种属性上都\n\n1.4 归纳偏好\n\n7\n\ny\n\n，、\n\nJ\n\n、\n\n&\n\n_一『旬_-，\n\n\"/, '\n\n\\ A\n\n、\n\n、\n\n、\n\n、\n\n、\n\n- 、\n\n、 、\n\n,\n\n/B\n、 ‘\nE E 1\n\nx\n\n图1. 3 存在多条曲线与有限样本训练集一致\n很相像的西瓜，成熟程度应该比较接近)，则对应的学习算法可能偏好图1. 3 中 比较\"平滑\"的曲线 A 而不是比较\"崎岖\"的曲线 R\n归纳偏好可看作学习算法自身在一个可能很庞大的假设空间中对假设进 行选择的启发式或\"价值观\"那么，有没有一般性的原则来引导算法确立\n\"正确的\"偏好呢? \"奥卡姆剃刀\" (Occam's razor) 是一种常用的、自然科学\n研究中最基本的原则，即\"若有多个假设与观察一致，则选最简单的那个\"如 果采用这个原则，并且假设我们认为\"更平滑\"意味着\"更简单\" (例如曲线\nA 更易于描述，其方程式是 y = _X2 + 6x + 1 ，而曲线 B 则要复杂得多) ，则在\n图1. 3 中我们会自然地偏好\"平滑\"的曲线 A.\n然而，奥卡姆剃刀并非唯一可行的原则.退一步说，即使假定我们是奥卡姆 剃刀的铁杆拥走，也需注意到，奥卡姆剃刀本身存在不同的诠释，使用奥卡姆剃 刀原则并不平凡.例如对我们已经很熟悉的西瓜问题来说，\"假设 1: 好瓜件\n^ ^ (色泽= *) (根蒂=蜷缩)八(敲声=浊响)\"和假设 2: \"好瓜件(色泽= *)\n(根蒂=蜷缩)八(敲声= *)\"这两个假设，哪一个更\"简单\"呢?这个问题并不 简单，需借助其他机制才能解决.\n事实上，归纳偏好对应了学习算法本身所做出的关于\"什么样的模型更 好\"的假设.在具体的现实问题中，这个假设是否成立，即算法的归纳偏好是否 与问题本身匹配，大多数时候直接决定了算法能否取得好的性能.\n让我们再回头看看图1. 3. 假设学习算法 Zα 基于某种归纳偏好产生了对应 于曲线 A 的模型，学习算法 ~b 基于另一种归纳偏好产生了对应于曲线 B 的模 型.基于前面讨论的平滑曲线的某种\"描述简单性\"?我们满怀信心地期待算 法乌比岛更好.确实，图1. 4(a) 显示出?与 B 相比， A 与训练集外的样本更一 致;换言之， A 的泛化能力比 B 强.\n\n8\n\n第 1 置在绪\n\n论\n\ny\n\ny\n\n, ，.0-‘回\n\nB\nJ\n, ‘ BEES\n\n1;才;\n\n、。 咽'\n\nB\n/\nS飞 。\n\n、\n、。、\n\n(a) A 优于 B\n\n(b) B 优于 A\n\n国1. 4 没有免费的午餐(黑点:训练、样本;白点:测试样本)\n\n但是，且慢!虽然我们希望并相信乌比马更好，但会不会出现图1.4(b) 的 情况:与 A 相比， B 与训练集外的样本更一致?\n\n很遗憾，这种情况完全可能出现.换言之，对于一个学习算法鸟，若它在某\n\n些问题上比学习算法岛好，则必然存在另一些问题，在那里岛比 2α 好.有趣 的是，这个结论对任何算法均成立，哪怕是把本书后面将要介绍的一些聪明算\n\n法作为乌而将\"随机胡猜\"这样的笨拙算法作为乌.惊讶吗?让我们看看下\n\n这里只用到一些非常基 础的数学知识，只准备读 第 1 幸且有\"数学恐惧\" 的读者可以跳过这个部分 而不会影响理解，只需相 信，上面这个看起来\"匪 夷所思\"的结论确实是成\n立的.\n\n面这个简短的讨论: 为简单起见，假设样本空间 X 和假设空间组都是离散的.令 P(hIX，'ca)\n代表算法乌基于训练数据 X 产生假设 h 的概率，再令 f 代表我们希望学习的 真实目标函数 . 'ca 的\"训练集外误差\"，即鸟在训练、集之外的所有样本上的 误差为\nEote(乌 IX， f) 二三二三二 P(x) lI (h 忡忡 f(x))P(h I x，，cα) ， (1.1)\nh æEX-X\n\n其中1I(. )是指示函数，若·为真则取值 1 ，否则取值 o. 考虑二分类问题，且真实目标函数可以是任何函数 X 叶 {O ， l} ，函数空间\n为 {O ， l}IXI. 对所有可能的 f 按均匀分布对误差求和，有\n\n若 f 均匀分布，则有一 半的 f.对面的预测与 h(æ) 不一致.\n\n三二 ιdαIX，f) =艺 2二三二 P(x) lI(h(x) 纠 (x)) P(h I X，乌)\n\nf\n\nf h æεX…X\n\n=汇 P(x) 艺 P(h I X ,'ca) L)(h(x) 并 f(x))\n\n= L P(x) 艺 P(h I X ,'ca)~2IXI\n\næEX-X\n\nh\n\n=jHZKZ) 汇 P例 X，'ca)\n\nzε X-X\n\nh\n\n1.4 归纳偏好\n\n9\n\n= 21.1'1-1 三二 P(æ). 1 .\næE二 .1' -x\n\n(1. 2)\n\n严格的 NFL 定理证明比 这里的简化论述繁难得多.\n\n式(1. 2) 显示出，总误差竟然与学习算法无关!对于任意两个学习算法乌和\n\n鸟，我们都有\n\n三二 ιte(~αIX，f) =汇 ιte(~bIX， f) ,\n\n(1.3)\n\nf\n\nf\n\n也就是说，无论学习算法乌多聪明、学习算法鸟多笨拙，它们的期望性能竟\n\n然相同!这就是\"没有免费的午餐\"定理 (No Free Lunch Theorem，简称 NFL 定理) [Wolpert, 1996; Wolpert and Macready, 1995].\n\n这下子，读者对机器学习的热情可能被一盆冷水浇透了:既然所有学习算 法的期望性能都跟随机胡猜差不多，那还有什么好学的?\n\n我们需注意到， NFL 定理有一个重要前提:所有\"问题\"出现的机会相 同、或所有问题同等重要.但实际情形并不是这样.很多时候，我们只关注自 己正在试图解决的问题(例如某个具体应用任务)，希望为它找到一个解决方案， 至于这个解决方案在别的问题、甚至在相似的问题上是否为好方案，我们并不 关心.例如，为了快速从 A 地到达 B 地，如果我们正在考虑的 A 地是南京鼓· 楼、 B 地是南京新街口，那么\"骑自行车\"是很好的解决方案;这个方案对 A 地是南京鼓楼、 B 地是北京新街口的情形显然很糟糕，但我们对此并不关心.\n\n事实上，上面 NFL 定理的简短论述过程中假设了 f 的均匀分布，而实际情\n形并非如此.例如，回到我们熟悉的西瓜问题，考虑{假设 1: 好瓜件(色泽= *)\n^ 八(根蒂=蜷缩)八(敲声=浊响)}和{假设 2: 好瓜村(色泽= *) (根蒂=硬挺)\n^ (敲声:清脆)}.从 NFL 定理可知，这两个假设同样好.我们立即会想到符\n合条件的例子，对好瓜(色泽=青绿;娘蒂=蜷缩;敲声=浊响)是假设 1 更好，而 对好瓜(色泽=乌黑;根蒂=硬挺;敲声=清脆)则是假设 2 更好.看上去的确是\n这样.然而需注意到， \" (根蒂=蜷缩;敲声=浊晌)\"的好瓜很常见，而\"(根\n蒂:硬挺;敲声 z 清脆)\"的好瓜罕见，甚至不存在.\n\n所以， NFL 走理最重要的寓意?是让我们清楚地认识到，脱离具体问题，空 泛地谈论\"什么学习算法更好\"毫无意义，因为若考虑所有潜在的问题，贝。所 有学习算法都一样好.要谈论算法的相对优劣，必须要针对具体的学习问题;在 某些问题上表现好的学习算法，在另一些问题上却可能不尽如人意，学习算法 自身的归纳偏好与问题是否相配，往往会起到决定性的作用.\n\n10\n\n第 1 章绪论\n\n1. 5 发展历程\n\n所谓\"知识就是力量>>\n1965 年， Feigenbaum 主 持研制了世界丰第一个专 家系统 DENDRAL.\n\n机器学习是人工智能 (artificial intelligence)研究发展到一定阶段的必然产 物.二十世纪五十年代到七十年代初，人工智能研究处于\"推理期\"，那时人们 以为只要能赋予机器逻辑推理能力，机器就能具有智能.这一阶段的代表性工\n作主要有 A. Newell 和 H. Simon 的\"逻辑理论家\" (Logic Theorist)程序以及 此后的\"通用问题求解\" (General Problem Solving) 程序等，这些工作在当时\n取得了令人振奋的结果.例如\"逻辑理论家\"程序在 1952 年证明了著名数学 家罗素和怀特海的名著《数学原理》中的 38 条定理 7 在 1963 年证明了全部 52\n条定理，特别值得一提的是，定理 2.85 甚至比罗素和怀特海证明得更巧妙. A.\nNewell 和 H. Simon 因为这方面的工作获得了 1975 年圈灵奖.然而?随着研究 向前发展，人们逐渐认识到，仅具有逻辑推理能力是远远实现不了人工智能的-\nE. A. Feigenbau日1 等人认为，要使机器具有智能?就必须设法使机器拥有知识.\n在他们的倡导下，从二十世纪七十年代中期开始，人工智能研究进入了\"知识 期\"在这一时期，大量专家系统问世，在很多应用领域取得了大量成果 .E.A. Feigenbaum 作为\"知识工程\"之父在 1994 年获得图灵奖.但是，人们逐渐认 识到，专家系统面临\"知识工程瓶颈\"，简单地说，就是由人来把知识总结出来 再教给计算机是相当困难的.于是?一些学者想到，如果机器自己能够学斗知识 该多好!\n\n参见 p.22\n\n事实上，图灵在 1950 年关于图灵测试的文章中?就曾提到了机器学习的可 能;二十世纪五十年代初已有机器学习的相关研究，例如 A. Samucl 著名的跳\n棋程序.五十年代中后期 7 基于神经网络的\"连接主义\" (conncctionism) 学习\n开始出现?代表性工作有 F. Rosenblatt 的感知机 (Perceptron) 、 B. Widrow 的 Adaline 等.在六七十年代，基于逻辑表示的\"符号主义\" (symbolism) 学习技\n术建勃发展，代表性王作有 P. Winston 的\"结构学习系统\"、R. S. Michalski 等人的\"基于逻辑的归纳学习系统'人E. B. Hunt 等人的\"概念学习系统\"\n等;以决策理论为基础的学习技术以及强化学习技术等也得到发展，代表性份工\n作有 N. J. Nilson 的\"学习机器\"等·二十多年后红极一时的统计学习理论的\n一些奠基性结果也是在这个时期取得的.\n\nIWIVIL 后来发展为国际 机器学习会议 ICIVIL\n\n1980 年夏，在美国卡耐基梅隆大学举行了第一届机器学习研讨会 (IWML); 同年， ((策略分析与信息系统》连出三期机器学习专辑; 1983 年， Tioga 山版社\n出版了R. S. Michalski、 J. G. Carbonell 和 T. Mitchell 主编的《机器学习:一 种人工智能途径)) [Michalski et al., 1983] ，对当时的机器学习研究工作进行了\n总结; 1986 年 7 第→本机器学习专业期刊 Machine LeαTηing 创刊; 1989 年，人\n\n1.5 发展历程\n\n11\n\n工智能领域的权威期刊 Artificial Intelligence 出版机器学习专辑，刊发了当时\n一些比较活跃的研究工作?其内容后来出现在 J. G. Carbonell 主编、 MIT 出 版社 1990 年的《机器学习:范型与方法>> [Carbonell, 1990] 一书中.总的来看，\n二十世纪八十年代是机器学习成为一个独立的学科领域、各种机器学习技术 百花初绽的时期.\n\nR. S. Michalski 等人 [Michalski et al., 1983] 把机器学习研究划分为\"从样\n例中学习\" \"在问题求解和规划中学习\" \"通过观察和发现学习\" \"从指令\n中学习\"等种类; E. A. Feigenbaum 等人在著名的《人工智能手册>> (第二卷) [Cohen and Feigenbau日1 ， 1983] 中，则把机器学习划分为\"机械学习\" \"示教\n学习\" \"类比学习\"和\"归纳学习\"机械学习亦称\"死记硬背式学习\"，即 把外界输入的信息全部记录下来，在需要时原封不动地取出来使用?这实际上 没有进行真正的学习?仅是在进行信息存储与检索;示教学习和类比学习类似\n于R. S. Michalski 等人所说的\"从指令中学习\"和\"通过观察和发现学习\"\n归纳学习相当于\"从样例中学习\"，即从训练样例中归纳出学习结果.二十世 纪八十年代以来，被研究最多、应用最广的是\"从样例中学习\" (也就是广义 的归纳学习) ，它涵盖了监督学习、无监督学习等，本书大部分内容均属此范畴. 下面我们对这方面主流技术的演进做一个简单回顾.\n\n参几第 4 幸.\n这时实际是 ILP 的前身 参见第 15 章\n\n在二十世纪八十年代，\"从样例中学习\"的一大主流是符号主义学习， 其代表包括决策树 (decision tree) 和基于逻辑的学习.典型的决策树学习以信 息论为基础，以信息娟的最小化为目标，直接模拟了人类对概念进行判定的\n树形流程.基于逻辑的学习的著名代表是归纳逻辑程序设计 (Inductive Logic\nProgramming，简称 ILP) ，可看作机器学习与逻辑程序设计的交叉，它使用一 阶逻辑(即谓词逻辑)来进行知识表示，通过修改和扩充逻辑表达式(例如 Prolog 表达式)来完成对数据的归纳.符号主义学习占据主流地位与整个人工智能领域 的发展历程是分不开的.前面说过，人工智能在二十世纪五十到八十年代经历 了\"推理期\"和\"知识期\"，在\"推理期\"人们基于符号知识表示、通过演绎 推理技术取得了很大成就，而在\"知识期\"人们基于符号知识表示、通过获取 和利用领域知识来建立专家系统取得了大量成果，因此，在\"学习期\"的开始? 符号知识表示很自然地受到青睐.事实上 7 机器学习在二十世纪八十年代正是 被视为\"解决知识工程瓶颈问题的关键\"而走上人工智能主舞台的.决策树学 习技术由于简单易用，到今天仍是最常用的机器学习技术之一. ILP 具有很强 的知识表示能力，可以较容易地表达出复杂数据关系，而且领域知识通常可方 便地通过逻辑表达式进行描述，因此， ILP 不仅可利用领域知识辅助学习，还可\n\n12\n参见第 5 幸. 参见第 6 章. 参见习题 6.5.\n\n第 1 章绪论\n通过学习对领域知识进行精化和增强;然而，成也萧何、败也萧何，由于表示能 力太强，直接导致学习过程面临的假设宅间太大、复杂度极高?因此，问题规模 稍大就难以有效进行学习，九十年代中期后这方面的研究相对陷入低潮.\n二十世纪九十年代中期之前，\"从样例中学习\"的另一主流技术是基于神 经网络的连接主义学习.连接主义学习在二十世纪五十年代取得了大发展，但 因为早期的很多人工智能研究者对符号表示有特别偏爱?例如图灵奖得主 E Simon 曾断言人工智能是研究\"对智能行为的符号化建模\"，所以当时连接主 义的研究未被纳入主流人工智能研究范畴.尤其是连接主义自身也遇到了很大\n的障碍?正如图灵奖得主 M. Minsky 丰11 S. Papert 在 1969 年指出， (当时的)神经\n网络只能处理线性分类 7 甚至对\"异或\"这么简单的问题都处理小了. 1983 年，\nJ. J. Hopfield 利用神经网络求解\"流动推销员问题\"这个著名的 NP 难题取得 重大进展，使得连接主义重新受到人们关注. 1986 年， D. E. Rumelhart 等人重\n新发明了著名的 BP 算法，产生了深远影响.与符号主义学习能产生明确的概 念表示不同，连接主义学习产生的是\"黑箱\"模型，因此从知识获取的角度来 看?连接主义学习技术有明显弱点;然而，由于有 BP 这样有效的算法，使得它 可以在很多现实问题上发挥作用.事实上， BP 一直是被应用得最广泛的机器 学习算法之一.连接主义学习的最大局限是其\"试错性 'p; 简单地说?其学习过 程涉及大量参数，而参数的设置缺乏理论指导，主要靠于工\"调参\"夸张一点 说，参数调节上失之毫厘，学习结果可能谬以千里.\n二十世纪九十年代中期\"统计学习\" (statistical learning) 闪亮登场并 迅速占据主流舞台，代表性技术是支持向量机 (Support Vector Machine ，简称 SVM) 以及更一般的\"核方法\" (kernel methods). 这方面的研究早在二十世\n纪六七十年代就已开始，统计学习理论 [Vapnik， 1998] 在那个时期也已打下\n了基础?例如 V. N. Vapnik 在 1963 年提出了\"支持向量\"概念，他和 A. J.\nChervonenkis 在 1968 年提出 VC 维，在 1974 年提出了结构风险最小化原则等. 但直到九十年代中期统计学习才开始成为机器学习的主流，一方面是由于有效 的支持向量机算法在九十年代初才被提出，其优越性能到九十年代中期在文 本分类应用中才得以显现;坤一方面，正是在连接主义学习技术的局限性凸显 之后，人们才把目光转向了以统计学习理论为直接支撑的统计学习技术.事实 上，统计学习与连接主义学习有密切的联系.在支持向量机被普遍接受后，核技 巧 (kernel trick) 被人们用到了机器学习的几乎每一个角落，核方法也逐渐成为 机器学习的基本内容之一.\n有趣的是?二十一世纪初，连接主义学习又卷土重来，掀起了以\"深度学\n\n1.6 应用现状\n\n13\n\n参见 5.6 节 \"过拟俨参见第 2 章\n\n习\"为名的热潮.所谓深度学习?狭义地说就是\"很多层\"的神经网络.在若 干测试和竞赛上，尤其是涉及语音、图像等复杂对象的应用中，深度学习技术 取得了优越性能.以往机器学习技术在应用中要取得好性能，对使用者的要求 较高;而深度学习技术涉及的模型复杂度非常高，以至于只要下工夫\"调参 把参数调节好?性能往往就好.因此，深度学习虽缺乏严格的理论基础，但它显 著降低了机器学习应用者的门槛，为机器学习技术走向工程实践带来了便利. 那么?它为什么此时才热起来呢?有两个基本原因:数据大了、计算能力强了 深度学习模型拥有大量参数?若数据样本少，则很容易\"过拟合\".如此复杂的 模型、如此大的数据样本 7 若缺乏强力计算设备，根本无法求解.恰由于人类进 入了\"大数据时代 习技术焕发又一春.有趣的是，神经网络在二十世纪八十年代中期走红，与当时\nIntel x86 系列微处理器与内存条技术的广泛应用所造成的计算能力、数据访\n存效率比七十年代有显著提高不无关联.深度学习此时的状况，与彼时的神经 网络何其相似.\n需说明的是?机器学习现在已经发展成为一个相当大的学科领域，本节仅 是管中窥豹，很多重要技术都没有谈及，耐心的读者在读完本书后会有更全面 的了解.\n\n1. 6 应用现状\n在过去二十年中，人类收集、存储、传输、处理数据的能力取得了飞速提 升，人类社会的各个角落都积累了大量数据，亟需能有效地对数据进行分析利 用的计算机算法?而机器学习恰顺应了大时代的这个迫切需求，因此该学科领 域很自然地取得巨大发展、受到广泛关注.\n今天?在计算机科学的诸多分支学科领域中?无论是多媒体、图形学，还是 网络通信、软件工程，乃至体系结构、芯片设计?都能找到机器学习技术的身 影，尤其是在计算机视觉、自然语言处理等\"计算机应用技术\"领域，机器学 习已成为最重要的技术进步源泉之一.\n机器学习还为许多交叉学科提供了重要的技术支撑.例如\"生物信息 学\"试图利用信息技术来研究生命现象和规律，而基因组计划的实施和基因药 物的美好愿景让人们为之心潮薛湃.生物信息学研究涉及从\"生命现象\"到 \"规律发现\"的整个过程，其间必然包括数据获取、数据管理、数据分析、仿 真实验等环节，而\"数据分析\"恰是机器学习技术的舞台，各种机器学习技术 已经在这个舞台上大放异彩.\n\n14\n\n第 1 章绪论\n\nNASA-JPL 的全称是美\n国航空航天局喷气推进实\n验室，著名的\"勇气\"号\nZJZ;;225;\nDARPA 的全称是美国 国防部先进研究计划局， 互联网、全球卫星定位系 统等都源于 DARPA 启动 的研究项目\n机器学习提供数据分析 能力，云计算提供数据处 理能力，众包提供数据标 记能力.\n\n事实上，随着科学研究的基本手段从传统的\"理论十实验\"走向现在的 \"理论+实验十计算\"?乃至出现\"数据科学\"这样的提法?机器学习的重要 性日趋显著，因为\"计算\"的目的往往是数据分析，而数据科学的核心也恰是 通过分析数据来获得价值.若要列出目前计算机科学技术中最活跃、最受瞩\n目的研究分支，那么机器学习必居其中. 2001 年?美国 NASA-JPL 的科学家\n7\n在 Science 杂志上专门撰文 [Mjolsness and DeCoste, 2001] 指出，机器学习对\n科学研究的整个过程正起到越来越大的支撑作用?其进展对科技发展意义重大\n2003 年， DARPA 启动 PAL 计划， i号机器学习的重要'性上升到美国国家安全的 高度来考虑.众所周知，美国最尖端科技的研究通常是由 NASA 和 DARPA 推 进的，而这两大机构不约而同地强调机器学习的重要性，其意义不言而喻\n2006 年，卡耐基梅隆大学宣告成立世界上第一个\"机器学习系\"，机器学\n习领域奠基人之- T. Mitchell 教授出任首任系主任. 2012 年 3 月 7 美国奥巴马\n政府启动\"大数据研究与发展计划\"，美国国家科学基金会旋即在加州大学伯 克利分校启动加强计划，强调要深入研究和整合大数据时代的三大关键技术: 机器学习、云计算、众包 (crowdsourcing) .显然，机器学习在大数据时代是必 不可少的核心技术，道理很简单:收集、存储、传输、管理大数据的目的，是为 了\"利用\"大数据?而如果没有机器学习技术分析数据?则\"利用\"无从谈起.\n\n\"数据挖掘\"这个词很 早就在统计学界出现并略 带贬义，这是由于传统统 计学研究往往醉心于理论 的优美而忽视实际效用. 但最近情况发生变化，越 来越多的统计学家开始关 注现实问题，进入机器学 习和数据挖掘领域-\n\n谈到对数据进行分析利用，很多人会想到\"数据挖掘\" (data mining) ，这\n里简单探讨一下数据挖掘与机器学习的联系.数据挖掘领域在二十世纪九十年 代形成，它受到很多学科领域的影响，其中数据库、机器学习、统计学无疑影 响最大 [Zhou， 2003]. 数据挖掘是从海量数据中发掘知识，这就必然涉及对\"海 量数据\"的管理和分析.大体来说，数据库领域的研究为数据挖掘提供数据管 理技术?而机器学习和统计学的研究为数据挖掘提供数据分析技术.由于统计 学界的研究成果通常需要经由机器学习研究来形成有效的学习算法，之后再进 入数据挖掘领域，因此从这个意义上说，统计学主要是通过机器学习对数据挖 掘发挥影响，而机器学习领域和数据库领域则是数据挖掘的两大支撑.\n\n今天，机器学习己经与普通人的生活密切相关.例如在天气预报、能源勘 探、环境监测等方面，有效地利用机器学习技术对卫星和传感器发国的数据进 行分析，是提高预报和检测准确性的重要途径;在商业营销中?有效地利用机器 学习技术对销售数据、客户信息进行分析，不仅可帮助商家优化库存降低成本， 还有助于针对用户群设计特殊营销策略;……下面再举几例;\n\n众所周知，谷歌、百度等互联网搜索引擎己开始改变人类的生活方式，例 如很多人已习惯于在出行前通过互联网搜索来了解目的地信息、寻找合适的\n\n1.6 应用现状\n\n15\n\n酒店、餐馆等.美国《新闻周刊》曾对谷歌有一句话评论\"它使任何人离任 何问题的答案间的距离变得只有点击一下鼠标这么远\"显然，互联网搜索是 通过分析网络上的数据来找到用户所需的信息，在这个过程中，用户查询是输 入、搜索结果是输出，而要建立输入与输出之间的联系，内核必然需要机器学 习技术.事实上，互联网搜索发展至今，机器学习技术的支撑居功至伟.到了今 天，搜索的对象、内容日趋复杂，机器学习技术的影响更为明显，例如在进行\n\"图片搜索\"时?无论谷歌还是百度都在使用最新潮的机器学习技术.谷歌、 百度、脸书、雅虎等公司纷纷成立专攻机器学习技术的研究团队，甚至直接以 机器学习技术命名的研究院，充分体现出机器学习技术的发展和应用，甚至在 一定程度上影响了互联网产业的走向\n\n例如著名机器学习教科 书 [Mitchell. 1997]4.2 节介 绍了二十世纪九十年代早 期利用神经网络学习来控 制自动驾驶车的 ALVINN 系统\n\n再举一例.车祸是人类最凶险的杀手之丁全世界每年有上百万人丧生车 轮?仅我国每年就存约十万人死于车祸.由计算机来实现自动汽车驾驶是一个 理想的方案，因为机器上路时可以确保不是新手驾驶、不会波劳驾驶，更不会 酒后驾驶，而且还有重要的军事用途.美国在二十世纪八十年代就开始进行这 方面研究.这里最大的困难是无法在汽车厂里事先把汽车上路后所会遇到的所 有情况都考虑到、设计出处理规则并加以编程实现，而只能根据上路时遇到的 情况即时处理.若把车载传感器接收到的信息作为输入?把方向、刹车、油门 的控制行为作为输出，则这里的关键问题怆可抽象为→个机器学习任务 .2004 年 3 月，在美国 DARPA 组织的自动驾驶车比赛中 3 斯坦福大学机器学习专家\nS. Thrun 的小组研制的参赛车用 6 小时 53 分钟成功走完了 132 英里赛程获得\n冠军.比赛路段是在内华达州西南部的山区和沙漠中 7 路况相当复杂，在这样的\n路段上行车即使对经验丰富的人类司机来说也是一个挑战. S. Thrun 后来到谷\n歌领导自动驾驶牢项目团队.值得…提的是自动驾驶车在近几年取得了飞跃 式发展，除谷歌外?通用、奥迪、大众、宝马等传统汽车公司均投入巨资进行 研发，目前已开始有产品进入市场. 2011 年 6 月，美国内华达州议会通过法案? 成为美国第一个认可自动驾驶车的州，此后，夏威夷州和佛罗里达州也先后通 过类似法案，自动驾驶汽车可望在不久的将来出现在普通人的生活中，而机器 学习技术则起到了\"司机\"作用.\n\n机器学习技术甚至己影响到人类社会政治生活. 2012 年美国大选期间，奥 巴马磨下有一支机器学习团队，他们对各类选情数据进行分析，为奥巴马提示 下一步竞选行葫.例如他们使用机器学习技术分析社交网络数据，判断出在总 统候选人第一次辩论之后哪些选民会倒戈，并根据分析的结果开发出个性化宣 传策略，能为每位选民找出一个最有说服力的挽留理由;他们基于机器学习模\n\n16\n\n第 1 章绪论\n\n型的分析结果提示奥巳马应去何处开展拉票活动，有些建议甚至让专业竞选顾 问大吃一惊，而结果表明去这些地方大有收获.总统选举需要大量金钱，机器 学习技术在这方面发挥了奇效.例如，机器学习模型分析出，某电影明星对某 地区某年龄段的特定人群很有吸引力?而这个群体很愿意出高价与该明星及奥 巴马共进晚餐... .....果然，这样一次筹资晚宴成功募集到 1500 万美元;最终，借 助机器学习模型，奥巴马筹到了创纪录的 10 亿美元竞选经费.机器学习技术不 仅有助于竞选经费\"开源\"还可帮助\"节流 \"7 例如机器学习模型通过对不 同群体选民进行分析，建议购买了→些冷门节目的广告时段，而没有采用在昂 贵的黄金时段购买广告的传统做法，使得广告资金效率相比 2008 年竞选提高 了 14%; ……胜选后， ((时代》周刊专门报道了这个被奥巴马称为\"竞选核武 器\"、由半监督学习研究专家R. Ghani 领导的团队.\n值得一提的是，机器学习备受瞩目当然是由于它已成为智能数据分析技术 的创新源泉 7 但机器学习研究还有另一个不可忽视的意义，即通过建立一些关 于学习的计算模型来促进我们理解\"人类如何学习\"例如， P. Kanerva 在二\n十世纪八十年代中期提出 SDM (Sparse Distributed Memory)模型 [Kanerva，\n1988] 时并没有刻意模仿脑生理结构，但后来神经科学的研究发现， SDM 的稀 疏编码机制在视觉、昕觉、嗅觉功能的脑皮层中广泛存在，从而为理解脑的某 些功能提供了一定的启发.自然科学研究的驱动力归结起来无外是人类对宇宙 本源、万物本质、生命本性、自我本识的好奇，而\"人类如何学习\"无疑是一 个有关自我本识的重大问题.从这个意义上说，机器学习不仅在信息科学中占 有重要地位，还具有一定的自然科学探索色彩.\n\n1. 7 阅读材料\n\nWEKA 是著名的免费 机器学习算法程序库，由 新西兰 Wail咀t。大学研 究人员基于 JAVA 开发 ι\nhttp://www.cs.waikato. ac.nz/ml/weka j.\n\n[Mitchell, 1997] 是第一本机器学习专门性教材， [Duda et al., 2001; Alc paydin, 2004; Flach, 2012] 都是出色的入门读物. [Hastie et al. , 2009] 是很好 的进阶读物， [Bishop, 2006] 也很有参考价值?尤其适合于贝叶斯学习偏好者. [Shalev-Shwartz and Ben-David, 2014] 则适合于理论偏好者. [Witten et 此， 2011] 是基于 WEKA 撰写的入门读物 7 有助于初学者通过 WEKA 实践快速掌\n握常用机器学习算法.\n本书1. 5 和1. 6 节主要取材于[周志华， 2007]. ((机器学习:一种人工智能\n途径)) [Michalski et al., 1983] 汇集了 20 位学者撰写的 16 篇文章，是机器学习 早期最重要的文献.该书出版后产生了很大反响， Morgan Kaufmann 出版社后\n来分别于 1986 年和 1990 年出版了该书的续篇，编为第二卷和第二卷. ((人工\n\n1.7 阅读材料\n\n17\n\n深度学习参见 5.6 节\n\n智能手册》系列是图灵奖得主 E. A. Feigenbau日1 与不同学者合作编写而成，该 书第三卷 [Cohen and Feigenbaum, 1983] 对机器学习进行了讨论，是机器学习 早期的重要文献. [Dietterich, 199可对机器学习领域的发展进行了评述和展望.\n早期的很多文献在今天仍值得重视，一些闪光的思想在相关技术进步后可能焕\n发新的活力，例如近来流行的\"迁移学习\" (transfer learning) [Pan and Yang, 2010] ，恰似\"类比学习\" (1earning by analogy) 在统计学习技术大发展后的升 级版;红极一时的\"深度学习\" (deep learning) 在思想上井未显著超越二十世 纪八十年代中后期神经网络学习的研究.\n\n规则学习参见第 15 章\n\n机器学习中关于概念学习的研究开始很早，从中产生的不少思想对整个 领域都有深远影响.例如作为主流学习技术之一的决策树学习，就起源于关\n于概念形成的树结构研究 [Hu日.t and Hovlar吨 1963]. [Winston, 1970] ;在著\n名的\"积木世界\"研究中，将概念学习与基于泛化和特化的搜索过程联系起\n来. [Simon and Lea, 1974] 较早提出了\"学习\"是在假设空间中搜索的观点. [Mitchell, 197句稍后提出了版本空间的概念.概念学习中有很多关于规则学习\n的内容.\n\n集成学习参见第 8 章.\n\n奥卡姆剃刀原则主张选择与经验观察一致的最简单假设 7 它在自然科学如 物理学、天文学等领域中是一个广为沿用的基础性原则，例如哥白尼坚持\"日 心说\"的理由之一就是它比托勒密的\"地心说\"更简单且符合天文观测.奥\n卡姆剃刀在机器学习领域也有很多追随者 [Blumer et al., 1996]. 但机器学习\n中什么是\"更简单的\"这个问题一直困扰着研究者们，因此，对奥卡姆剃刀在\n机器学习领域的作用一直存在着争议阳\"ebb ， 1996; Domingo民 1999]. 需注意\n的是，奥卡姆剃刀并非科学研究中唯一可行的假设选择原则，例如古希腊哲学\n家伊壁坞鲁(公元前341年一前270年)提出的\"多释原则\" (principle of multiple explanations) ，主张保留与经验观察一致的所有假设 [Asmis ， 1984]，这与集成\n学习 (ensemble learning) 方面的研究更加吻合.\n机器学习领域最重要的国际学术会议是国际机器学习会议 (ICML) 、国际 神经信息处理系统会议 (NIPS) 和国际学习理论会议 (COLT) ，重要的区域性会 议主要有欧洲机器学习会议 (ECML) 和亚洲机器学习会议 (ACML); 最重要的\n国际学术期刊是 Journal of Machine Learning Research 和 Machine Learning. 人工智能领域的重要会议如 IJCAI、 AAAI 以及重要期刊如 Art侨c归1 Intelligence 、 Journal of Art听cial Intelligence Reseαrch， 数据挖掘领域的重要会议 如 KDD 、 ICDM 以及重要期刊如 ACM Transactions on Knowledge Discovery fromDα归、 Dαtα Mining and Knowledge Discovery， 计算机视觉与模式识别\n\n18.\n\n第 1 章绪论\n\n领域的重要会议如 CVPR 以及重要期刊如 IEEE Transactions on Pattem Analysis and Machine Intelligence， 神经网络领域的重要期刊如 Neural Computation 、 IEEE Transaιtions on Neural Networks αηd Leαming 8ystems 等\n也经常发表机器学习方面的论文.此外，统计学领域的重要期刊如 Annals 旷 8tαtistics 等也常有关于统计学习方面的理论文章发表.\n国内不少书籍包含机器学习方面的内容，例如[陆汝铃， 1996]. [李航， 2012] 是以统计学习为主题的读物.国内机器学习领域最主要的活动是两年一次 的中国机器学习大会 (CCML) 以及每年举行的\"机器学习及其应用\"研讨 会 (MLA); 很多学术刊物都经常刊登有关机器学习的论文.\n\n习题\n\n19\n\n习题\n\n1.1 表1. 1 中若只包含编号为 1 和 4 的两个样例?试给出相应的版本空间.\n\n析合范式即多个合取式 的析取 z\n\n1.2 与使用单个合取式来进行假设表示相比，使用\"析合范式\"将使得假\n设空间具有更强的表示能力.例如\n好瓜件((色泽=们(根蒂=蜷缩) ^(敲声= *))\nv ((色泽=乌黑) ^(根蒂=们(敲声=沉闷)) ,\n\n提示注意冗余情况，\n如 (A= α) V (A = *)\n与 (A = *)等价.\n\n会把\"(色泽=青绿)八(根蒂=蜷缩)八(敲声=清脆)\"以及\"(色泽=\n^ 乌黑) (根蒂=硬挺)八(敲声=沉闷)\"都分类为\"好瓜\"若使用最\n多包含 k 个合取式的析合范式来表达表1. 1 西瓜分类问题的假设空\n间 7 试估算共有多少种可能的假设.\n\nI!p 不存在训练错误为 0 的假设\n\n1.3 若数据包含噪声，则假设空间中有可能不存在与所有训练样本都一致\n的假设在此情形下，试设计一种归纳偏好用于假设选择.\n\n1.4*\n\n本章1. 4 节在论述\"没有免费的午餐\"定理时，默认使用了\"分类错 误率\"作为性能度量来对分类器进行评估.若换用其他性能度最孔则 式(1. 1) 将改为\n\nEote(i:，αIX，!) = 2二三二 p(x)e(h(x) ，J (x))P(h I X， 刻，\nh æε x-x\n试证明\"没有免费的午餐定理\"仍成立.\n\n1.5 试述机器学习能在互联网搜索的哪曲环节起什么作用.\n\n20\n\n第 1 章绪论\n\n参考文献\n\n陆汝铃. (1996). 人工智能(下册) .科学出版社，北京.\n周志华. (2007). \"机器学习与数据挖掘\"中国计算机学会通讯， 3(12):35-44.\n李航. (2012). 统计学习方法.清华大学出版社，北京.\nAlpaydin, E. (2004). Introduction to Machine Learning. MIT Press, Cambridge, MA.\nAsinis, E. (1984). Epicurus' Sc的tt侨c Method. Cornell University Press, Ithaca, NY.\nBishop, C. M. (2006). Pattern Recognition and Machine Learnir协 Springer ， New York, NY.\nBlumer, A. , A. Ehrenfeucht, D. Haussler, and M. K. Warml灿. (1996). - \"O咱c­\ncam'、s 阳 ra缸zor巳r.\"\nCa缸，r协 bonell ， J. G. , ed. (1990). Machine Learning: Pαradigms and Methods. MIT Press, Cambridge, MA.\nCohen, P. R. and E. A. Feige巾au日1 ， eds. (1983). The Hα， ndbook of Art~卢cial Intelligence, volume 3. William Kaufmann, New York, NY.\nDietterich, T. G. (1997). \"Machine learni吨 research: Four current directions.\"\nAIMα， .gazine， 18(4):97~136.\nDomi吨os ， P. (1999). \"The role of Occam's razor in knowledge discovery.\" Dαtα\nMining and Knoω ledge Discovery, 3(4) 油9-425. Duda, R. 0. , P. E. Hart, and D. G. Stork. (2001). Pattern Classi.声cαtion， 2nd\nedition. John 飞iViley & Sons, New York, NY. Flach, P. (2012). Machine Leαrning: The Art and Science of Algo时thms that\nMαke Sense of Datα. Cambridge University Press, Cambridge, UK.\nHand ，且， H. Mannila, and P. Smyth. (2001). Principles of Dαtα Mining. MIT\nPress, Cambridge, MA. Hastie, T. , R. Tibshira风 and J. Friedman. (2009). The Elements of Stαtistical\nLearning, 2nd edition. Springer, New York, NY. Hunt, E. G. and D. 1. Hovland. (1963). \"Programming a model of human con-\ncept ，fo岛r口ma旧，tion.\" 1丑 Compu时t化e附 r8， αη叫d Thought (E. Feige由au日1 and J. Feldma几 eds.) , 310-325, McGraw Hill, New York, NY.\n\n参考文献\n\n21\nKanerva, P. (1988). Spαrse Distributed Memory. MIT Press, Cambridge, MA. Michalski, R.丘， J. G. Carbonell, and T. M. Mitchell, eds. (1983). Machine\nLearning: An A付侨cial Intelligence Approαch. Tioga, Palo Alto, CA. Mitchell, T. (1997). Mαchine Learning. McGraw Hill, New York, NY. Mitchell, T. M. (1977). \"Version spaces: A candidate elimination approach to\nrule learning.\" In Proceedings of the 5th Internαtional Joint Confe陀nce on\nA付侨cial Intelligence (IJCA刀， 305-310, Cambridge, MA.\nMjolsne盹 E. and D. DeCoste. (2001). \"Machine learni吨 for science: State of\nthe art and future prospects.\" Science, 293(5537):2051-2055. Pan, S. J. and Q. Yang. (2010). 咀 survey of transfer learning.\" IEEE Trαns­\nαctions on Knowledge αnd Datα Engineering， 22(10):1345-1359.\nShalev-Shwartz, S. and S. Ben-David. (2014). Understanding Machine Learning. Cambridge University Press, Cambridge, UK.\nSimon, H. A. and G. Lea. (1974). \"Problem solving and rule induction: A unified view.\" In K noω ledge and Cognition (L. W. Gre腿， ed.) , 105-127, Erlbaum, New York, NY.\nVapnik, V. N. (1998). Stαtistical Learning Theo啡 Wiley， New York, NY. Webb, G. 1. (1996). \"F\\川her experimental evidence against the utility of Oc-\ncam's razor.\" Journal of Art~卢cial Intelligence Research, 43:397-417.\nWinston, P. H. (1970). \"Learning structural descriptions from examples.\" Technical Report AI-TR-231 , AI Lab, MIT, Cambridge, MA.\nWitten,1. 且， E. .Frank, and M. A. Hall. (2011). Dαtα Mining: Pmctical Machine Learing Tools αnd Techniques, 3rd edition. Elsevier, Burlington, MA.\nWolpe叽 D. H. (1996). \"The lack of a p巾ri distinctions between learning algorithms.\" Neural Computatio风 8(7) :1341-1390.\nWolpert, D. H. and W. G. Macready. (1995). \"No free lunch theorems for search.\" Technical Report SFI-TR-05-010, Santa Fe Institute, Sante Fe,\nNM.\nZhou, Z.-H. (2003). \"Three perspectives of data m扭扭g.\" Art~声ciallntelligence，\n143(1):139-146.\n\n22 休息一会儿\n\n第 1 章绪论\n\n小故事: \"机器学习\"名字的由来\n\n这个跳棋程序实质上使 用了强化学习技术，参见 第 16 章.\n\n1952 年，阿瑟·萨缪尔 (Arthur Samuel, 1901- 1990)\n在 IBM 公司研制了一个西洋跳棋程序，这 个程序具有自 学习 能力， 可通过对大量棋局的分析逐 渐辨识 出当前局 面 下的 \"好 棋\"和\"坏 棋'\\ 从而不断提高 弈棋 水平 ，并很 快就下 赢了 萨缪尔自己 1956 年，萨 缪尔应约 翰·麦 卡锡\n(John McCarthy, \"人工智能之父\" , 1971 年图灵奖得主 )之邀， 在标志着 人\n工智能学科诞生的达特茅斯会议上介绍这项工作.萨 缪尔发明了\"机器学习\" 这个词，将其定义为\"不显式编程地赋予计算机能力的研究领域\"他的文\n章 \"Some studies in machine learning using the game of checkers\" 1959 年在 IBMJournal 正式发表后 ， 爱德华·费根鲍姆 (Edward Feigenbau日1，\"知识工\n程之父\" ， 1994 年图灵 奖得 主)为编写其巨著 Computers and Thought， 在 1961\n年邀请萨缪尔提供 一 个该程序最好的对弈实例.于是，萨缪尔借机 向康涅 狄格 州的跳棋冠军、当时全美排名第四的棋手发起了挑战，结果萨缪尔程序获胜， 在当时引起轰动.\n\n事实上，萨缪尔跳棋程序不仅在人王智能领域产生了重大 影 响，还影响到 整个计算机科学的发展.早期计算机科学研究认为，计算机不可能完成事先没 有显式编程好的任务，而萨缪尔跳棋程序 否证了 这个假设 . 另外，这个程序是最 早在计算机上执行非数值计算任务的程序之一，其逻辑指 令设计思想极大地影 响 1 IBM 计算机的指令集， 并很快被其他计 算机 的设计者采用 .\n\n第 2 章 模型评估与选择\n\n2.1 经验误差与过拟合\n\n-;:;) 精度常写为百分比形式\n。- x 100%\n这里所说的\"误差\"均 指误差期望-\n在后面的章节中将介绍 不同的学习算法如何最小 化经验误差\n\n通常我们把分类错误的样本数占样本总数的比例称为\"错误率\" (error rate) ，即如果在 m 个样本中有 α 个样本分类错误，则错误率 E= α1m; 相应的，\n1 一 α1m 称为\"精度\" (acc旧acy) ，即\"精度 =1 一错误率\"更一般地，我们把\n学习器的实际预测输出与样本的真实输出之间的差异称为\"误差\" (error) , 学习器在训练集上的误差称为\"训练误差\" (training error) 或\"经验误 差\" (empirical error) ，在新样本上的误差称为\"泛化误差\" (generalization\nerror). 显然，我们希望得到泛化误差小的学习器.然而，我们事先并不知道新 样本是什么样，实际能做的是努力使经验误差最小化.在很多情况下，我们可以 学得一个经验误差很小、在训练集上表现很好的学习器，例如甚至对所有训练 样本都分类正确，即分类错误率为零，分类精度为 100% ，但这是不是我们想要 的学习器呢?遗憾的是，这样的学习器在多数情况下都不好.\n\n过拟合亦称\"过自己\" 欠拟合亦称\"欠配\"\n\n我们实际希望的，是在新样本上能表现得很好的学习器.为了达到这个 目的，应该从训练样本中尽可能学出适用于所有潜在样本的\"普遍规律\"，这 样才能在遇到新样本时做出正确的判别.然而，当学习器把训练样本学得\"太 好\"了的时候，很可能巳经把训练样本自身的一些特点当作了所有潜在样本都 会具有的一般性质，这样就会导致泛化性能下降这种现象在机器学习中称为 \"过拟合\" (overfitting). 与\"过拟合\"相对的是\"欠拟合\" (underfitting) ，这 是指对训练样本的一般性质尚未学好.图 2.1 给出了关于过拟合与欠拟含的一 个便于直观理解的类比.\n\n学习能力是否\"过于强 大，是由学习算法和数\n据内涵共同决定的\n\n有多种因素可能导致过拟合，其中最常见的情况是由于学习能力过于强大， 以至于把训练样本所包含的不太一般的特性都学到了，而欠拟合则通常是由 于学习能力低下而造成的欠拟合比较容易克服，例如在决策树学习中扩展分 支、在神经网络学习中增加训练轮数等，而过拟合则很麻烦.在后面的学习中 我们将看到，过拟合是机器学习面临的关键障碍，各类学习算法都必然带有一 些针对过拟合的措施;然而必须认识到，过拟合是无法彻底避免的，我们所能做 的只是\"缓解'气或者说减小其风险.关于这一点，可大致这样理解:机器学习 面临的问题通常是 NP 难甚至更难，而有效的学习算法必然是在多项式时间内\n\n24\n\n第 2 章模型评估与选择\n\n树 叶 训 练 样\n\n过拟合模型 分类结果 :\n\n→ 不是树叶\n\n新\n\n( 误以为树叶必 须有铅齿 )\n\n样\n\n本\n\n本\n\n欠拟合模型分类结 果. →是树叶\n(误 以为绿色 的都是树 叶)\n\n图 2.1 过拟合 、欠拟合的 直观类比\n运行完成 ，若可彻底避免过拟合， 则通过经验误差最小化就能获最优解，这 就意 味着我们 构造性地证 明了 \" P=NP\" ;因此7 只要 相信 \"p 并 NP \" ，过拟合就 不 可避免\n在现实任务中，我们往往有 多 种 学习算沾 了IJ供选择 ，甚至对同 - 个 学习算 法，当使用不同的参数配置 时 ?也会产生不 同的模 型 . 那么，我们 该选用 哪 -个\n学习算法、使用哪 一种参数配置呢?这就是机器学习 中的\" 模型选择\" (model\nselection) 问题.理想的解决方案当然是对候选模型的泛化误差进行 评估 7 然后 选择泛化误差最 小的那个模型.然而如上面所讨 论的，我们无法直接获得泛化 误 差，而训练误差又由于过拟 合现象的存在 而不 适 合 作为标准，那么，在 现 实中 如何进行模型评估与选择呢?\n\n2.2 评估方法\n\n在现实任务中往往还会\n考虑时间开信\n销、可解释性等方面的因 素误， 差 这里暂且只考虑泛化\n\n通常， 我们 可通过实验测试来对 学习器的泛化误差进行评估并进而做出 选\n择 为此， 需使用一个 \"测试集 \" (testing set)来测试学习器对新样本 的判别 能 力，然后 以 测试集上的\"测试误差\" (testing error) 作为 泛化误差的 近似通常\n我们假设测试样本也是 从样 本真实分布 中独立同分布采样 而得但需 注意 的 是，测试集应该尽可能 与训练集互斥， 即测试样本尽量不在 训练集 中出现、未 在训 练过程 中使用过.\n\n测试样本为什么要尽可能不出现在 训练集中呢?为理解这一 点 ，不妨考虑 这样一个场景:老师出了 10 道习题供同学们 练习 ，考试时老师又用 同样的这 10 道题作为试题，这个考试成绩 能否有效反 映出同学们 学得好不好呢?答案是否 定 的，可能有的同学只 会做这 10 道题却能得高分 .回到我们的问题上来，我们\n\n2.2 评估方法\n\n25\n\n希望得到泛化性能强的模型?好比是希望同学们对课程学得很好、获得了对所 学知识\"举一反三\"的能力;训练样本相当于给同学们练习的习题，测试过程 则相当于考试.显然，若测试样本被用作训练了，则得到的将是过于\"乐观\"的 估计结果.\n可是，我们只有一个包含 m 个样例的数据集 D={(叫 ， Yl) ,(X2 ,Y2) , … 7\n(Xm ， Ym)} ， 既要训练，又要测试，怎样才能做到呢?答案是:通过对 D 进行适当 的处理，从中产生出训练集 S 和测试集 T. 下面介绍儿种常见的做法.\n\n2.2.1 留出法\n\n\"留出法\" (hold-out) 直接将数据集 D 划分为两个互斥的集合?其中一个 集合作为训练集 5 ，另一个作为测试集 T， 即 D=BUT ， 5 门 T= 正~.在 S 上训 练出模型后，用 T 来评估其测试误差，作为对泛化误差的估计.\n\n以二分类任务为例，假定 D 包含 1000 个样本，将其划分为 8 包含 700 个样 本 ， T 包含 300 个样本，用 S 进行训练后，如果模型在 T 上有 90 个样本分类错\n误，那么其错误率为 (90/300) x 100% 口 30% ，相应的，精度为 1- 30% = 70%.\n需注意的是，训练/测试集的划分要尽可能保持数据分布的一致性，避免 困数据划分过程引入额外的偏差而对最终结果产生影响，例如在分类任务中 至少要保持样本的类别比例相似.如果从来样 (sampling) 的角度来看待数据\n集的划分过程，则保留类别比例的采样方式通常称为\"分层采样\" (stratified\nsampling). 例如通过对 D 进行分层采样而获得含 70% 样本的训练集 S 和含 30% 样本的测试集 T， 若 D 包含 500 个正例、 500 个反例，则分层采样得到的 S 应包含 350 个正例、 350 个反例?而 T 则包含 150 个正例和 150 个反例;若 S、 T 中样本类别比例差别很大，则误差估计将由于训练/测试数据分布的差异 而产生偏差.\n\n参见习题 2.1 同时可得估计结呆的标\n准差，\n\n另一个需注意的问题是，即使在给定训练/测试集的样本比例后，仍存在多\n种划分方式对初始数据集 D 进行分割.例如在上面的例子中，可以把 D 中的样\n本排序，然后把前 350 个 E 例放到训练集中，也可以把最后 350 个正例放到训 练集中，……这些不同的划分将导致不同的训练/测试集，相应的?模型评估的 结果也会有差别.因此?单次使用留出法得到的估计结果往往不够稳定可靠，在 使用留出法时，一般要采用若干次随机划分、重复进行实验评估后取平均值作 为留出法的评估结果.例如进行 100 次随机划分，每次产生一个训练/测试集用\n于实验评估， 100 次后就得到 100 个结果?而留出法返回的则是这 100 个结果的\n平均.\n\n此外，我们希望评估的是用 D 训练出的模型的性能，但留出法需划分训\n\n26\n\n第 2 章模型评估与选择\n\n可从\"偏差-方差\" (参 见 2.6 节)的 角度 来理解 测试集小 时 ，坪千古结采的 方差较大， 训练集小 时，评\n估结果的偏差 较大\n一般 而言，测试集 至少 应含 30 个样例 [Mitchell ， 1997]\n\n练/测试集7 这就会导致一个窘境:若令训练集 S 包含绝大多数样本7 则训 练出 的模型可能更接近于用 D 训 练 出的模型， 但由 于 T 比较小 ，评估 结果可能不够 稳定准确 ;若令测试集 T 多包含一些样本， 则训 练集 S 与 D 差别更大了，被评 估的模型与用 D 训练出 的模型相比可能有较大差别?从而 降低了评估结果的保 真性 (fidelity) 这个问题没有完美 的解决方案 ， 常见做法是将大约 2/3 rv 4/5 的 样本用于训练，剩余样本用 于测试.\n2.2.2 交叉验证法\n\n亦称 \"k 倍交又验证\"\n\n\"交叉验证法\" (cross validation) 先 将数据 集 D 划 分为 k 个大 小相 似的\n互斥子集， 即 D = D1 U D2υ... U D k, Di n D j = ø (í 手 j ) . 每个子集 Di 都\n尽可 能 保持数据分布的 一 致性 ，即从 D 中 通过 分层采样得到. 然 后，每次用 k-1 个子集 的并集作 为训练集 ?余 F 的那个子集作 为 测 试集;这样就可获得 k 组训练/测 试集，从而可 进行 k 次训练和 测试? 最终返回的是 这 k 个测试 结果 的均值 显然，交叉验证法评估结果的 稳定 性 和保真 性在很大程度 上取决于 k\n的取值 ，为强调这一点 ，通常把交叉验证法称为 \" k 折 交叉验证\" (k-fold cross validat ion). k 最常用 的取值是 10 ，此时 称为 1 0 折交叉验 证 ; 其他常用 的 k 值\n有 5、 20 等.图 2.2 给出了 10 折交叉验证的 示意 图.\n\nD\nG ID1 1D2 1D31D4 1Ds ID6 1D71 D81Dg IDlOI\n\n训练集\n\n测试集\n\n| 叭 队 I D31 马 IDs I D6 1 D71 D81 D91 ~ →测 试结采 1 1\n\n|叭 队 I D31乌 IDs I D6 I D7 1D81DlOI 巨~ →测试结果 2 廿生返回\n\nr\n\nr 结果\n\nID2 1马 ID4 IDsID6ID7ID8IDgIDlOl 囚 →测 议结果1 0 J\n\n图 2.2 10 折交又验证示 意图\n\n({ 10 次 10 折交又验\n证法\"与 \" 100 次留 出 法\"都是进行了 100 次训 练/，，1'] i式\n\n与 留出法相似，将数据集 D 划 分 为 k 个子集同样存在多种 划 分方式.为 减 小 因样本划分不同 而 引入的差别 ， k 折交叉验证通常 要随机使用不同的划分 重复 p 次?最终的评估 结果是这 p 次 k 折交叉验证 结果 的均值，例如常 见的有\n\"10 次 10 折交叉验证\n{院假 定数据集 D 中包含 m 个样本3 若令 k=m ， 则得 到了交叉验证法的 一 个特例:留 一法 (Leave- One-Ot比，简称 LOO) . 显然 ， 留 一 法不受随机样本 划分\n\n2.2 评估方法\n\n27\n\n参见习题 2.2 NFL 定理参见1. 4 节\n\n方式的影响，因为 m 个样本只有唯一的方式划分为 m 个子集一一每个子集包含 一个样本;留一法使用的训练集与初始数据集相比只少了一个样本，这就使得 在绝大多数情况下，留一法中被实际评估的模型与期望评估的用 D 训练出的模 型很相似.因此，留一法的评估结果往往被认为比较准确.然而，留一法也有其 缺陷:在数据集比较大时，训练 m 个模型的计算开销可能是难以忍受的(例如数 据集包含 1 百万个样本，则需训练 1 百万个模型)，而这还是在未考虑算法调参 的情况下.另外，留一法的估计结果也未必永远比其他评估方法准确;\"没有免 费的午餐\"定理对实验评估方法同样适用.\n\n2.2.3 自助法\n\n关于样本复杂度与泛化 性能之间的关系，参见第 12 章.\n\n我们希望评估的是用 D 训练出的模型.但在留出法和交叉验证法中，由于 保留了一部分样本用于测试，因此实际评估的模型所使用的训练集比 D 小，这 必然会引入一些因训练样本规模不同而导致的估计偏差.留一法受训练样本规 模变化的影响较小，但计算复杂度又太高了.有没有什么办法可以减少训练样 本规模不同造成的影响，同时还能比较高效地进行实验估计呢?\n\nBootstrap本意是\"解靴 带\"这里是在使用德国 18 世纪文学作品《吹牛 大王历险记》中解靴带自 助的典故，因此本书译为\n\"自助法\" 自助采样亦 称\"可重复采样\"或\"有 放回采样\"\n\n\"自助法\" (bootstrapping) 是一个比较好的解决方案，它直接以自助采样\n法 (bootstrap sampling) 为基础 [Efron and Tibshirani, 1993]. 给定包含 m 个样\n本的数据集 D ， 我们对它进行采样产生数据集 D': 每次随机从 D 中挑选一个 样本 7 将其拷贝放入 DF' 然后再将该样本放回初始数据集 D 中，使得该样本在 下次采样时仍有可能被采到;这个过程重复执行 m 次后?我们就得到了包含 m 个样本的数据集 DF ，这就是自助采样的结果.显然 ， D 中有一部分样本会在 D' 中多次出现，而另一部分样本不出现.可以做一个简单的估计，样本在 m 次采 样中始终不被采到的概率是 (1 一去 )m ， 取极限得到\n\n已是自然常数\n\n(2.1)\n\n气\"表示集合;或法 集成学习参见第 8 章\n\n即通过自助来样，初始数据集 D 中约有 36.8% 的样本未出现在采样数据集 D' 中.于是我们可将 D' 用作训练、集 ， D\\D' 用作测试集;这样?实际评估的模型与 期望评估的模型都使用 m 个训练、样本，而我们仍有数据总量约 1/3 的、没在训\n练集中出现的样本用于测试.这样的测试结果，亦称\"包外估计\" (out-of-bag estimate).\n自助法在数据集较小、难以有效划分训练/测试集时很有用;此外，自助法 能从初始数据集中产生多个不同的训练集，这对集成学习等方法有很大的好处. 然而，自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差.因\n\n28\n\n第 2 章模型评估与选择\n\n此，在初始数据量足够时，留出法和交叉验证法更常用一些.\n\n2.2.4 调参与最终模型\n\n大多数学习算法都有些参数 (parameter) 需要设定，参数配置不同，学得模 型的性能往往有显著差别.因此，在进行模型评估与选择时，除了要对适用学习 算法进行选择，还需对算法参数进行设定，这就是通常所说的\"参数调节\"或\n简称\"调参\" (parameter tuning).\n\n例如大型\"深度学习\"\n模型甚至有上百亿个参数.\n\n读者可能马上想到，调参和算法选择没什么本质区别:对每种参数配置都 训练出模型，然后把对应最好模型的参数作为结果.这样的考虑基本是正确的， 但有一点需注意:学习算法的很多参数是在实数范围内取值，因此，对每种参数 配置都训练出模型来是不可行的.现实中常用的做法?是对每个参数选定一个 范围和变化步长，例如在 [0 ， 0.2] 范围内以 0.05 为步长，则实际要评估的候选参 数值有 5 个，最终是从这 5 个候选值中产生选定值.显然，这样选定的参数值往 往不是\"最佳\"值，但这是在计算开销和性能估计之间进行折中的结果，通过 这个折中，学习过程才变得可行.事实上，即便在进行这样的折中后，调参往往 仍很困难.可以简单估算一下:假定算法有 3 个参数，每个参数仅考虑 5 个候选\n值，这样对每一组训练/测试集就有 53 = 125 个模型需考察;很多强大的学习算\n法有大量参数需设定，这将导致极大的调参工程量，以至于在不少应用任务中， 参数调得好不好往往对最终模型性能有关键性影响.\n给定包含 m 个样本的数据集 D ，在模型评估与选择过程中由于需要留出 一部分数据进行评估测试，事实上我们只使用了一部分数据训练、模型.因此，在 模型选择完成后，学习算法和参数配置己选定，此时应该用数据集 D 重新训练 模型.这个模型在训练过程中使用了所有 m 个样本，这才是我们最终提交给用 户的模型.\n\n另外，需注意的是，我们通常把学得模型在实际使用中遇到的数据称为测 试数据，为了加以区分，模型评估与选择中用于评估测试的数据集常称为\"验\n证集\" (validation set). 例如，在研究对比不同算法的泛化性能时，我们用测试\n集上的判别效果来估计模型在实际使用时的泛化能力，而把训练数据另外划分 为训练集和验证集，基于验证集上的性能来进行模型选择和调参.\n\n2.3 性能度量\n对学习器的泛化性能进行评估，不仅需要有效可行的实验估计方法，还需\n要有衡量模型泛化能力的评价标准，这就是性能度量 (performance measure).\n\n2.3 性能度量\n\n29\n\n性能度量反映了任务需求，在对比不同模型的能力时，使用不同的性能度量往 往会导致不同的评判结果;这意味着模型的\"好坏\"是相对的，什么样的模型 是好的?不仅取决于算法和数据，还决定于任务需求.\n\n聚类的性能度量参见第 9章\n\n在预测任务中?给定样例集 D = {(X1 ,Y1) , (X2 ， 的)， . . . , (Xm, Ym)} ， 其中饥\n是示例 Xi 的真实标记.要评估学习器 f 的性能，就要把学习器预测结果 I(x) 与真实标记 υ 进行比较.\n\n回归任务最常用的性能度量是\"均方误差\" (mean squared error)\n\nE(川)=二 (f (Xi) 一切)2\n\n(2.2)\n\n更一般的，对于数据分布 Ð 和概率密度函数 p(.) ， 均方误差可描述为\n\nE(f;Ð) = i~Ð 州一的(x)dx\n\n(2.3)\n\n本节下面主要介绍分类任务中常用的性能度量.\n\n2.3.1 错误率与精度\n\n本章开头提到了错误率和精度?这是分类任务中最常用的两种性能度量，\n\n既适用于二分类任务，也适用于多分类任务.错误率是分类错误的样本数占样\n\n本总数的比例，精度则是分类正确的样本数占样本总数的比例.对样例集 D ， 分\n\n类错误率定义为\n\nEU;D)=tEM) 并执)\n\n(2 .4)\n\n精度则定义为\n\nacc(f; D)\n\n主兰1I (f (Xi) = 饥)\n\n(2.5)\n\n1- E (f;D) .\n\n旦王‘般的，对于数据分布 Ð 和概率密度函数 p(.) ， 错误率与精度可分别描\n\n述为\n\nE(fiD)ZLJfW 川)dx ,\n\n(2.6)\n\n30\n\n第 2 章模型评估与选择\n\nacc(f; Ð)\n\nL EM\n\n剖归p\nZ\n\n(2.7)\n\n1 一 E (f ;Ð) .\n\n查准率亦称\"准确卒\" 查全卒亦称\"召回率\"\n\n2.3.2 查准率、查全率与 Fl\n错误率和精度虽常用，但并不能满足所有任务需求.以西瓜问题为例，假定 瓜农拉来一车西瓜，我们用训练好的模型对这些西瓜进行判别，显然，错误率衡 量了有多少比例的瓜被判别错误.但是若我们关心的是\"挑出的西瓜中有多少 比例是好瓜\"，或者\"所有好瓜中有多少比例被挑了出来 就不够用了'这时需要使用其他的性能度量.\n类似的需求在信息检索、 Web搜索等应用中经常出现?例如在信息检索 中，我们经常会关心\"检索出的信息中有多少比例是用户感兴趣的\" u 用 户感兴趣的信息中有多少被检索出来了 率\" (rec叫aall) 是更为适用于此类需求的性能度量.\n对于二分类问题，可将样例根据其真实类别与学习器预测类别的组合划 分为真正例 (true positive) 、假正例 (false positive) 、真反倒 (true negative) 、 假反例 (false negative) 四种情形，令 TP 、 FP 、 TN 、 FN 分别表示其对应的 样例数，则显然有 TP+FP+TN+FN=样例总数.分类结果的\"泪淆矩 阵\" (co时usion matrix) 如表 2.1 所示\n\n表 2.1 分类结果混淆矩阵\n\n具实情况\n正例 反例\n\n预测结果\n州一「反例\nTP(真正例) I FN (假~17IJ)\nFP (假正例) I TN (真反例)\n\n查准率 P 与查全率 R 分别定义为\n\nTP\n\nP 二一T一P-+一一 F一P'\n\n(2.8)\n\nR\n\nn '-F\n\n-T一P\n\n一 +\n\n-N.\n\n(2.9)\n\n查准率和查全率是一对矛盾的度量.一般来说，查准率高时，查全率往往 偏低;而查全率高时，查准率往往偏低.例如，若希望将好瓜尽可能多地选出来， 则可通过增加选瓜的数量来实现，如果将所有西瓜都选上，那么所有的好瓜也\n\n2.3 性能度量\n\n31\n\n必然 都被选上了，但这样查准率 就会较低;若希望选 出 的瓜中好瓜比例尽可能 高，则可只挑选最有把握的瓜， 但这样就难免会漏掉不少好瓜，使得查全率较 低.通常只有在一些简单任务中 7 才可能使查全率和查准率都很高.\n\n以信息 4全索应用为例， 逐条向用尸反馈其可能感 兴趣的信息，即可计算出 查全率、查准卒\n亦称 \"PR 曲线\"或 \"PR 图\"\n\n在 很多情形札我们可根据 学习器的预测结 果对样例进行排序，排在前面 的是 学习器认为\"最可能 \"是正例的 样本?排在最后的则是学习器认为\"最 不可能\"是正例的样本.按此顺序逐个把样本作为正例进行预测 ，则每 次可以 计算出当前的查全 率、 查准率以查准 率为纵轴、查全率为横轴 作图 ，就得到 了查准率-查全率曲线 ，简称 \" P-R 曲 线\"显示该 曲线 的图称为 \" P-R图\" 图 2 .3 给出了一个示意图.\n\n10\n\n为绘 图方 便和美观，示 意图显示出羊调平滑曲线， 但现实任务中的 P-R 曲线 常是非羊调、不平滑的， 在很 多局部有 上下波动\n\n特 0.6 ↑\n\n传I\n\n./\n\n喇 0.4 ~\n\n0.2 ~\n\n/\n\nO l\n\n0 2 04 0 6\n\n查全率\n\n图 2 . 3 P-R曲线与 平衡点示 意图\n\nP-R 图直观地显示 出学 习器在样本总 体上的查全率、 查准率 .在进行比较 时?若一个学 习器的 P-R 曲线被另一个 学习器 的曲线 完全\"包住 \" ， 则可 断言 后者的性能优于前者， 例 如图 2 . 3 中 学习器 A 的性能优于 学习器 C; 如果两个 学习器 的 P-R 曲线发生了交叉 7 例如图 2 . 3 中的 A 与 B ，则难以 -般性地断言 两者孰优孰劣?只能在具体的查准率或查全率条件下进行 比较然 而，在很多 情 形下，人们往往仍希望把学习 器 A 与 B 比出个高低 . 这时一个比 较合理的判据 是比较 P-R 曲线节面积的大小，它在一定程度上表征了学习器在查准率和查全 率上取得相对\"双 高\"的比例 .但这个值不太容易估算， 因此 7 人们设计 了 一些 综合考虑查准率 、 查全率的性能度量 .\n\"平衡点 \" (Break-Event Point ，简称 BEP)就是这样一个度量，它 是\" 查\n准率=查全率\"时的取值3 例 如图 2.3 中 学习器 C 的 BEP 是 0 . 64 ，而基于 BEP 的比较，可认为学习器 A 优于 B .\n\n32\n\n第 2 章模型评估与选择\n\n但 BEP 还是过于简化了些，更常用的是 F1 度量:\n\nF1= 一 2Px一P+一xR一 R\n\n样 -1.>，q例\"，I总.v数.2_ x+.T,,T-P,rP-. -T\"-N'~T'\n\n(2.10)\n\nFl 是基于查准率与查 全率的调和平均 (harinonic mean) 定义的:\n古= ~. (~+主)\n?则胁了调7712\\\n\n在一些应用中，对查准率和查全率的重视程度有所不同.例如在商品推荐\n\n系统中，为了尽可能少打扰用户，更希望推荐内容确是用户感兴趣的，此时查准\n\n率更重要;而在逃犯信息检索系统中，更希望尽可能少漏掉逃犯，此时查全率更\n\n重要 . F1 度量的一般形式 --Fß' 能让我们表达出对查准率/查全率的不同偏\n\n好，它定义为\n\n乃=飞之)马♂tL7飞?，R\n\n归\n\nF马3 ← 1忏+β俨2 飞\\p ' R)\" 其中 ß>O 度量了查全率对查准率的相对重要性 [Van Rijsbergen, 1979]. ß = 1\n\n与算术平均(号旦)和几\n何平均 ( ..jP艾R)相比，调\n和平均~重视或小值.\n\n时退化为标准的 F1; ß> 1 时查全率有更大影响 ; ß < 1 时查准率有更大影响.\n很多时候我们寄多个二分类混淆矩阵，例如进行多次训练/测试，每次得到\n\n一个混淆矩阵;或是在多个数据集上进行训练/测试，希望估计算法的\"全局\"\n\n性能;甚或是执行多分类任务，每两两类别的组合都对应一个混淆矩阵，\n\n总之，我们希望在 n 个二分类混淆矩阵上综合考察查准率和雪全率\n\n一种直接的做法是先在各混淆矩阵上分别计算出查准率和查全率?\n记为 (Pl， R1 ) ， (马 ， R2) ，\"'， (凡 ， Rn) ， 再计算平均值，这样就得到\"宏查准 率\" (m肌ro-P) 、 \"宏查全率\" (macro-R) ，以及相应的\"宏 F1\" (macro-F1):\n\nmm0·p=iZR ，但\n\nm阳。R=izι(2.13)\n\nP R macro-F1 = - ,. I~n~~a-c-r-o--- x macro- •• ~~~---:.. -.\n+ macro-P macrc护 n\n\n(2.14)\n\n还可先将各泪淆矩阵的对应元素进行平均，得到 TP 、 FP 、 TN 、 FN 的 平均值，分别记为 TP 、 FP 、 Tl可、 F万，再基于这些平均值计算出\"微查准\n率 \"(micrE←P) 、 \"徽查全率\" (micro-R) 和\"微F1\" (micro-F1):\n\n= mlCro-r\n\nTP\n=--=工‘\n\nTP+FP'\n\n(2.15)\n\n2.3 性能度量\n神经网络参几第 5 章\n\n33\n\nmlCrO-l'í\n\n=\n\nTP\n=一一τ\n\n‘\n\nTP+FN'\n\nmicrc• F1=\n\n2\n\nx micrc←PX 口ùcro-R\nmicro-P +micro-R\n\n(2.16) (2.17)\n\n2.3.3 ROC 与 AUC\n\n很多学习器是为测试样本产生一个实值或概率预测，然后将这个预测值与 一个分类阔值(threshold) 进行比较，若大于|词值则分为正类，否则为反类.例 如，神经网络在一般情形下是对每个测试样本预测出一个 [0.0 ，1. 0] 之间的实值， 然后将这个值与 0.5 进行比较，大于 0.5 则判为正例，否则为反例.这个实值或 概率预测结果的好坏，直接决定了学习器的泛化能力.实际上?根据这个实值或 概率预测结果，我们可将测试样本进行排序，\"最可能\"是正例的排在最前面， \"最不可能\"是正例的排在最后面.这样，分类过程就相当于在这个排序中以\n某个\"截断点\" (cut point)将样本分为两部分，前一部分判作正例，后一部分则\n判作反例.\n\n在不同的应用任务中，我们可根据任务需求来采用不同的截断点，例如若 我们更重视\"查准率\"，则可选择排序中靠前的位置进行截断;若更重视\"查 全率\"，则可选择靠后的位置进行截断.因此，排序本身的质量好坏，体现了综 合考虑学习器在不同任务下的\"期望泛化性能\"的好坏，或者说\"一般情况 下\"泛化性能的好坏. ROC 曲线则是从这个角度出发来研究学习器泛化性能 的有力工具.\n\nROC 全称是\"受试者工作特征\" (Receiver Operating Characteristic) 曲\n\n线 7 它源于\"二战\"中用于敌机检测的雷达信号分析技术，二十世纪六七十\n\n年代开始被用于→些心理学、医学检测应用中?此后被引入机器学习领域\n\n[Spackman, 1989]. 与 2.3.2 节中介绍的 P-R 曲线相似?我们根据学习器的预\n\n测结果对样例进行排序，按此顺序逐个把样本作为正例进行预测，每次计算\n\n出两个重要量的值，分别以它们为横、纵坐标作图'就得到了 \"ROC 曲线\n\n与 P卫-R 曲线使用查准率、查全率为纵、横轴不同， ROC 曲线的纵轴是\"真正\n\n例率\" (True Positive Rate ，简称 TPR) ，横轴是\"假正例率\" (False Positive\n\nRate ，简称 FPR) ，基于表 2.1 中的符号，两者分别定义为\n\nT P R F P R\n\n… 凹 '-F\n\n-l-TA\n\n-N,\n\nh R÷\n\n-\n\n(2.18) (2.19)\n\n34\n\n第 2 章模型评估与选择\n\n显示 ROC 曲线的图称为 \"ROC 图\"图 2叫a)给出了一个示意图，显然 ， 对角线对应于 \"随机猜测\" 模型，而点 (0， 1 ) 则对应于将所有正例 排在所有 反 例之前的\"理想模型\"\n\n1.0\n。.8\n侍 0. 6 写E 叫 咔 0.4\n0.2\n。\n\n1.0\n\n0.8 恃 0.6\n写E 叫 咔 0 .4\n0.2\n\nAUC\n\n。\n\n0.2 0.4 0.6\n\n假正例 卒\n\n(b) 基于有限样例 绘制的 ROC 曲线 与 AUC\n\n图 2.4 ROC 曲线与 AUC 示意图\n\n基于有限个测 试样例绘 制 P-R 图时有同样问题 本书到这里才介绍近似曲 线的绘制，是为了便于下 面介绍 AUC 的计算\n\n现实任务中通常是利用 有限个测试样例来绘制 ROC 图 ，此时仅能获得有 限个(真正例率，假正例 率)坐标对，无法产生图 2.4(a) 中的光滑 ROC 曲线 ， 只能 绘制出如图 2 叫b)所示的近似 ROC 曲线.绘图过程很简单:给定 m+ 个正例和 m一 个反例，根据学习器预测结果对样例进行排序，然后把分类阔值设 为 最大， 即把所有样例均预测为反例，此时真正例率和假正例率均为 0 ， 在坐标 (0， 0) 处 标记一个点然后，将分类 阐值依次设为每个样例的预测值，即依次将每个样例 划分为正例.设前一个标记点坐标为 (X， y) ， 当 前若为 真正例，则对应标记 点的 坐标为 (X ， y + 步) ;当前若为假正例，则对应标记点的 坐标为 (X + 去 ， ν) ，然 后用线段连接相邻点即 得.\n\n进行学习器的比较时， 与 P-R 图相似， 若一个学习器的 ROC 曲线被另 一 个学 习器的曲线完全\"包住\"， 则可断言后者的性能优于前者;若两个学习 器 的 ROC 曲线发生交叉，则难以-般性地断言两者孰优孰劣 . 此时如果一定要进\n行比较， 则较为合理的 判据是 比较 ROC 曲 线下 的面积 ，即 AUC (Area Under ROC Curve) ，如图 2.4 所示.\n\n从定义可知， AUC 可 通过对 ROC 曲 线下各部分的面积 求和而得 . 假\n定 ROC 曲线是由坐标为 {(Xl ， yl), (X2,Y2) ,.. . , (xm,Ym)} 的点按序连接而形\n成 (Xl =0, x m = 1) ; 参见 图 2 .4(b) ，则 AUC 可估算为\n\n2.3 性能度量\n\n35\n\nAUC=; 汇 (Xi+l 均)队十饥+1)\n\nρ\n\n形式化地看， AUC 考虑的是样本预测的排序质量，因此它与排序误差有紧 密联系.给定 m十个正例和 m 个反例?令 D+ 和 D一分别表示正、反例集合， 则排序\"损失\" (loss) 定义为\n\nfl.rank = 中=艺艺 l][ (f (æ+) < f(æ一))十 iE(fW)zf(z一)) ) ,\n\næ+ED 十 gεD\n\n飞/\n\n(2.21 )\n\n即考虑每一对正、反例?若正例的预测值小于反例?则记一个\"罚分\n\n等?则 t记己 0.5 个\"罚分\"容易看出 ， fl.rαnk 对应的是 ROC 曲线之上的面积:若\n\n一个正例在 ROC 曲线上对应标记点的坐标为 (X ， y) ， 则 z 恰是排序在其之前的\n\n反例所占的比例?即假正例率.因此有\n\nAUC = 1- fl.rαnk .\n\n(2.22)\n\n2.3 .4代价敏感错误率与代价曲线\n\n在现实任务中常会遇到这样的情况:不同类型的错误所造成的后果不同. 例如在医疗诊断中，错误地把患者诊断为健康人与错误地把健康人诊断为患者， 看起来都是犯了\"一次错误\"但后者的影响是增加了进→步检查的麻烦，前 者的后果却可能是丧失了拯救生命的最佳时机;再如，门禁系统错误地把口J 通 行人员拦在门外，将使得用户体验不佳，但错误地把陌生人放进门内，则会造成 严重的安全事故.为权衡不同类型错误所造成的不同损失，可为错误赋予\"非\n均等代价\" (unequa1 cost).\n\n一般情况下，重要的是\n代价比值而非绝对值， 17'1\n如 costOl costl0 5 1\n与 50: 10 所起效果相当\n\n以二分类任务为例，我们可根据任务的领域知识设定一个\"代价矩\n\n阵\" (cost matrix) ，如表 2.2 所示，其中 costij 表示将第 i 类样本预测为第 j 类\n\n样本的代价.一般来说 ， costii = 0; 若将第 0 类判别为第 1 类所造成的损失更\n\n大，则 / .,\n\ncost01\n\n>\n\ncost lO;\n\n损失程度相差越大 ，\n\ncost01\n\n与\n\ncost lO\n\n值的差别越大.\n\n斗 凯 阵 表\n一\n\n9\"q-a-\n\n价 一\n\nM阳 …\n\n一如 一叭 -睛 真实类别\n\n一 叭 一句 第 0 类\n\n( -\n\n-现 一 第 1 类\n\nm\n\n啤 …f\n\nR F一\n\nhυ←卜 ← |\n\n才 在 一 刀\n一O\n\n一\n\n36\n\n第 2 章模型评估与选择\n\n回顾前面介绍的一些性能度量可看出，它们大都隐式地假设了均等代价， 例如式 (2 .4)所定义的错误率是直接计算\"错误次数\"，并没有考虑不同错误会 造成不同的后果.在非均等代价下，我们所希望的不再是简单地最小化错误次\n数，而是希望最小化\"总体代价\" (total cost). 若将表 2.2 中的第 0 类作为正\n类、第 1 类作为反类?令 D+ 与 D一分别代表样例集 D 的正例子集和反例子 集，则\"代价敏感\" (cost-sensitive)错误率为\n\nE (f; D; cost) = 二|艺 II (f (叫)向) xωtQ1\n\\X; ξ D+\n\nL I . +\n\n1I(f (Xi) 向i) XωstlO\n\nXi 巳D 一/\n\n(2.23)\n\n参见习题 2.7\n\n类似的，可给出基于分布定义的代价敏感错误率，以及其他一些性能度量 如精度的代价敏感版本.若令 costij 中的 4 、 j 取值不限于0 、 1 ，则可定义出多 分类任务的代价敏感性能度量.\n在非均等代价下， ROC 曲线不能直接反映出学习器的期望总体代价，而\n\"代价曲线\" (cost curve) 则可达到该目的.代价曲线图的横轴是取值为 [0 ， 1]\n的正例概率代价\n\n+ P(+)cost\n\n二\n\npx\n\npX costOl ωst01 (1 - p)\n\nxωst107\n\n(2.24)\n\n\"规范化\" (normalization) 是将不同变化范围的 位映射到相同的固定范围 中，常见的是 [0 ， 1]. 此时亦 称\"归一化\" 参见习题\n2.8.\n\n其中 p 是样例为正例的概率;纵轴是取值为 [0 ， 1] 的归一化代价\n\nωst~nT~ !NR X P x cost01 十 FPR x (1- p) x ∞stlO\n\nnorm\n\n+ p xωst01 (1 - p) xωst10'\n\n(2.25)\n\n其中 FPR 是式 (2.19) 定义的假 E例率， FNR == 1 - TPR 是假反例率.代价曲线\n的绘制很简单: ROC 由线上每…点对应了代价平面上的二条线段 7 设 ROC 曲 线上点的坐标为 (TPR， FPR) ，则可相应计算出 FNR，然后在代价平面上绘制 一条从 (O ， FPR) 到 (l ， FNR) 的线段，线段下的面积即表示了该条件下的期望 总体代价;如此将 ROC 曲线土的每个点转化为代价平面上的一条线段，然后 取所有线段的下界，围成的自积即为在所有条件下学习器的期望总体代价，如 图 2.5 所示.\n\n2.4 比较检验\n\n37\n\n0.5\n\n1.0\n\n正例概率代价\n\n图 2.5 代价曲线与期望总体代价\n\n2 .4比较检验\n\n有了实验评估方法和性能度量，看起来就能对学习器的性能进行评估比较 了:先使用某种实验评估方法测得学习器的某个性能度量结果，然后对这些结 果进行比较.但怎么来做这个\"比较\"呢?是直接取得性能度量的值然后\"比 大小\"吗?实际上，机器学习中性能比较这件事要比大家想象的复杂得多.这 里面涉及几个重要因素:首先，我们希望比较的是泛化性能，然而通过实验评估 方法我们获得的是测试集上的性能，两者的对比结果可能未必相同;第二，测试 集上的性能与测试集本身的选择有很大关系，且不论使用不同大小的测试集会 得到不同的结果，即使用相同大小的测试集?若包含的测试样例不同，测试结果 也会有不同;第二，很多机器学习算法本身有一定的随机性，即便用相同的参数 设置在同一个测试集上多次运行，其结果也会有不同.那么，有没有适当的方法 对学习器的性能进行比较呢?\n\n更多关于假设检验的介\n绍可参见 [Wellek. 2010]\n\n统计假设检验 (hypothesis test) 为我们进行学习器 t性能比较提供了重要依 据.基于假设检验结果我们可推断出，若在测试集上观察到学习器 A 比 B 好， 则 A 的泛化性能是否在统计意义上优于 B ，以及这个结论的把握有多大.下面 我们先介绍两种最基本的假设检验，然后介绍几种常用的机器学习性能比较方 法.为便于讨论，本节默认以错误率为性能度量，用 E 表示.\n\n2 .4 .1 假设检验\n假设检验中的\"假设\"是对学习器泛化错误率分布的某种判断或猜想，例\n如 \"f = fO\". 现实任务中我们并不知道学习器的泛化错误率，只能获知其测试错\n误率 ι 泛化错误率与测试错误率未必相同，但直观上?三者接近的可能性应比\n\n38\n\n第 2 章模型评估与选择\n\n较大，相差很远的可能性比较小.因此， 可根据测试错误率估推出泛化错误率的 分布.\n泛化错误率为 E 的学习器在一个样本上犯错的概率是 ε; 测试错误率 E 意味 着在 m 个测试样本中恰有三 xm 个被误分类.假定测试样本是从样本总体分布 中独立采样而得，那么泛化错误率 为 ε 的 学习器将其中 m' 个样本误分类 、 其\n余样本全部分类正确的概率是 fm' (1 - fr-m' ; 由此可估算出其恰将 Ê x m 个\n样本误分类的概率如下式所示，这也表达了 在包含 m 个样本的测试集上， 泛化 错误率为 E 的学习器被测得测试错误率为 王的概率:\n\nP(Ê; f) = (Ê 了'm)fÊxm(1一俨xm\n\n(2.26)\n\n给定测试错误率，则解 θP (Ê; f)/8f = 0 可知 ， P (正; f) 在 ε= 三时最大， k- ÊI 增\n大时 P(Ê; f) 减小.这符合二项 (binomial) 分布，如 图 2.6 所示，若 f = 0. 3，则 10\n个样本中 测得 3 个被误分类的概率最大.\n\n0.25\n\n0.20\n\n0.1 5\n候革￡+\n0, 10\n\nα 的常用取位有 0.05 、 0.1 ，图 2.6 中 α 较 大是为了绘图方便，\n\n。 .05 。\n图 2.6 二项分布示意图 (m = 10， ε= 0.3)\n\n我们可使用\"二项检验\" (binomial test) 来对 \"εζ0.3\"( 即\"泛化错误率是\n否不大于 0.3\" )这样的假设进行检验.更一般 的，考虑假 设 \"εζε。\"，则在 l 一 α 的概率 内所能观测 到的最大错误率如下式计算.这里 1 一 α 反映 了 结论的 \" 置信度 \" (confidence) ，直观地来看，相应于图 2.6 中非阴 影部分的范围\n\n5.t. 是 \"5ubject to\" 的 简写，使左边式子在右边 条件满足时成立\n\nS.t e= maxf 二+î (7) 年\n\n(2.27)\n\n2.4 比较检验\n\n39\n\n二项检验的临界位在 R 语言中可通过 qbinom(l­ Ct:， m，句)计 算，在 Matlab\n中是 icdf ('Binomial', 1 一\nα ， m， ε0)\nR 语言是面向统计计 算 的开源脚本语言， 参几\nwww.r-project.org\n\n此时若测试错误率 E 小于临界值 Ë，则根据二项检验可得出结论:在 α 的显著度 下，假设 \"ε~ EO\" 不能被拒绝，即能以 1 一 α 的置信度认为 ，学习器的泛化错误 率不大于 EO; 否则该假设可被拒绝，即在 α 的显著度下可认为学习器的泛化错 误率大于 EO.\n\n在很多时候我们并非仅做一次留出法估计，而是通过多次重复留出法或是\n\n交叉验证法等进行多 次训练/测 试，这样会得到多个测试错误率， 此时可 使用\n\n\"t 检验\" (t-test). 假定我们得到了 k 个测试错误率，缸，也 ... ，龟 ，则平均测试\n\n错误率 μ 和方差 σ2 为\n\nμ=i 乞，\n\n(2.28)\n\nσ\n\n一\n\nK Z\n\n户间\n\nμ\n\n(2.29)\n\n考虑到这 k 个测试错误率可看作泛化错误率句的独立采样，则变量\n\n吭 Jk(μ- EO)\nσ\n服从自由度为 k-l 的 t 分布，如图 2.7 所示.\n\n(2.30)\n\n概\n率 密 度\n\nα\n\n-10\n\n‘ 气，\n\n5\n\n4 。\n\n5\n\n10\n\nTt\n\n固 2.7 t 分布示意图 (k = 10)\n\n对假设 \"μ = E。\"和显著度 α，我们可计算出 当 测试错误率均值为 EO 时，在\n1 α 概率内能观测到的最大错误率，即临界值.这里考虑双边(twφtailed)假\n设，如图 2.7 所示，两边阴影部分各有 α/2 的面积;假定阴影部分范围分别为\nl一∞ ， t_白/2] 和 [ta/2 ， ∞].若平均错误率 μ 与 EO 之差 |μ- Eo l 位于临界值范围\n\n40\n\n第 2 章模型评估与选择\n\n临界侄儿 /2 在民语言 中可通过 qt(l 一 α/2 ， k 1) 计算，在 Matlab 中是\nicdf('T' ， lα/2 ， k -1).\n\n[t_α/2 ，乌/2] 内，则不能拒绝假设 \"μ=E。\"，即可认为泛化错误率为 EO ，置信度为 1 一 α; 否则可拒绝该假设，即在该显著度下可认为泛化错误率与 EO 有显著不 同 .α 常用取值有 0.05 和 0. 1.表 2.3 给出了一些常用临界值.\n表 2.3 双边 t 检验的常用临界值\n\nα\n2\n\nk\n\n5\n\n10 20 30\n\n0.05 12.706 2.776 2.262 2.093 2.045 0.10 6.314 2.132 1.833 1.729 1.699\n\n上面介绍的两种方法都是对关于单个学习器泛化性能的假设进行检验，而 在现实任务中，更多时候我们需对不同学习器的性能进行比较，下面将介绍适 用于此类情况的假设检验方法.\n\n2 .4 .2 交叉验证 t 检验\n对两个学习器 A 和 B ，若我们使用 k 折交叉验证法得到的测试错误率分\n别为 Ef ， Ef，...， Ef 和 EtEP ，...， Ef ，其中 Ef 和平是在相同的第 4 折训练/测 试集上得到的结果，则可用 k 折交叉验证\"成对 t 检验\" (paired t-tests)来进行\n比较检验.这里的基本思想是若两个学习器的性能相同，则它们使用相同的训 练/测试集得到的测试错误率应相同，即 Ef=EP.\n具体来说，对 k 折交叉验证产生的 k 对测试错误率:先对每对结果求差， Az=Ef-EP; 若两个学习器性能相同，则差值均值班为零.因此，可根据差值\n.ð.1 , .ð.2 , . . . ，.ð.k 来对\"学习器 A 与 B 性能相同\"这个假设做 t 检验，计算出差值 的均值 μ 和方差 σ2 ，在显著度 α 下，若变量\n\nη 斗争|\n\n(2.31)\n\n小于临界值 ta/2， k-ll 则假设不能被拒绝，即认为两个学习器的性能没有显著差\n另Ù; 否则可认为两个学习器的性能有显著差别，且平均错误率较小的那个学习\n器性能较优.这里 ta/2， k-1 是自由度为 k-1 的 t 分布上尾部累积分布为 α/2\n的临界值.\n欲进行有效的假设检验，一个重要前提是测试错误率均为泛化错误率的独 立采样.然而，通常情况下由于样本有限，在使用交叉验证等实验估计方法时， 不同轮次的训练集会有一定程度的重叠，这就使得测试错误率实际上并不独立， 会导致过高估计假设成立的概率.为缓解这一问题，可采用 \"5 x 2 交叉验证\"\n\n2.4 比较检验\n\n41\n法 [Dietterich ， 1998].\n5x2 交叉验证是做 5 次 2 折交叉验证，在每次 2 折交叉验证之前随机将数 据打乱?使得 5 次支又验证中的数据划分不重复.对两个学习器 A 和 B ，第 4 次 2 折交叉验证将产生两对测试错误率?我们对它们分别求差，得到第 1 折上的差 值 Aj 和第 2 折上的差值 ß~. 为缓解测试错误率的非独立性，我们仅计算第 1\n+ 次 2 折交叉验证的两个结果的平均值 μ= 0.5(ßi ßr) ，但对每次 2 折实验的 结果都计算出其方差 σ仨 (ßl 一笃到 2+ 何一句句 2 变量\n\nf..L\n\nTt = ----;===一一一一\n\n0.2\n\n5\nI:\n\nut\n\n(2.32)\n\n服从自由度为 5 的 t 分布，其双边检验的临界值凡12 ， 5 当 α 止。 .05 时为 2.5706 ， α= 0.1 时为 2.0150.\n2.4.3 McNemar 检验\n对二分类问题，使用留出法不仅可估计出学习器 A 和 B 的测试错误率，还 可获得两学习器分类结果的差别，即两者都正确、都错误、一个正确另一个错\n误的样本数，如\"列联衷\" (contingency table) 2 .4所示.\n表 2 .4 两学习器分类差别列联表\n\n算法 B\n.J1.确 辛苦误\n\n算法 A\n\n正确\n\n辛苦误\n\neOO\n\neOl\n\neîo\n\nel1\n\n若我们做的假设是两学习器性能相同?则应有 e01 - elQ，那么变量 le01 - e lO l 应当服从正态分布，且均值为 1 ，方差为 e01 十 elQ.回此变量\n\n久 (le01 - e lO l- 1)2\n\n、 .2 二二\n\n^\n\ne01 十 e lO\n\n(2.33)\n\n中文称为\"卡方分布\"\n临界值址在 R 语 言中可通过 qchisq(l α ， k-l) 计算，在 Matlab 中\n是 icdf ('Chisquare' , 1 一\n白 ， k -1). 这里的 k = 2 走进行比较的算法个数.\n\n服从自由度为 1 的 χ2 分布?即标准正态分布变量的平方.给定显著度 α ，当以 上变量恒小于临界值功时，不能拒绝假设，即认为两学习器的性能没有显著差 别;否则拒绝假设，即认为两者性能有显著差别，且平均错误率较小的那个学习\n器性能较优.自由度为 1 的 χ2 检验的临界值当 α= 0.05 时为 3.8415 ， α= 0.1\n时为 2.7055.\n\n42\n\n第 2 章模型评估与选择\n\n2.4.4 Friedman 检验与 N 凹nenyl 后续检验\n交叉验证 t 检验和 McNemar 检验都是在一个数据集上比较两个算法的 性能，而在很多时候，我们会在一组数据集上对多个算法进行比较.当有多个 算法参与比较时，一种做法是在每个数据集上分别列出两两比较的结果，而在 两两比较时可使用前述方法;另一种方法更为直接?即使用基于算法排序的 Friedman 检验.\n假定我们用 Dl' D2 、 D3 和 D4 四个数据集对算法 A 、 B 、 C 进行比较. 首先，使用留出法或交叉验证法得到每个算法在每个数据集仁的测试结果?然\n后在每个数据集上根据测试性能由好到坏排序，并赋予序值 1 ， 2, ...，若算法的\n测试性能相同，则平分序值.例如，在 D1 和 D3 上， A 最好、 8 其次、 C 最差， 而在 D2 上 ， A 最好、 B 与 C 性能相间，……，则可列出表 2.5 ，其中最后一行通 过对每一列的序值求平均，得到平均序值.\n\n表 2.5 算法比较序位表\n\n数据集\nDl D2 D3 D4\n平均序值\n\n算法 A\n1\nl\n1 1 1\n\n算法 B\n2 2.5 2 2 2.125\n\n算法 C\n3 2.5 3 3 2.875\n\n然后，使用Friedman 检验来判断这些算法是否性能都相同.若相同，则它 们的平均序值应当相同.假定我们在 N 个数据集上比较 k 个算法，令?飞表示第 4 个算法的平均序值，为简化讨论，暂不考虑平分序值的情况，则 η 服从正态分\n+ 布?其均值和方差分别为 (k 1)/2 和 (k2 - 1)/12. 变量\n\nχ2= 午二三LZ(Tz 一号)\n\n=刮去?一叩:)\n\nρ\n\n在 k 和 N 都较大时，服从自由度为 k-1 的 χ2 分布. 然而?上述这样的\"原始Friedman 检验\"过于保守，现在通常使用变量\n\n- - (N -1)Tx2 YF Z N(k-1)-TX2'\n\n(2.35)\n\n2.4 比较检验\n\n43\n\n其中 TX2 由式 (2.34) 得到 . TF 服从自由度为 k-1 和 (k - l)(N - 1) 的 F 分布，\n表 2.6 给出了一些常用临界值.\n\nF 检验的格界值在 R 语 言中可通过 qf(l- a ， k 一\n1. (k -l)(N- 1)) 计算，在 Matlab 中是 icdf (/F / , 1\n白 ， k -1 , (k -1) * (N -1)).\n\n表 2.6 F 检验的常用临界值\n\nα= 0.05\n数据集 个数 N\n4 5 8 10 15 20\n\n2\n10.128 7.709 5.591 5.117 4.600 4.381\n\n3\n5.143 4.459 3.739 3.555 3.340 3.245\n\n4\n3.863 3.490 3.072 2.960 2.827 2.766\n\n算法个数 k\n\n5\n\n6\n\n7\n\n3.259 3.007 2.714 2.634 2.537 2.492\n\n2.901 2.711 2.485 2.422 2.346 2.310\n\n2.661 2.508 2.324 2.272 2.209 2.179\n\n8\n2.488 2.359 2.203 2.159 2.104 2.079\n\n9\n2.355 2.244 2.109 2.070 2.022 2.000\n\n10\n2.250 2.153 2.032 1. 998 1.955 1.935\n\nα= 0.1\n数据集 个数 N\n4 5 8 10 15 20\n\n2\n5.538 4.545 3.589 3.360 3.102 2.990\n\n3\n3.463 3.113 2.726 2.624 2.503 2.448\n\n4\n2.813 2.606 2.365 2.299 2.219 2.182\n\n算法个数 k\n\n5\n\n6\n\n7\n\n2.480 2.333 2.157 2.108 2.048 2.020\n\n2.273 2.158 2.019 1.980 1.931 1.909\n\n2.130 2.035 1.919 1.886 1.845 1.826\n\n8\n2.023 1.943 1.843 1.814 1. 779 1. 762\n\n9\n1.940 1.870 1.782 1.757 1. 726 1. 711\n\n10\n1.874 1.811 1.733 1.710 1.682 1.668\n\n若\"所有算法的性能相同\"这个假设被拒绝，则说明算法的性能显著不 同.这时需进行\"后续检验\" (post- hoc test) 来进一步区分各算法.常用的有 Nemenyi 后续检验.\nNemenyi 检验计算出平均序值差别的临界值域\n\nCD=JF ,\n\n(2.36)\n\n也是 Tukey 分布的临\n界值，在 R 语言中可通\n过 qtukey (l白 ， k ， Inf)!\nsqrt (2) 计算\n\n表 2.7 给出了 α= 0.05 和 0.1 时常用的如值.若两个算法的平均序值之差超出\n了临界值域 CD ， 则以相应的置信度拒绝\"两个算法性能相同\"这一假设­\n表 2.7 Nemenyi 检验中常用的也值\n\n算法个数 k\n\nα\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\n9\n\n10\n\n0.05 1.960 2.344 2.569 2.728 2.850 2.949 3.031 3.102 3.164 0.1 1.645 2.052 2.291 2.459 2.589 2.693 2.780 2.855 2.920\n\n44\n\n第 2 章模型评估与选择\n\n以表 2.5 中的数据为例，先根据式 (2.34) 和 (2.35) 计算出 Tp =24 .429 ， 由表 2.6 可知，它大于 α= 0.05 时的 F 检验临界值 5.143 ，因此拒绝\"所有算法性\n能相同\"这个假设.然后使用 Nemenyi 后续检验，在表 2.7 中找到 k = 3 时 QO.05 = 2.344 ，根据式 (2.36) 计算出临界值域 CD = 1. 657 ，由表 2.5 中的平均序\n值可知?算法 A 与 B 的差距，以及算法 B 与 C 的差距均未超过临界值域，而算 法 A 与 C 的差距超过临界值域，因此检验结果认为算法 A 与 C 的性能显著不 同，而算法 A 与 B 、以及算法 B 与 C 的性能没有显著差别.\n上述检验比较可以直观地用Friedman 检验图显示.例如根据表 2.5 的序 值结果可绘制出图 2.8 ，图中纵轴显示各个算法，横轴是平均序值.对每个算法? 用一个圆点显示其平均序值，以圆点为中心的横线段表示临界值域的大小.然 后就可从图中观察，若两个算法的横线段有交叠，则说明这两个算法没有显著 差别，否则即说明有显著差别.从图 2.8 中可容易地看出?算法 A 与 B 没有显著 差别，因为它们的横线段有交叠区域，而算法 A 显著优于算法 C ，因为它们的 横线段没有交叠区域.\n\n临界值域\n算法A '---c--------，------引\n\n算法B\n\n平均序值----t\n\n算法 C\n\n1.0\n\n3.0\n\n图 2.8 Friedman 检验图\n\n2.5 偏差与方差\n\n对学习算法除了通过实验估计其泛化性能?人们往往还希望了解它\"为什\n么\"具有这样的性能\"偏差方差分解\" (bias-variance decomposition) 是解\n释学习算法泛化性能的一种重要工具.\n\n有可能出现嗓声使得 自D 笋 y.\n\n偏差方差分解试图对学习算法的期望泛化错误率进行拆解.我们知道，算 法在不同训练集上学得的结果很可能不同，即便这些训练集是来自同一个分布.\n对测试样本队令 YD 为 m 在数据集中的标记 ， y 为 2 的真实标记 ， f(x; D) 为训\n练集 D 上学得模型 f 在 m 上的预测输出.以回归任务为例，学习算法的期望预\n\n2.5 偏差与方差\n\n45\n\n测为\nf(x) = ED[f(x;D)] ,\n使用样本数相同的不同训练集产生的方差为\nvar(x) = ED [(f (川)-f(x)) 斗，\n\n(2.37) (2.38)\n\n噪声为\n\nιED [(YD-y)2]\n\n期望输出与真实标记的差别称为偏差 (bias) ，即\n\nbiαS2 (x) = (1 (x) _ Y) 2 .\n\n(2.39) (2 .40)\n\n为便于讨论，假定噪声期望为霉，即 ED[ω -y] =0. 通过简单的多项式展开合 井，可对算法的期望泛化误差进行分解:\n\n由式 (2.37) ，最后项为 0\n噪声期望为 0 ， 因此最后项为 0\n\nE(σ川;剖川 D)忡=也=\n= ED [(f (叫一 f(刑十 f(x) 一如) 2] = ED [(f (吼叫 -f(X))2] 十 ED [(1 (X) 一如) 2J\n(f +ED [2 (x;D) - f(x)) (f (x) -YD)] = ED [(f (吼叫 f(x月 1 十叫 (1 (X)-YD)2]\n=ED [(f (æ;D)-f(æ))2] +ED [(1 (æ)-Y+Y-YD)2]\n=ED [(f (æ;D)-f(æ))2] 十lED [(1 (æ) _y)2] +ED [(川D)2]\n十 2ED [(1 (æ) - Y) (y - YD)]\n[(f = ED (川)-f(æ)) 才 + (f (æ) - y)2 + lED [(YD 一叫，\n(2.41)\n\n于是，\n\nE (f; D) = biαS2 (æ) 十四r (æ) +ε2\n\n(2 .42)\n\n也就是说?泛化误差可分解为偏差、方差与噪声之和. 四顾偏差、方差、噪声的含义:偏差 (2.40) 度量了学习算法的期望预测与\n\n46\n\n第 2 章模型评估与选择\n\n真实结果的偏离程度，即刻画了学习算法本身的拟合能力;方差 (2.38) 度量了闰 样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的 影响;噪声 (2.39) 则表达了在当前任务上任何学习算法所能达到的期望泛化误 差的 F 界，即刻画了学习问题本身的难度.偏差一方差分解说明，泛化性能是由 学习算法的能力、数据的充分性以及学习任务本身的难度所共同决定的.给定 学习任务?为了取得好的泛化性能，则需使偏差较小，即能够充分拟合数据，并 且使方差较小，即使得数据扰动产生的影响小.\n\n很多学习算法都可控制 训练程度，例如决策树可 控制层数，神经网络可控 制训练轮数，集成学习方 法可控制基学习器个数\n\n一般来说?偏差与方差是有冲突的，这称为偏差一方差窘境 (bias-variance\ndilemma). 图 2.9 给出了一个示意图给定学习任务，假定我们能控制学习算法 的训练程度，则在训练不足时?学习器的拟合能力不够强，训练数据的扰动不足 以便学习器产生显著变化，此时偏差主导了泛化错误率;随着训练程度的加深， 学习器的拟合能力逐渐增强，训练数据发生的扰动渐渐能被学习器学到，方差 逐渐主导了泛化错误率;在训练程度充足后，学习器的拟合能力已非常强，训练 数据发生的轻微扰动都会导致学习器发生显著变化，若训练数据自身的、非全 局的特性被学习器学到了，则将发生过拟合.\n\n-一--i.乏化误差 一一偏差\n-…·方差\n\n理整 得\n\n训练程度 图 2.9 泛化误差与偏差、方差的关系示意图\n2.6 阅读材料\n自助采样法在机器学习中有重要用途， [E仕0卫 and Tibshirani, 1993] 对此\n进行了详细的讨论.\nROC 曲线在二十世纪八十年代后期被引入机器学习 [Spackm钮， 1989],\nAUC 则是JA九十年代中期起在机器学习领域广为使用 [Bradley ， 1997] ，但利用\n\n2.6 阅读材料\n\n47\n\nROC 曲线下面积来评价模型期望性能的做法在医疗检测中早已有之 [Har由y\nand McNeil, 1983]. [Hand and Till, 2001] 将 ROC 曲线从二分类任务推广到多\n分类任务. [Fawce忱， 2006] 综述了 ROC 酣线的用途.\n\n2.3.4 节仅讨论了基于类 别的误分类代价.\n\n[Drummond and Holte, 2006] 发明了代价曲线.需说明的是，机器学习过\n程涉及许多类型的代价，除了误分类代价，还有测试代价、标记代价、属性代 价等，即使仅考虑误分类代价，仍可进一步划分为基于类别的误分类代价以及\n基于样本的误分类代价.代价敏感学习 (cost-sensitive learning) [Elkan, 2001; Zhou and Liu, 2006] 专门研究非均等代价下的学习.\n\n[Dietterich, 1998] 指出了常规 k 折交叉验证法存在的风险，并提出了 5x2 交叉验证法. [Demsar, 2006] 讨论了对多个算法进行比较检验的方法.\n\n[Geman et al., 1992] 针对回归任务给出了偏差一方差一协方差分解 (bias­ variance-covariance decomposition) ，后来被简称为偏差一方差分解.虽然偏差\n和方差确实反映了各类学习任务内在的误差决定因素，但式 (2 .42) 这样优美的 形式仅在基于均方误差的回归任务中得以推导出.对分类任务，由于 0/1 损失 函数的跳变性，理论上推导出偏差方差分解很困难.己有多种方法可通过实\n验对偏差和方差进行估计 [Kong and Dietterich, 1995; Kohavi and Wolpert, 1996; Breiman, 1996; Friedman, 1997; Domi吨os ， 2000].\n\n48\n\n第 2 章模型评估与选择\n\n习题\n2.1 数据集包含 1000 个样本，其中 500 个正例、 500 个反例，将其划分为\n包含 70% 样本的训练集和 30% 样本的测试集用于留出法评估，试估 算共有多少种划分方式.\n2.2 数据集包含 100 个样本，其中正、反例各一半，假定学习算法所产生\n的模型是将新样本预测为训练样本数较多的类别(训练样本数相同时 进行随机猜测)，试给出用 10 折交叉验证法和留一法分别对错误率进 行评估所得的结果.\n\n2.3 若学习器 A 的 F1 值比学习器 B 高试析 A 的 BEP 值是否也比 B 高.\n\n2.4 试述真正例率 (TPR) 、假正例率 (FPR) 与查准率 (P) 、查全率 (R) 之间\n的联系.\n\n2.5 试证明式 (2.22).\n\n2.6 试述错误率与 ROC 曲线的联系.\n\n2.7 试证明任意一条 ROC 曲线都有一条代价曲线与之对应，反之亦然.\n\n2.8 Min-max 规范化和公score 规范化是两种常用的规范化方法.令 z 和\nX' 分别表示变量在规范化前后的取值，相应的，令 Xmin 和 Xm即表示 规范化前的最小值和最大值 ， x~in 和 z;mz 表示规范化后的最小值和 最大值，军和 σz 分别表示规范化前的均值和标准差，则 min-max 规范 化、 z-score 规范化分别如式 (2 .43)和 (2 .44) 所示.试析二者的优缺点.\n\nd=z:YBWB 十\n\nz -Xmin -.\n\n× (zLm-zLsn) ，\n\n~mα耳自 m.n\n\n, x-x\n\n3巳 =二一一一一一-\n\nσ3巳\n\n2.9 试述 χ2 检验过程.\n\n(2 .43) (2 .44)\n\n2.10* 试述在Friedman 检验中使用式 (2.34) 与 (2.35) 的区别.\n\n参考文献\n\n49\n参考文献\nBrad1ey, A. P. (1997). \"The use of the 町ea under the ROC curve in the eva1uation of machine 1earning a1gorithms.\" Pattem Recognition, 30(7):1145一1159.\nBreiman, L. (1996). \"Bi拙， variance, and arcing classifiers.\" Technica1 Report 460, Statistics Department, University of California, Berke1ey, CA.\nDemsar, J. (2006). \"Statistical comparison of classifiers over mu1tip1e data sets.\" Journal of Machine Leaming Research, 7:1-30.\nDietterich, T. G. (1998). \"Approximate statistical tests for comparing super-\nvised classification 1earning algorithms.\" Neural Computαtio凡 10(7):1895 1923. Do回 mi吨 r os凯， P. (2但000叫) 吐 uni觅ed bias，-胃胃v吁\noft仇heυ17ηthl时 nt切巳m呢Z耐 αti佣 o7ηZaαl ωCOη呼jer何附它吻nce 0η Mαáchi附 1Z记eLe创αming ρCMLυ)， 231-238 ，\nStanfl岛ord， CA.\nDru旧mr\nfor visualizing classifier performance.\" Machine Leαming， 65(1):95-130.\nEfron, B. and R. Tibshirani. (1993). An Introduction to the Bootstrα， ，p. Chapman & Hall, New York, NY.\nElkan, C. (2001). \"The foundations of cost-senstive 1earning.\" In Proceedings of\nthe 17th Intemational Joint Conference on Artificial 1:时elligence (IJCA I，人\n973-978, Seatt1e, WA. Fawcett, T. (2006). \"An introduction to ROC ana1ysis.\" Pαttem Recognition\nLetters, 27(的 :861-874. Friedman, J. H. (1997). \"On bias, variance, 0/1-108s, and the curse-of-\ndimensionality.\" Dαtα Mining αnd Knowledge Discove吼 1(1):55-77.\nGeman，乱， E. Bienenstock, and R. Doursat. (1992). \"Ne盯al networks and the\nbias/variance dilemma.\" Neural C01叩utation， 4(1):1• 58 Ha丑d ， D. J. and R. J. Till. (2001). 吐 simp1e generalisation of the area under\nthe ROC curve for multiple class classification prob1ems.\" Mα chine Learning, 45(2):171-186 Har由y， J. A. and B. J. McNeil. (1983). \"A method ofcomparing the 町eas under receiver operating characteristic curves derived from the same cases.\" Rαdiology， 148(3):839-843.\n\n50\n\n第 2 意模型评估与选择\n\nKohavi, R. and D. H. Wo1pert. (1996). \"Bi副 p1us variance decomposition for\nzero-one 10ss functions.\" 1n Proceeding of the 13th Internationαl Conference\nonMαchine Learning ρCML) ， 275-283, Bari, 1ta1y.\nKo丑g ， E. B. and T. G. Dietterich. (1995). \"Error-correcti吨 output coding corrects bias and variance.\" 1n Proceedings of the 12th International Conference on Machine Leαrning 仔CML) ， 313-321 , Tahoe City, CA.\nMitchell, T. (1997). Machine Learning. McGrawHill, New YI。此 NY.\nSpackm inductive 1e旧 ar口r，旧 n1让i吨 n1咯g.\" 1n Proceedings of 仇 thε6t仇h Iηn~拢 ter、7羽7nηZ硝 α仰 tizω肌 O7η叫 Zαaωl W orkshop oη n\nMαá， chiη阳eL巳mαrniηn gρWMLυ) ， 160-163, Ithaca, NY. VanRijsbergen, C. J. (1979). Informαtion Retrieval, 2nd edition. Butterworths,\nLondon, UK. Wellek, S. (2010). Tes耐ti叼 ntg 白 Stαt创t化Caαl Hypot仇he臼se臼s of Eq阴u川Z\nrwr忖证侃t句y， 2nd edition. Chapman & HalljCRC, Boca Raton, FL. Zhou, Z.-H. and X.-Y. Liu. (2006). \"On mu1ti-class cost-sen吕i让ti忖ve 1ea缸:，r丑nl山 i\nProc臼E巳eding oft仇he 幻 21stNα， ω仰 t4iiωonaαl Coη1e陀 re， nce on Ar付ti侨.卢CαZaαlln巾teωllig巳7nηωcce (AAA刀.z): ，\n567一572 ， Boston, WA.\n\n休息一会儿\n\n51\n\n休息一会儿\n\n小故事: t 检验、啤酒、 \"学生'与威廉·戈瑟特\n\n1954 年该厂开始出版 《吉尼斯世界纪录大会)) .\n\n1899 年，由于爱尔兰都柏林的吉尼斯啤酒厂热衷于聘 用剑桥、牛津的优秀毕业生，学化学的牛津毕业生威廉·戈\n瑟特 (William Gosset, 1876-1937) 到 该 厂就职，希望将他\n的生 物 化学知识用于啤 酒 生产过程. 为降低 啤酒质量监 控 的戚 本，戈瑟特发明了 t 检验法， 1908 年在 Biometrika 发 表.为防止泄漏商业机密'戈瑟特发表文章时用了笔名 \"学 生\n称为 \"学生氏 t 检验\" (Student's t-test).\n\n吉尼斯啤酒厂是一家很有远见的企业 ? 为保持技 术人员 的高水准 ，该 厂像高校一样给予技术人员\"学术假\" , 1906-1907 年 戈瑟 特得以到\" 统\n计学之父\"卡尔·皮 尔逊 (Karl Pearson, 1857-1936) 教授 在伦敦大学学院 (University College London，简称 UCL) 的实验室访问学习.因此，很 难说 t\n检验法是戈瑟特在啤酒 厂还是在 UCL 访学 期间提出的 ，但 \"学生\"与戈 瑟特之间的联系是被 UCL 的统计学家 们 发现的，尤其因 为皮尔 逊教授 恰是 Biometrika 的主编 .\n\n第 3 章线性模型\n\n3.1 基本形式\n给定由 d 个属性描述的示例 æ = (X1; 白;...; Xd) ， 其中均是 a 在第 4 个属\n性上的取值，线性模型 (linear model) 试图学得一个通过属性的线性组合来进行 预测的函数，即\n\nf(æ) = ω1 X1 + ω2 X2 十 ...+ωdXd + b ,\n\n(3.1)\n\n一般用向量形式写成\n\nf(æ) = ωTæ+b ，\n\n(3.2)\n\n其中 ω=(叫 ;ω2;'\" ;ωd)' W 和 b 学得之后，模型就得以确定.\n\n亦称\"可理解性\" (understandability)\n\n线性模型形式简单、易于建模，但却蕴涵着机器学习中一些重要的基本思 想.许多功能更为强大的非线性模型 (nonlinear model) 可在线性模型的基础上 通过引入层级结构或高维映射而得.此外，由于 ω 直观表达了各属性在预测中 的重要性，因此线性模型有很好的可解释'性 (comprehensibility) .例如若在西瓜 问题中学得 \"f好瓜 (æ)=O.2.x色泽 +O.5.x根蒂 +O.3.x敲声 +1\" ，则意味着可 通过综合考虑色泽、根蒂和敲声来判断瓜好不好，其中根蒂最要紧，而敲声比 色泽更重要.\n\n本章介绍几种经典的线性模型.我们先从回归任务开始，然后讨论三分类 和多分类任务.\n\n3.2 线性回归\n给定数据集 D = {(æ1 ,Y1) , (町，的)，...， (æm ， Ym)} ， 其中 æi (Xi1; zω. . . ; Xid) , Yi ε lR. \"线性回归\" (linear regression) 试图学得一个线性模\n型以尽可能准确地预测实值输出标记.\n我们先考虑一种最简单的情形:输入属性的数目只有一个.为便于讨论，此\n时我们忽略关于属性的下标，即 D = {(Xi ， Yi)}立l' 其中玛巴lR.对离散属性，\n若属性值间存在\"序\" (order) 关系，可通过连续化将其转化为连续值，例如二\n\n54\n\n第 3 章 线性模型\n\n若将元序属性 i主续化， 则会不恰当地引入序关系， 对后续处理如距离计算等 造成误导，参见 9.3 节.\n\n值属性\"身高\"的取值\"高\" \"矮\"可转化为 {1 札 O.叶，三值属性\"高度\" 的取值\"高\" \"中\" \"低\"可转化为 {1 札 0.5 ， 0.0}; 若属性值间不存在序关 系，假定有 k 个属性值，则通常转化为 k 维向量，例如属性\"瓜类\"的取值\"西\n瓜\" \"南瓜\" \"黄瓜\"可转化为 (0， 0 ， 1) ， (0, 1 ，时， (1 , 0, 0).\n线性回归试图学得\n\nf(Xi) 口 ω町 +b， 使得 f(Xi) ~执.\n\n(3.3)\n\n均方误差亦称平方损失 (5quare 1055)\n\n如何确定 ω 和 b 呢?显然?关键在于如何衡量 f(x) 与 u 之间的差别 .2.3 节 介绍过，均方误差 (2.2) 是回归任务中最常用的性能度量，因此我们可试图让均 方误差最小化，即\n\n四*， b* 表示四和 b 的解.\n\n(旷，扩) == arg min ) ~ (f (问)一切 )2 (四 ，b) i:i\n\n= argmin ) :(Yi 一 ωXi -b?\n\n(3.4)\n\n(凹 ， b) 立:\n\n最小二来法用途很广， 不仅限于线性回归\n这里 E(四，则是关于四和 b 的凸函数，当它关于四和 b 的导数均为零时，得到四 和 b 的最优解.\n对区问 [α，叫上定义 的函数 J ， 若它对区间 中任意两点町 ， X2 均有\nf( 咛旦) ;;;监号且ρ ，\n则称 f 为区间 [α ， bJ 上的凸 函数\nU 形曲线的函数如\nf(x) = x2 ， 通常是凸函数\n对实数集上的函数，可 通过求二阶导数来在'J 别 若二阶导数在区间丰非负， 则称为凸函数，若二阶导 数在区间上'隆大于 0 ，则称 为严格凸函数.\n\n均方误差有非常好的几何意义?它对应了常用的欧几里得距离或简称\"欧\n氏距离\" (Euclidean distance). 基于均方误差最小化来进行模型求解的方法称 为\"最小二乘法\" (least squ町e method). 在线性回归中，最小 A 乘法就是试图\n找到一条直线，使所有样本到直线上的欧氏距离之和最小.\n\n求解 ω 和 b 使 E(白，b) = 艺立 1 (Yi → ω问 -b? 最小化的过程，称为线性回归\n\n模型的最小二乘\"参数估计\" (p町ameter estimation). 我们可将 E(四，b) 分到\n\n对 ω 和 b 求导，得到\n\n434-t no'-nu川一ω\n\nJ，\n\n'\n\nS\n\nE\n\nt t\n\n飞 、\n\nω m\n\nm Z M\n\n四 二 协\n\n/ I t\n\n卜\n\nt\n\nE飞\n\nE\\\n\n2旷 m艺 国\n\n汇m 同 扩\n\n~ 川w ω\n\n、\n'bz \\l、BE ll-/' E F /\n\nZ\n\n(3.5) (3.6)\n\n然后令式 (3.5) 和 (3.6) 为零可得到 ω 和 b 最优解的闭式 (closed-form) 解\n\nZ Yi(Xi - x)\n\n24 一去(卦r\n\n(3.7)\n\n3.2 线性回归\n\n55\n\nb= 卢汇(饥一叫，\n\n(3.8)\n\n其中注=去 2二 Xi 为 z 的均值.\n更一般的情形是如本节开头的数据集 D ， 样本由 d 个属性描述.此时我们 试图学得\nf(Xi) = ωTXi + b， 使得 f(仰m叫i) ，巳立 Uωi ,\n归?称\"多交量线性回 这称为\"多元线性回归\" (mu址l扰山t削i忖v缸a.ria臼te line町ar regres部蚓吕剖io叫\n类似的，可利用最小二乘法来对 ω 和 b 进行估计.为便于讨论，我们把 ω\n和 b 吸收入向量形式 'ÛJ = (ω ; b) ， 相应的，把数据集 D 表示为一个 m x (d 十 1)\n大小的矩阵 X ，其中每行对应于一个示例，该行前 d 个元素对应于示例的 d 个 属性值，最后一个元素恒置为 1 ，即\n\nX11 X12 X22\nXm l Xm2\n\n1)(711 X2d I I xi\n\n... ...\n\n1} 1 Xmd\n\n\\x;,\n\n再把标记也写成向量形式 y=(ν1; 如;... ;Ym) ， 则类似于式 (3 剧?有\n\n'ÛJ* = argmin (ν- X 'ÛJ )T (y - X 'ÛJ)\n咀3\n令 Ew = (y - X 'ÛJ)T (y - X'ÛJ)，对'ÛJ求导得到\nåB 生中\n万左= 2X1 (Xψ - y)\n\n(3.9) (3.10)\n\n令上式为零可得 'ÛJ 最优解的闭式解，但由于涉及矩阵逆的计算，比单变量情形 要复杂一些.下面我们做一个简单的讨论.\n当 XTX 为满秩矩阵 (full-rank matrix) 或正走矩阵 (positive definite ma-\ntrix) 时，令式 (3.10) 为零可得\n\n旷= (XTX)~1XTy ，\n\n(3.11)\n\n其中 (XTX)~l 是矩阵 (XTX) 的逆矩阵.令企i = (xi ， l) ， 则最终学得的多元\n\n56\n\n第 3 章线性模型\n\n线性回归模型为\n\nf (Xi ) = x'f (XTXr 1 XTy\n\n(3. 12)\n\n例如，生物信息学的基 因芯片数据中常有成千上 万个属性，但往往只有几 十、上百个样伽l\n回忆一下解线性方程 纽时，若因交量过多，则会 解出多纽解.\n归纳偏好参见1.4 节，丘 则化参见 6 .4、 1 1.4 节\n\n然而，现实任务中 xTx 往往不是满秩矩 阵 .例如在许多任务中我们会遇到 大量的变量?其数目甚至超过样例数，导致 X 的列数多于行数 ， xTx 显然不满 秩.此时可解出多个仙 ， 它们都能使均方误差 最小化.选择哪 一个解作为输出 ， 将由学 习算法的归纳偏好决定， 常见的做法是引入正则化 (regularization) 项.\n线性模型虽简单，却有丰富 的变化. 例如对于样例忡 ， y) ， y ε lR ，当我们希 望线性模型 (3.2) 的预测值逼近真实标记 ν 时， 就得 到了线性 回归模型.为便于 观察?我们把线性回归模 型简写 为\n\nυ =wTx+b .\n\n(3.13)\n\n可否令模型预测值逼近 u 的衍 生物呢? 譬如说，假设我们 认为 示例 所对应的输\n\n出标记是在指数尺度上变化，那就可将输出标记的对数作为线性模型逼近的目\n\n标， 即\n\nlny = wTx +b\n\n(3 .14)\n\n这就是\"对数线性回归\" (log-linear regression) ，它实际上是在试图 让 ewTæ+b\n逼近 y . 式 (3.14)在 形式上仍是线性回归，但实质上已是在求取输入空间到输出 空间的非线性函数映射，如图 3 .1 所 示. 这里的对数函数起到了将线性回归 模 型的预测值与真实标记联系起来的作用.\n\nU\n30\n20 百; = inuz\n\n2 X\n图 3.1 对数线性回归示意图\n\n3.3 对数儿率回归\n\n57\n\ng(.) 连续且充分光滑\n\n更一般地，考虑单调可微函数 g(.) ， 令\n\ny = g-l (WTX 十 的，\n\n(3. 15 )\n\n广义线性祺型的参数估\n计常通过加 权最 小二朱法\n或极大似然法进行\n\n这样得到的模型称为\" 广 义线性模型\" (generalized linear model) ，其中 函数 g(-) 称为\"联系函数\" (link function). 显然? 对数线性回归是广义线性模型在\ng(-) = ln(.) 时的特例.\n\n亦称 Heaviside 函数\n\n3.3 对数几率回归\n上一节讨论了如 何使用线性模型进行 回 归学习，但若要做的是分类任务该 怎么 办?答案蕴涵在式 (3.15) 的广义线 性模型 中.只需 找 一个 单调可做 函数将 分类任务的真实标记 υ 与线性回归模型的 预测值联系起来.\n考虑 二分类任务， 其 输出标记 νε{0， 1} ，而线性 回归模型产生的预测值 z = ωTx +b 是实值，于 是?我们需将实值 z 转换为 0/ 1 值. 最理想的是\"单位\n阶跃函数\" (unit-step function)\n\nI 0, z < 0 ;\ny = < 0.5, z = 0 ;\n1 1, z > 0 ,\n\n(3.16)\n\n即若预测值 z 大于零就判为 正例小于零则判 为反例预测值为 临界值零则可 任意判 别，如图 3.2 所示.\n\np\n\nl\ny= 一 l 一 十 一 巳 ­Z\n\nZ >O z = 0;\n二 <0\n\n10\n\n5\n\n10 z\n\n图 3.2 单位阶跃函数与对数几率函数\n\n58\n\n第 3 章线性模型\n\n简称\"对率函数，\n\n但从图 3.2 可看出，单位阶跃函数不连续，因此不能直接用作式 (3.15) 中 的 g-(-). 于是我们希望找到能在一定程度上近似单位阶跃函数的\"替\n代函数\" (surrogate function) ，并希望它单调可微.对数几率函数 (logistic\nfunction) 正是这样一个常用的替代函数:\n\n注意对数几率函数与 \"对数函数\" ln(.) 不同.\n\n1\ny = 1. + e--~z\n\n(3.17)\n\nSigmoid 函数即形似 s\n的函数对率函数是 Sig-\nmoid 函数最重要的代表，\n在第 5 章将看到它在神经\n网络中的重要作用.\n\n从图 3.2 可看出，对数几率函数是一种 \"Sigmoid 函数\"，它将 z 值转化为一个\n\n接近 0 或 1 的 υ 值并且其输出值在 z 一 0 附近变化很陡.将对数几率函数作为\n\n日,\n\n一\n\ng一(-)代入式 (3.15) ，得到\n\n1 y= 1+ε(四Tæ+b) .\n\n(3.18)\n\n类似于式 (3.14) ，式 (3.18) 可变化为\n\n丑一旦一 =ωTæ+b. 1-y\n\n(3.19)\n\n若将 u 视为样本 z 作为正例的可能性，则 1-y 是其反例可能性，两者的比值\n\nU 1-y\n\n(3.20)\n\n称为\"几率\" (odds) ，反映了 m 作为正例的相对可能性.对几率取对数则得到\n\"对数几率\" (log odds ，亦称 logit)\n\nl丑一旦一-\n1-y\n\n(3.21)\n\n有文献译为\"逻辑回 归，但中文\"逻辑\"与 logistic 和 logit 的含义相 去甚远，因此本书意译为\n\"对数几率回归，简称 \"对率回归，\n\n由此可看出，式 (3.18) 实际上是在用线性回归模型的预测结果去逼近\n真实标记的对数几率，因此，其对应的模型称为\"对数几率回归\" (logistic\nregression ，亦称 logit regr臼sio丑) .特别需注意到，虽然它的名字是\"回归\"，但 实际却是一种分类学习方法.这种方法有很多优点，例如它是直接对分类可能 性进行建模，无需事先假设数据分布?这样就避免了假设分布不准确所带来的 问题;它不是仅预测出\"类别\"，而是可得到近似概率预测，这对许多需利用概 率辅助决策的任务很有用;此外，对率函数是任意阶可导的凸函数，有很好的数 学性质，现有的许多数值优化算法都可直接用于求取最优解.\n\n3.3 对数几率回归\n\n59\n\nF 面我们来看看如何确定式 (3.18) 中的 ω 和 b. 若将式 (3.18) 中的 u 视为类\n后验概率估计 p(y = 1 1x) ， 则式 (3.19) 可重写为\n\np(y p(y\n\n= =\n\n11 01\n\nx) x)\n\n=wTx+b.\n\n(3.22)\n\n显然有\n\nA wTæ+b p(y 二 112)=U\nl+e四 Tæ+b '\n\n(3.23)\n\np ( U = 0 1 z )l=+e1四Tæ十b .\n\n(3.24)\n\n极大似然法参几 7.2 节\n\n于是?我们可通过\"极大似然法\" (maximum likelihood method) 来估计 ω 和 b 给定数据集{(酌 ， Yi)}江l' 对率回归模型最大化\"对数似然\" (log-\n\nlikelihood)\n\n巾 ， b) = 汇 lnp(Yi 1 Xi; 矶的?\n也 =1\n\n(3.25)\n\n即令每个样本属于其真实标记的概率越大越好.为便于讨论，令 β= (ω; 的，\nX = (x; 1) ， 则 wTx +b 可简写为 βT￡ 再令 P1(念;β) = p(ν= 1 1 :金 ;β) ， PO(X; β) = p(y = 0 1X; β) = 1 - P1(企;间，则式 (3.25) 中的似然项可重写为\n\n+ p(饥 1 xi; ω ， b) = 执P1(岛 ;β) (1 ← Yi)PO(向 ;β) .\n\n(3.26)\n\n将式 (3.26)代入 (3 岛) ，并根据式 (3.23) 和 (3.24) 可知，最大化式 (3.25) 等价于\n\n最小化\n\n. e(β) = E (-YißT如叫l+e内))\n\n(3.27)\n\n参见附录 B .4\n\n式 (3.27) 是关于 β 的高阶可导连续凸函数，根据凸优化理论 [Boyd and Vandenberghe, 2004]，经典的数值优化算法如梯度下降法 (gradient descent\nmethod) 、牛顿法 (Newton method) 等都可求得其最优解，于是就得到\n\n= β* argmine(β) .\nβ\n以牛顿法为例，其第 t 十 1 轮选代解的更新公式为\nβt十 +1二 βat- ([-θ;一2- e(βτ)l\\ -1一θ'e一(β一)\n\\8ρoρ 1' )δβ\n\n(3.28) (3.29)\n\n60\n\n第 3 章线性模型\n\n其中关于 β 的一阶、 二 阶导数分别为\nm t t 。C(β) =一)ι: Xi(Yi - P1(Xi; β)) ,\n一 的 åß一å( τ ß'l= β) ) 乞ι :附T加(哉 ?β) ( 1- P1(企i ; ß )) .\n\n(3.30) (3.31)\n\n3 .4线性判别分析\n\n严格说来 LDA 与 Fisher\n判别分析稍有不同，前者 假设了各类样本的协方差\n矩阵相同且 满秩.\n\n线性判另IJ 分析 (Linear Discriminant Analysis ，简称 LDA) 是 一 种 经典的线 性学 习方法， 在二分类问题上因为最早由 [Fisher， 1936] 提出 ， 亦称 \"Fisher 判\n别分析\"\nLDA 的，思想非常朴 素: 给定训练样 例 集 7 设 法将样 例投影到 一条 直 线 上 ， 使得同 类样例的投影 点尽可能接近、 异类样例 的 投影点尽 可 能远离 ;在对 新样 本进 行分类 时，将其投影到 同样的这条 直线 上，再根据投 影 点的位置来确定 新 样本 的类别. 图 3.3 给出了 一个二维示意图.\n\nXl 图 3.3 LDA 的二维示 意图\"+ \"、 \" \"分别代表正例和反例，椭圆表示数据簇的 外轮廓，虚 线表示投影， 红色实心园和实心三 角形分别表示两类样本投影后的中心点.\n给定数据集 D = { (Xi ， Yi)}旦l' Yi 巳 {0， 1 } ， 令 Xi 、阳、 :Ei 分别表 示 第\n1ε {0 ， 1} 类示例的集合、均值向量、协方差矩阵.若将数据投影到直线 w上 ， 则两类样本的中心在直线上 的投影分别为 ωTμo 和 ωTμ1; 若将所有样本点都 投 影到直线上，则两类样本的 协方差分别 为 ωT :Eoω 和 ωT :E 1ω. 由于直线是\n\n3.4 线性判别分析\n\n61\n\n一维空间?因此 wTμ。、 wTμ1 、 wT :Eow 和 ωT :E 1 w 均为实数.\n欲使同类样例的投影点尽可能接近，可以让同类样例投影点的协方差尽可 能小，即 ωT :Eoω+ωT :E 1ω 尽可能小;而欲使异类样例的投影点尽可能远离，\n可以让类中心之间的距离尽可能大，即 11ωTμ。一 ωTμ111~ 尽可能大.同时考虑 二者，则可得到欲最大化的目标\n\nJ=JIwTμ。一 ωTμ111~\n- wT :Eow + WT :E 1 切\nωT(μ。一 μ1)(μ。一 μ1)TW wT( :Eo 十 :E 1 )ω\n\n(3.32)\n\n定义\"类内散度矩阵\" (withi丑-cl回s scatter matrix)\n\nS四=:E o +:E1\n\n=汇 (x 一 μ0) (x 一 μO)T +汇 (x 一 μ1) (x 一 μl)T\n\næEXo\n\nzεXl\n\n以及\"类问散度矩阵\" (betwee坠class scatter matrix)\n\n(3.33)\n\nSb = (μ。一 μ1) (μ。一 μl)T ,\n\n(3.34)\n\n则式 (3.32) 可重写为\n\nJ 一旦旦 一 ωTSwω.\n\n(3.35)\n\n这就是 LDA 欲最大化的目标，即 Sb 与 S凹的\"广义瑞利商\" (generalized Rayleigh quotie叫.\n\n若 w 是一个解，则对 于任意常数 α ， aw 也是 式 (3.35) 的解.\n\n如何确定 ω 呢?注意到式 (3.35) 的分子和分母都是关于 ω 的二次项?因此\n式 (3.35) 的解与 ω 的长度无关?只与其方向有关.不失一般性，令 ωTS四ω= 1, 则式 (3.35) 等价于\n\nmin 一ωTSbW 咀3\ns.t. wTSww = 1 .\n录tf朗日乘子法参几附 由拉格朗日乘子法，上式等价于\n\n(3.36)\n\nSbW = λS四 w ，\n\n(3.37)\n\n62\n\n第 3 章线性模型\n\n其中 λ 是拉格朗日乘子.注意到 Sbω 的方向恒为 μ。一 μ1 ，不妨令\n\nSbW = λ(μ。 -μ1) ,\n\n(3.38)\n\n代入式 (3.37) 即得\n\nω=8;;/(μ。一 μ1) .\n\n(3.39)\n\n奇异值分解参见附录\nA.3 目\n\n考虑到数值解的稳定性，在实践中通常是对 Sw 进行奇异值分解，即 S四= U~VT ，这里 2 是一个实对角矩阵，其对角线上的元素是 S凹的奇异值，然后 再由 st=VZ-IUT 得到 st.\n\n参见习题 7.5\n\n值得一提的是， LDA 可从贝时斯决策理论的角度来阐释，井可证明，当两 类数据同先验、满足高斯分布且协方差相等时， LDA 可达到最优分类.\n\n可以将 LDA 推广到多分类任务中.假定存在 N 个类，且第 4 类示例数为 叫·我们先主义\"全局散度矩阵\"\n\nSt = Sb + Sw\n=2二 (Xi 一 μ)(Xi μ)T ,\n\n(3.40)\n\n其中 μ 是所有示例的均值向量.将类内散度矩阵 S四重定义为每个类别的散度\n\n矩阵之和，即\n\nN\nSw 二三二缸，\n\n(3.41)\n\n其中\n\nL = SWi\n\n(x 一问 )(æ\n\nzεXi\n\n由式 (3 .40)\"-'(3 .42) 可得\n\n向 )T\n\n(3.42)\n\nSb = St - Sw\n\n一 一\n\nN汇 间\n\nm μ\n\nμ μ\n\nμ T\n\n(3 .43)\n\n显然，多分类 LDA 可以有多种实现方法:使用龟 ， Sw , St 兰者中的任何两\n个即可.常见的一种实现是采用优化目标\n\n3.5 多分类学习\n降维参见第 10 章.\n\n63\n\ntr (WTSbW)\nW 位 (WTSwW) ,\n\n(3.44)\n\n其中 W E ]Rdx(N一 1) ， tr(.) 表示矩阵的迹 (tr缸e). 式 (3 .44) 可通过如下广义特征 值问题求解:\n\nSbW = λSw引T .\n\n(3 .45)\n\nW 的闭式解则是 S;_;;lS b 的 N 一 1 个最大广义特征值所对应的特征向量组成的 矩阵.\n若将 W 视为一个投影矩阵，则多分类 LDA 将样本投影到 N-1 维空间， N-1 通常远小子数据原有的属性数.于是，可通过这个投影来减小样本点的 维数，且投影过程中使用了类别信息?因此 LDA 也常被视为一种经典的监督降 维技术\n\n3.5 多分类学习\n\n例如上一节球后介绍的 LDA 推广.\n\n现实中常遇到多分类学习任务.有些二分类学习方法可直接推广到多分类， 但在更多情形下，我们是基于-些基本策略，利用二分类学习器来解决多分类 问题.\n\n通常称分类学习器为\n\"分类器\" (classifier)\n关于多个分类器的集成， 参见第 8 章，\nOvR 亦称 OvA (One vs\nAII) ，但OvA 这个说法不严 格，因为不可能把\"所有 类\"作为反类，\n亦可根据各分类器的预 测置信度等信息进行集成， 参见 8 .4节\n\n不夫一般性，考虑 N 个类别 C1 ， C2 γ •• ， CN ， 多分类学习的基本思路是 \"拆解法飞即将多分类任务拆为若干个二分类任务求解.具体来说，先对问题 进行拆分，然后为拆出的每个二分类任务训练一个分类器;在测试时，对这些分 类器的预测结果进行集成以获得最终的多分类结果.这里的关键是如何对多分 类任务进行拆分，以及如何对多个分类器进行集成.本节主要介绍拆分策略.\n最经典的拆分策略有三种. \"一对一\" (One vs. One ，简称 OvO) 、 \"一对 其余\" (One vs. Rest ，简称 OvR) 和\"多对多\" (Many vs. Ma町，简称 MvM).\n给定数据集 D = {(Xl ,Y1) , (X2 ， 但)， . . . ，但如 Ym)} ， Yi ε {C1 ， C2 ，...， CN}.\nOvO 将这 N 个类别两两配对?从而产生 N(N 一 1)/2 个三分类任务，例如 OvO 将为区分类别 Q 和 Cj 训练 个分类器，该分类器把 D 中的 Q 类样例作为正 例 ， Cj 类样例作为反例.在测试阶段，新样本将同时提交给所有分类器，于是我 们将得到 N(N -1)/2 个分类结果，最终结果可通过投票产生:即把被预测得最 多的类别作为最终分类结果.图 3 .4给出了一个示意图.\nOvR 则是每次将一个类的样例作为正例、所有其他类的样例作为反例来 训练 N 个分类器.在测试时若仅有一个分类器预测为正类，则对应的类别标记 作为最终分类结果?如图 3.4 所示.若有多个分类器预测为正类 7 则通常考虑各\n\n64\n\n第 3 章线性模型\n\n伽γ\n\n~v~ 的\n\n十两类样节 ,\n\n器 预型\n\n(因 圈 )刊→ q\n\n(囚 医蜜函) 斗 h → \" 二，\n\n最终\n\n(曰 圈 )刊→ G\n\n(曰 噩噩)刊 →‘ -\n\n结果 C\n\n(囚 圈 )刊→ q 22( 囚 匮墅里~) =} h -7 \" + \"\n\n(曰圈)刊→ α 叫 (囚 匮翠望)刊→ \" _ ，，\n\n(曰圃)刊→ α (囚 圈 )刊→ α\n\n固 3.4 OvO 与 OvR 示意图\n\n分类器的预测置信度，选择置信度最大的类别标记作为分类结果.\n容易看出， OvR 只需训练 N 个分类器， 而 OvO 需训练 N(N - 1)/2 个分\n类器， 因此， OvO 的存储开销和测试时间开销通常比 OvR 更大. 但在训练时， OvR 的每个分类器均使用全部训练样例，而 OvO 的每个分类器仅用到两个类 的样例，因此，在类别很多时， . OvO 的训练时间开销通常比 OvR 更小 . 至于预 测性能， 则取决于具体的数据分布， 在多数情形下两者差不多.\nMvM 是每次将若干个类作为正类，若干个其他类作为反类.显然， OvO 和 OvR 是 MvM 的特例. MvM 的正、反类构造必须有特殊的设计，不能随意选\n取.这里我们介绍一种最常用的 MvM 技术\"纠错输出码\" (Error Correcting Output Codes，简称 ECOC)..\nECOC [Dietterich and Bakiri, 1995] 是将编码的思想引入类别拆分，并尽\n可能在解码过程中具有容错性. ECOC 工作过程主要分为两步:\n\n·编码:对 N 个类别做 M 次划分， 每次划分将一部分类别划为正类，一部 分划为反类，从而形成一个二分类训 练集;这样一共产生 M 个训练集，可 训练出 M 个分类器.\n·解码:M 个分类器分别对测试样本进行预测 ，这些预测标记组成一个编 码.将这个预测编码与每个类别各自的编码进行比较，返回其中距离最小 的类别作为最终预测结果.\n\n3.5 多分类学习\n\n65\n类别划分通过\"编码矩阵\" (coding matrix) 指定.编码矩阵有多种形式， 常见的主要有二元码 [Dietterich and B此iri， 1995] 和三元码 [Allwein et al.,\n2000]. 前者将每个类别分别指定为正类和反类，后者在正、反类之外，还可指 定\"停用类\"因 3.5 给出了一个示意图，在图 3.5(a) 中，分类器 h 将 Cl 类和 C3 类的样例作为正例 ， C2 类和 C4 类的样例作为反例;在图 3.5(b) 中，分类器 14 将 C1 类和 C4 类的样例作为正例 ， C3 类的样例作为反例.在解码阶段，各分 类器的预测结果联合起来形成了测试示例的编码，该编码与各类所对应的编码 进行比较?将距离最小的编码所对应的类别作为预测结果.例如在图 3.5(a) 中， 若基于欧民距离，预测结果将是 C3.\n\n11 h fa 14 15 距海明离 距欧离氏\n\nh h fa f生\n\n16\n\n• C1\n\n• • ••\n32V3 C1\n\n•C2\n\n• • 4 4 C2\n\n• C3\n\n• • 1 2 C3\n\n• C4\n\n• 22v'2 C生→\n\n••\n\n(纱二元 ECOC 码\n\n。)三元 ECOC 码\n\n距海明欧氏\n离距离\n••\n•4 4 •2 2 • 5 2、ß\n\n圄 3.5 ECOC 编码示意图\"十 1\" 、 \"一 1\" 分别表示学习器 fi 将该类样本作为 正、反例;三元，码中 \"0\" 表示 fï 不使用该类样本\n\n为什么称为\"纠错输出码\"呢?这是因为在测试阶段， ECOC 编码对分类 器的错误有一定的容忍和修正能力.例如图 3.5(a) 中对测试示例的正确预测编 码是 (-1 ， +1 ，十 1 ，一 1 ， +1) ，假设在预测时某个分类器出错了，例如 h 出错从而 导致了错误编码 (-1 ， -1 ， +1 ，一 1 ， +1) ，但基于这个编码仍能产生正确的最终分 类结果 C3. 一般来说，对同一个学习任务， ECOC 编码越长，纠错能力越强.然 而，编码越长，意味着所需训练的分类器越多，计算、存储开销都会增大;元一 方面，对有限类别数 3 可能的组合数目是有限的，码长超过一定范圃后就失去了 意义.\n对同等长度的编码，理论上来说，任意两个类别之间的编码距离越远，则纠 错能力越强.因此，在码长较小时可根据这个原则计算出理论最优编码.然而， 码嵌稍大一些就难以有效地确定最优编码，事实上这是 NP 难问题.不过，通常 我们并不需获得理论最优编码，因为非最优编码在实践中往往己能产生足够好 的分类器.另一方面，并不是编码的理论性质越好，分类性能就越好，因为机器\n\n66\n\n第 3 章线性模型\n\n学习问题涉及很多因素，例如将多个类拆解为两个\"类别子集 式所形成的两个类另别u 于集的区分难度往往不间即其导致的二分类问题的难度 不同盹;于是'一个理论纠错牲质很好、 {ê. 导致的三分类问题较难的编码，与另一 个理论纠错性质差→些、但导致的二分类问题较简单的编码，最终产生的模型 性能孰强孰弱很难说.\n\n3.6 类别不平衡问题\n\n前面介绍的分类学习方法都有→个共同的基本假设，即不同类别的训练样 例数目相当.如果不同类别的训练样例数目稍有差别，通常影响不大，但若差别 很大，则会对学习过程造成困扰.例如有 998 个反例，但正例只有 2 个，那么学 习方法只需返回一个永远将新样本预测为反例的学习器，就能达到 99.8% 的精 度;然而这样的学习器往往没有价值，因为它不能预测出任何正例.\n\n对 OvR 、 MvM 来说，由 于对每个类进行了相同的 处理，其拆解出的二分类 任务中类别不平衡的影响 会相互抵消，因此通常不\n需专门处理.\n\n类别不平衡 (cla胁 imbalance) 就是指分类任务中不同类别的训练样例数 目差别很大的情况.不失一般性，本节假定正类样例较少，反类样例较多. 在现实的分类学马任务中，我们经常会遇到类别不平衡?例如在通过拆分 法解决多分类问题时，即使原始问题中不同类别的训练样例数目相当 7 在使 用 OvR 、 MvM策略后产生的二分类任务仍可能出现类别不平衡现象，因此有 必要了解类别不平衡性处理的基本方法.\n从线性分类器的角度讨论容易理解，在我们用 y=wTx+b 对新样本 m 进行分类时，事实上是在用预测出的 υ 值与一个阔值进行比较，例如通常在\ny > 0.5 时判别为正例，否则为反例 u 实际上表达了正例的国能性，几率古\n则反映了正例可能性与反例可能性之比值，阔值设置为 0.5 恰表明分类器认为 真实正、反例可能性相同，即分类器决策规则为\n\n若 τ旦一> 1 则预测为正例.\nl-y\n\n(3.46)\n\n元偏采样意味着真实样 本总体的类别比例在训练 集中得以保持.\n\n然而，当训练集中正、反例的数目不同时，令 m十表示正倒数目， m一表示\n反倒数目，则观测几率是罪，由于我们通常假设训练集是真实样本总体的无偏\n采样?因此观测几率就代表了真实几率.于是，只要分类器的预测几率高于观泪 IJ 几率就应判定为正例 7 即\n\n川\n\n旷盯+\n\n若 7立一>工L 贝 IJ 预测为正例.\n\nl-Y\n\nηz 一\n\n(3 .47)\n\n3.7 阅读材料\n\n67\n\n但是，我们的分类器是基于式 (3.46) 进行决策，因此，需对其预测值进行调\n\n整，使其在基于式 (3.46) 决策时，实际是在执行式 (3 .47). 要做到这 点很容易，\n\n只需令\n\n- - y'\n\ny m\n\n一 1-- y' -1- - . Y m+\n\n(3.48)\n\n亦称\"再平衡>> (rebalance).\n欠采样亦称\"下采样\" (downsampling) ，过采样 亦称\"上采样\" (upsampling)\n\n这就是类别不平衡学习的一个基本策略一\"再缩放\" (rescaling).\n再缩放的思想虽简单，但实际操作却并不平凡，主要因为\"训练集是真实 样本总体的无偏采样\"这个假设往往并不成立，也就是说 7 我们未必能有效 地基于训练集观测几率来推断出真实几率.现有技术大体上有三类做法:第 一类是直接对训练集里的反类样例进行\"欠采样\" (undersampling) ，即去除 一些反倒使得正、反例数日接近 7 然后再进行学习;第二类是对训练集里的 正类样例进行\"过来样\" (oversampling) ，即增加一些正例使得正、反例数目 接近，然后再进行学习;第三类则是直接基于原始训练集进行学习，但在用 训练好的分类器进行预测时，将式 (3.48) 嵌入到其决策过程中，称为\"阔值移\n动\" (threshold-moving).\n\n欠采样法的时间开销通常远小于过来样沽，因为前者丢弃了很多反例，使 得分类器训练集远小子初始训练集，而过来样法增加了很多正例，其训练、集 大于初始训练集.需注意的是，过采样法不能简单地对初始正例样本进行重\n复来样，否则会招致严重的过拟合 7 过采样法的代表性算法 SMOTE [Chawla et al., 2002] 是通过对训练集里的正例进行插值来产生额外的正例.另一方面，\n欠采样法若随机丢弃反例?可能丢失一些重要信息;欠采样法的代表性算法\nEasyEnsemble [Liu et 此， 2009] 则是利用集成学习机制，将反倒划分为若干个\n集合供不同学习器使用，这样对每个学习器来看都进行了欠采样，但在全局来 看却不会丢失重要信息.\n\n代价敏感学习研究非\n均等代价下的学习参见\n2.3.4 节\n\n值得一提的是，\"再缩放\"也是\"代价敏感学习\" (cost-sensitive le缸任 ing) 的基础.在代价敏感学习中将式 (3.48) 中的 m-jm+ 用 cost+ jcosr 代替即\n可，其中 cost+ 是将正例误分为反倒的代价 ， cost 是将反例误分为正例的代价.\n\n参见第 11 拿.\n\n3.7 阅读材料\n\"稀疏表示\" (sparse representation) 近年来很受关注，但即使对多元线性 回归这样简单的模型，获得具有最优\"稀疏性\" (sparsity)的解也并不容易.稀 疏性问题本质上对应了 Lo 范数的优化，这在通常条件下是 NP 难问题. LASSO [Tibshirani, 1996] 通过 L1 范数来近似 Lo 范数，是求取稀疏解的重要技术.\n\n68\n\n第 3 章线性模型\n\n可以证明， OvO 和 OvR 都是日COC 的特例 [Allwein et al., 2000]. 人们以 往希望设计通用的编码法， [Crammer and Singer, 2002] 提出要考虑问题本身\n的特点，设计\"问题依赖\"的编码法，并证明寻找最优的离散编码矩阵是一个 NP 完全问题.此后，有多种问题依赖的 ECOC 编码法被提出，通常是通过找\n出具有代表性的二分类问题来进行编码 [Pujol et 此， 2006, 2008]. [Escalera 创\n乱， 2010] 开发了一个开源 ECOC 库.\nMvM 除了 ECOC 还可有其他实现方式，例如 DAG (Directed Acyclic Graph) 拆分法 [Platt et al., 2000] 将类别划分表达成树形结构，每个结点对应\n于一个二类分类器.还有一些工作是致力于直接求解多分类问题，例如多类支\n持向量机方面的一些研究 [Crammer and Singer, 2001; Lee et 此， 2004].\n代价敏感学习中研究得最多的是基于类别的\"误分类代\n价\" (misclassification cost)) 代价矩阵如表 2.2 所示;本书在提及代价敏感\n学习时，默认指此类情形.已经证明，对二分类任务可通过\"再缩放\"获得理论 最优解 [Elkan， 2001] ，但对多分类任务，仅在某些特殊情形下存在闭式解 [Zhou\nand Liu, 2006a]. 非均等代价和类别不平衡性虽然都可借助\"再缩放\"技术， 但两者本质不同 [Zhou and Liu, 2006b]. 需注意的是，类别不平衡学习中通常\n是较小类的代价更高，否则无需进行特殊处理.\n多分类学习中虽然有多个类别，但每个样本仅属于一个类别.如果希望为 一个样本同时预测出多个类别标记，例如一幅图像可同时标注为\"蓝天\"、\n\"白云\"、 \"羊群\"、 \"自然场景\"?这样的任务就不再是多分类学习，而是 \"多标记学习\" (multi-labellearning) ，这是机器学习中近年来相当活跃的一个\n研究领域.对多标记学习感兴趣的读者可参阅 [Zhang and Zhou, 2014].\n\n习题\n\n69\n\n习题\n\n3.1 试析在什么情形下式 (3.2) 中不必考虑偏置项 b.\n\n3.2 试证明，对于参数 ω，对率团归的目标函数 (3.18) 是非凸的，但其对数\n似然函数 (3.27) 是凸的.\n\n西~数据集 3.0日见 p.89 的表 4.5.\nUCI 数据集见 http://archive.ics.uci 创 ujmlj\n\n3.3 3.4\n\n编程实现对率回归，并给出西瓜数据集 3.0α 上的结果.\n选择两个 UCI 数据集，比较 10 折交叉验证法和留 法所估计出的对 率回归的错误率.\n\n线性可分是指存在线性 趋平面能将不同类的样本 点分开参见 6.3 节\n\n3.5 编辑实现线性判别分析，并给出西瓜数据集 3.0α 上的结果.\n3.6 线性判别分析仅在线性可分数据上能获得理想结果?试设计一个改进\n方法，使其能较好地周于非线性可分数据\n\n3.7 令码长为 9 ，类别数为 4 ，试给出海明距离意义下理论最优的 ECOC\n二元码井证明之.\n\n3.8*\n\nECOC 编码能起到理想纠错作用的重要条件是:在每一位编码上出错 的概率相当且独立.试析多分类任务经 ECOC 编码后产生的二类分 类器满足该条件的可能性及由此产生的影响.\n\n3.9 使用 OvR 和 MvM 将多分类任务分解为二分类任务求解时，试述为何\n无需专门针对类别不平衡性进行处理.\n\n3.1 伊\n\n试推导出多分类代价敏感学习(仅考虑基于类别的误分类代价)使用 \"再缩放\"能获得理论最优解的条件.\n\n70\n\n第 3 章线性模型\n\n参考文献\n\nAllwein, E. L. , R. E. Schapire, and Y. Singer. (2000). \"Reduci吨 multiclass to binary: A uni命ing approach for margin classifiers.\" Journal of Machine\n\nLeαrning Reseαrch， 1:113-141.\n\nBoyd, S. and L. Vande由erghe. (2004). Convex Optimization. Cambridge U丑时i versi让ty Press, Cambridge, UK.\n\nChawla, N. V. , K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer. (2002). \"SMOTE: Synthetic minority over句sampling technique.\" Journal of Artificial Intelligence Reseαrch， 16:321-:-357.\n\nCrammer, K. and Y. Singer. (2001). \"On the algorithmic implementation of multiclass kernel-based vector machines.\" Journal of Mα chine Learning Re-\n\nseαrch， 2:265-292.\n\nJ\n\nCrammer, K. and Y. Singer. (2002). \"On the learnability and design of 01即ut\n\ncodes for multiclass problems.\" Machine Learning, 47(2-3):201-233.\n\nDi抬et忱t盯 e由r .\n\nvia error-correcting o旧 utp时 ut ∞ code臼吕 \" Journαl of Artificial Intelligence Reseαrch， 2:263-286.\n\nElkan, C. (2001). \"The foundations of cost-sensitive learning.\" In Proceedings of the 17th Internαtional Joint Conference on Artifiçial Intelligence (IJCAI) , 973-978, Seattle, WA.\n\nEscalera，鼠， O. Pujol, and P. Radeva. (2010). \"Error-correcting ouput codes\n\nlibrary.\" Journal of Machine Leαrning Reseαrch， 11:661-664.\n\nFisher, R. A. (1936). \"The use of multiple measuremer由 in taxonomic problems.\" Annals of E叼enics， 7(2):179-188.\n\nLee, Y., Y. Lin, and G. Wahba. (2004). \"Multicategory support vector machines, theory, and application to the classification of microarray data and satellite radiance data.\" Journal of the American Statistical Association, 99\n\n(465):67-81.\n\nLiu, X.-Y., J. Wu, and Z.-H. Zhou. (2009). 咀xploratory undersamping for class句 imbalance learning.\" IEEE Trα nsαctions on Systems, Mα n， αnd Cyberneticíi - Part B: Cybernetics, 39(2):539-550.\n\nPlatt, J. C. , N. Cristianini, and J. Shawe-Taylor. (2000). \"Large margin DAGs\n\n参考文献\n\n71\nfor multiclass classification.\" In Advαnces in Neural Informαtion Processing\nSy础ms 12 (NIPS) (8. A. 8011a, T. K. Leen, and K.-R. Müller, eds.) , MIT Press, Cambridge, MA. Pujol, 0. , 8. Escalera, and P. Radeva. (2008). 咀n incremental node embedding technique for error correcting output codes.\" Pattern Recognitìon, 41(2):713一\n725.\nPujol, 0. , P. Radeva, and J. Vitrià. (2006). \"Discriminant ECOC: A heuristic\nmethod for application dependent design of error correcti丑g output codes.\"\nIEEE 卧αnsαctions on Pattern Analysis and Machine Intelligence, 28(6):\n1007-1012.\nTibshirani, R. (1996). \"Regression shrinkage and selection via the LA880.\" Journal of the Royal Stαtistical Soc化ty: Series B , 58(1):267-288.\nZha吨， M.-L. and Z.-H. Zhou. (2014). 咀 review on multi-label learning algorithms.\" IEEE Transactions on Knowledge αnd Datα Engineering， 26(8): 1819-1837.\nZhou, Z.-H. and X.-Y. Liu. (2006a). \"On multi-class cost-sensitive learning.\" In\nProceeding ofthe 21st National Conference on Art侨cial Intelligence (AAA刀，\n567-572, Boston, WA. Zhou, Z.-H. and X.-Y. Liu. (2006b). \"1ì:创ai由 n 19 cost-sensitive neural networks\nwith methods addressing the class imbalance problem.\" IEEE 1子αnsαctions onKnm此dge αnd Datα Engineering， 18(1):63-77.\n\n72 休息一会儿\n\n第 3 章线性模型\n\n小故事:关于\"最小二乘法\"\n\n1801 年，意大利天文学家皮亚齐 发现了 1 号小行星\"谷神星\"，但在跟\n踪观 测 了 40 天后，因谷神 星转至太阳 I I立了14、 二 ! l\n的背后 ，皮 亚齐失去了谷 神 星的位置.\n许 多 天 文学家试图重新找 到谷神星，但 (1993 年版德国 10 马克纸 币主的高斯像)\n都 徒劳无 获. 这 引起了 伟 大的德国数 学家高斯 (1777-1855) 的注意 ，他 发 明了一 种方 法?根据皮亚齐的 观测数 据计 算出了谷神星的轨道， 后来德 国天文学家 奥伯斯 在高斯预言 的时间 和星空领域 重新找 到 了谷神星. 1809 年， 高斯在他 的著作 《天体运动论 》中发表了这种 方 法 ， 即 最 小二乘法.\n\n另两位是拉格朗日和拉 普拉斯，三人姓氏首字母\n斗目同，时{~ \"3L\"\n\n1805 年， 在椭圆积 分 、 数 论和几何方面都有重大贡献的法国大 数 学家勒让 德 (1752一1833) 发表 了 《 计算 彗星 轨道的新方法 )) ，其附录中描述了最小 二乘 法.勒 让德是法国 18一19 世 纪数学界 的三驾马车 之一， 早已是法国 科学 院院 士 .但 勒 让德的书中 没有涉及最小二乘 法的误差 分析?高 斯 1809 年的 著作 中 包 括了这方 面的内容，这对 最小 二乘法用于 数理统 计、乃至 今天的机器学习 有极 为重 要的意义.由于高斯 的 这一重大 贡 献 ，以及他 声称自己 1799 年就 已 开 始使 用这个方 法?因此 很 多人将最 小 二乘洼的发明优 先权归 之为高斯 .当时 这两位 大数学家发生了著名的 优 先权之争，此后有 许多 数学史家专 门进行研究 ， 但至 今也 没弄清到底是谁最 先发 明了最小二乘 法 .\n\n第 4 章决策树\n\n4.1 基本流程\n\n亦称\"判定树\"根据 上下文，本书中的\"决策 树\"有时是指学习方法， 有时是指学得的树.\n\n决策树 (decision tree) 是一类常见的机器学习方法.以二分类任务为例，我 们希望从给定训练数据集学得一个模型用以对新示例进行分类，这个把样本 分类的任务，可看作对\"当前样本属于正类吗?\"这个问题的\"决策\"或\"判 定\"过程.顾名思义，决策树是基于树结构来进行决策的，这恰是人类在面临决 策问题时一种很自然的处理机制.例如，我们要对\"这是好瓜吗?\"这样的问题 进行决策时，通常会进行一系列的判断或\"子决策\"我们先看\"它是什么颜 色?\"，如果是\"青绿色\"，则我们再看\"它的根蒂是什么形态?\"，如果是\"蜷 缩\"，我们再判断\"它敲起来是什么声音?\"，最后?我们得出最终决策:这是个 好瓜.这个决策过程如图 4.1 所示.\n\n青绿\n\n图 4.1 西瓜问题的一棵决策树\n显然 7 决策过程的最终结论对应了我们所希望的判定结果，例如\"是\"或 \"不是\"好瓜;决策过程中提出的每个判定问题都是对某个属性的\"拥t 试\"， 例如\"色泽=?\" \"根蒂:?\";每个测试的结果或是导出最终结论，或是导出 进一步的判定问题，其考虑范国是在上次决策结果的限定范围之内，例如若在 \"色泽=青绿\"之后再判断\"根蒂=?\"，则仅在考虑青绿色瓜的根蒂.\n一般的，一棵决策树包含一个根结点、若干个内部结点和若干个叶结点;\n\n74\n\n第 4 章决策树\n\n叶结点对应于决策结果?其他每个结点则对应于一个属性测试;每个结点包含 的样本集合根据属性测试的结果被划分到子结点中;根结点包含样本全集.从 根结点到每个叶结点的路径对应了一个判定测试序列.决策树学习的目的是为 了产生一棵泛化能力强，即处理未见示例能力强的决策树，其基本流程遵循简 单且直观的\"分而治之\" (divide-and-conquer) 策略，如图 4.2 所示.\n\n递归返回，情形 (1).\n递归远目，情形 (2). 我们将在下一节讨论如 何获得最优划分属性\n递归返回，情形 (3). 从 A 中去掉 α..\n\n输入:训练集 D = {(X1 ,Y1) , (X2 ， 但)，.. . , (Xm,Ym)};\n属性集 A={α1 ， a2 ，...， 句}.\n过程:函数TreeGenerate(D ， A)\n1: 生成结点 node;\n2: if D 中样本金属于同一类别 C then\n3: 将 node 标记为 C 类叶结点 return\n\n4: end if 5: if A= 0 ORD 中样本在 A 上取值相同 then 6: 将 node 标记为叶结点，其类别标记为 D 中样本数最多的类; return\n\n7: end if\n8: 从 A 中选择最优划分属性向;\n9: for 仇的每一个值 a~ do\n\n10: 为 node 生成一个分支;令 Dv 表示 D 中在岛上取值为 4 的样本子集;\n\n11: if Dv 为空 then\n\n12:\n\n将分支结点标记为叶结点，其类别标记为 D 中样本最多的类; return\n\n13: else\n\n14:\n\n以坚eeGenerate(Dv) A \\ {α*} )为分支结点\n\n15: end if\n\n16: end for\n\n输出:以 node 为根结点的‘棵决策树\n\n图 4.2 决策树学习基本算法\n\n显然?决策树的生成是一个递归过程.在决策树基本算法中，有三种情形会 导致递归返回: (1) 当前结点包含的样本全属于同一类别，无需划分; (2) 当前 属性集为空，或是所有样本在所有属性上取值相同，无法划分; (3) 当前结点包 含的样本集合为空，不能划分.\n在第 (2) 种情形下?我们把当前结点标记为叶结点，井将其类别设定为该结 点所含样本最多的类别;在第 (3) 种情形下，同样把当前结点标记为叶结点) 1且 将其类别设定为其父结点所含样本最多的类别.注意这两种情形的处理实质不 同:情形 (2) 是在利用当前结点的后验分布，而情形 (3) 则是把父结点的样本分布 作为当前结点的先捡分布.\n\n4.2 划分选择\n\n75\n\n4.2 划分选择\n\n由算法 4.2 可看出 7 决策树学习的关键是第 8 行，即如何选择最优划分属 性一般而言，随着划分过程不断进行，我们希望决策树的分支结点所包含的样 本尽可能属于同一类别，即结点的\"纯度\" (purity) 越来越高.\n\n4.2.1 信息增益\n\n计算信息煽时约定:若 p=o. 则 plog2P 二 O\nEnt(D) 的录 .j、值为 o.\n最大值为 10旬以|\n\n\"信息铺\" (information entropy) 是度量样本集合纯度最常用的一种指标.\n\n假定当前样本集合 D 中第 k 类样本所占的比例为 Pk (k = 1, 2,. . . , IYI) ，则 D\n\n的信息娟定义为\n\nIYI\n\n时 (D) = - I:>k1og2Pk\n\n(4.1)\n\nk=l\n\n日nt(D) 的值越小，则 D 的纯度越高.\n\n假定离散属性 α 布 V 个可能的取值 {α1 ， α2 尸. ， α勺，若使用 α 来对样本集 D 进行划分，则会产生 V 个分支结点?其中第 u 个分支结点包含了 D 中所有在 属性 α 上取值为 α\" 的样本 7 记为 DV. 我们可根据式(4.1) 计算出 DV 的信息:盹 再考虑到不同的分支结点所包含的样本数不同?给分支结点赋予权重 IDVI/IDI ， 即样本数越多的分支结点的影响越大，于是可计算出用属性 α 对样本集 D 进行\n划分所获得的\"信息增益\" (information gain)\n\nJ乌 IDVI Gain(D ， α) = Ent(D) 一>但:一I:DdI Ent(DV ) .\n\n(4.2)\n\nID3 名字中的 ID 是 It­ erative Dichotomiser (迭代 二分器)的简称\n\n一般而言，信息增益越大，则意味着使周属性 α 来进行划分所获得的\"纯 度提升\"越大.因此，我们可用信息增益来进行决策树的划分属性选择，即在圈 4.2 算法第 8 行选择属性 ω= 町gmaxGain(D ， α). 著名的 ID3 决策树学习算\nαεA\n法 [Quinlan ， 1986] 就是以信息增益为准则来选择划分属性.\n以表 4.1 中的西瓜数据集 2.0 为例，该数据集包含 17 个训练样例，用以学\n习一棵能预测设剖开的是不是好瓜的决策树.显然， IYI = 2. 在决策树学习开\n始时，根结点包含 D 中的所有样例，其中正例占 P1 = 击，反例占的 =ii 于 是，根据式 (4.1) 可计算出根结点的信息:脑为\n\nEnt(D)\n\n二\n\n-E~PKlom\n\n一((币8 .10吨8十五9 .10g 2\n\n9\\ 1\"'7)\n\n=\n\n76\n\n第 4 章决策树\n\n编号\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17\n\n色泽 青绿 乌黑 乌黑 青绿 浅白 青绿 乌黑 乌黑 乌黑 青绿 洁白 洁白 青绿 浅白 乌黑 践自 青绿\n\n表 4.1 西瓜数据集 2.0\n\n根蒂 蜷缩 蜡缩 蜡缩 蜷缩 蜷缩 稍蜷 稍蜷 稍蜷 稍蜷 硬挺 硬挺 蜷缩 稍蜷 稍蜷 稍蜷 蜷缩 蜡缩\n\n敲声 浊响 沉闷 1虫响 沉闷 浊响 浊响 浊日向 独日向\n祝闷 清脆 清脆 浊响 浊响 沉闷 浊响 浊响 沉闷\n\n纹理\n清晰 清晰 清晰 清晰 清晰 清晰 稍糊 清晰 硝糊 清晰 模糊 模糊 稍糊 稍糊 清晰 模糊 稍糊\n\n脐部 凹陷 凹陷 凹陷 凹陷 凹陷 稍凹 稍凹 稍凹 稍凹 平坦 平坦 平坦 凹陷 凹陷 稍凹 平坦 稍凹\n\n触感 硬滑 硬滑 硬滑 硬滑 硬滑 软粘 软粘 硬滑 硬滑 软粘 硬滑 软粘 硬滑 硬情 软粘 硬滑 硬滑\n\n好瓜 是 是 是 是 是 是 是 是 否 否 否 否 否 否 否 否 否\n\n然后，我们要计算出当前属性集合{色泽，根蒂，敲声，纹理，脐部，触感} 中每个属性的信息增益.以属性\"色泽\"为例，它有 3 个可能的取值: {青绿，乌\n黑，浅自}.若使用该属性对 D 进行划分，则可得到 3 个子集，分别记为: D 1 (色 泽=青绿)， D2 (色泽2 乌黑)， D 3 (色泽=浅白).\n子集 D 1 包含编号为 {1 ， 4, 6, 10, 13, 17} 的 6 个样例，其中正例占 p1=3 ， 反例占的=~; D2 包含编号为 {2 ， 3, 7, 8, 9, 15} 的 6 个样例，其中正、反例分\n别占 Pl = ~， P2 = ~; D3 包含编号为 {5 ， 11, 12, 14, 16} 的 5 个样例，其中正、\n反例分别占 pl=i ，的= !.根据式 (4.1) 可计算出用\"色泽\"划分之后所获得 的 3 个分支结点的信息:精为\n\nI == Ent(D l ) = 一(一63 l'~oOg:l23 -6 十'3 一6 l.3 o~gO2~ ~6)} 000 1.~.~~~ ,\n:l) Ent(D ( 4 4 2 2 ) = 一一6'l~oO g2:l 一6+'.;;6'l~oO g2:l 一 6J口 0~..9~1~8~，\n+ i Ent(D,j) ==一(一51 l'o~gO2:l1 ;5. '45 l.4 o~gO2~ 一 5)}= 0~...72-2- ,\n\n于是，根据式 (4.2) 可计算出属性\"色泽\"的信息增益为\n\n4.2 划分选择\n\n77\nGain(D ，色泽) = Ent(D) 一>f含L:lrD一IUD~I!Ent(DV)\n= 0.998 一 (167 x 1 肌言×圳Oω肌 9 ;X川川0 7叫川η2\n工 0.109.\n类似的，我们可计算出其他属性的信息增益:\nGain(D ，根蒂) = 0.143; Gain(D ，敲声) = 0.141;\nGain(D ，纹理) = 0.381; Gain(D ，脐部) = 0.289;\nGai丑 (D ， 触感) = 0.006.\n显然，属性\"纹理\"的信息增益最大?于是它被选为划分属性.图 4.3 给出 了基于\"纹理\"对根结点进行划分的结果，各分支结点所包含的样例子集显示 在结点中.\n\n固 4.3 基于\"纹理\"属性对根结点划分\n\n\"纹理\"不再作为候选 为j 分属性\n\n然后，决策树学习算法将对每个分支结点做进一步划分.以图 4.3 中第一 个分支结点( \"纹理=清晰\" )为例，该结点包含的样例集合 D 1 中有编号为 {1 ，\n2, 3, 4, 5, 6, 8, 10, 15} 的 9 个样例，可用属性集合为{色泽，根蒂，敲声，脐部 7 触感}.基于 D 1 计算出各属性的信息增益:\nGain(D 1 ， 色泽) = 0.043; Gain(D 1 ，根蒂) = 0.458; Gain(D 1 ，敲声) = 0.331; Gain(D 1 ，脐部) = 0.458; Gain(D1 ，触感) = 0.458.\n\"根蒂\"、 \"脐部\"、 \"触感\" 3 个属性均取得了最大的信息增益，可任 选其中之一作为划分属性.类似的，对每个分支结点进行上述操作，最终得到的 决策树如圈 4.4 所示.\n\n4.2.2 增益率 在上面的介绍中，我们有意忽略了表 4.1 中的\"编号\"这一列.若把\"编\n\n78\n\n第 4 章决策树\n\n图 4.4 在西瓜数据集 2.0 上基于信息增益生成的决策树\n\n号\"也作为一个候选划分属性，则根据式件均可计算出它的信息增益为 0.998 ， 远大于其他候选划分属性.这很容易理解\"编号\"将产生 17 个分支，每个分 支结点仅包含一个样本，这些分支结点的纯度己达最大.然而，这样的决策树显 然不具有泛化能力，无法对新样本进行有效预测.\n实际上，信息增益准则对可取值数目较多的属性有所偏好，为减少这种 偏好可能带来的不利影响，著名的 C4.5 决策树算法 [Quinlan， 1993J 不直接使\n用信息增益，而是使用\"增益率\" (gain ratio) 来选择最优划分属性.采用与\n式 (4.2) 相同的符号表示，增益率定义为\n\nGai丑_ratio(D ， a) = ← Ga一iIVn一((αD一)， 一 α)\n\n(4.3)\n\n其中\n\n(α) 安 ID叫 l|DUl\n/一士1 I页。g2 商\n\n(4.4)\n\n称为属性 α 的\"固有值\" (intrinsic value) [Quinlan, 1993J. 属性 α 的可能\n取值数目越多(即 V 越大)，则 IV(α) 的值通常会越大.例如，对表 4.1 的西\n瓜数据集 2.0，有 IV(触感) = 0.874 (V = 2) , IV(色泽) = 1.580 (V = 3) ,\nIV(编号) = 4.088 (V = 17).\n需注意的是，增益率准则对可取值数目较少的属性有所偏好?因此 ， C4.5 算法并不是直接选择增益率最大的候选划分属性，而是使用了一个启发式\n\n4.3 剪枝处理\n\n79\n\n[Q回nlan， 1993]: 先从候选划分属性中找出信息增益高于平均水平的属性，再从 中选择增益率最高的.\n\nCART 是 Classification\nand Regression Tr.胆的简 称，这是一种著名的决策 树学习算法，分类和回归 任务都可用\n\n4.2.3 基尼指数\nCART 决策树 [Breiman et al., 1984] 使用\"基尼指数\" (Gini index) 来选\n择划分属性.采用与式 (4.1) 相同的符号，数据集 D 的纯度可用基尼值来度量:\n\nG叫\n\nk=1k' 予他\nIYI =1- ~二 p1.\n\n(4.5)\n\n直观来说， Gini(D) 反映了从数据集 D 中随机抽取两个样本，其类别标记 不一致的概率.因此， Gini(D) 越小，则数据集 D 的纯度越高.\n采用与式 (4.2) 相同的符号表示，属性 α 的基尼指数定义为\n\nGiniJndex(D,a) =ι匀 )I:DI;IV-..D._II,' Gini(DV) .\n\n(4.6)\n\n于是，我们在候选属性集合 A 中，选择那个使得划分后基尼指数最小的属\n性作为最优划分属性，即向= argmin GiniJndex(D ， α).\nαεA\n\n4.3 剪枝处理\n\n关于过拟合，参见2.1 节.\n\n剪枝 (pruning) 是决策树学习算法对付\"过拟合\"的主要手段.在决策树学 习中，为了尽可能正确分类训练样本，结点划分过程将不断重复，有时会造成决 策树分支过多，这时就可能因训练样本学得\"太好\"了，以致于把训练集自身 的一些特点当作所有数据都具有的一般性质而导致过拟合.因此，可通过主动 去掉一些分支来降低过拟合的风险.\n决策树剪枝的基本策略有\"预剪枝\" (prepruning) 和\"后剪枝 \"(post\"\npruning) [Quinlan, 1993]. 预剪枝是指在决策树生成过程中，对每个结点在划\n分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划 分并将当前结点标记为叶结点;后剪枝则是先从训练集生成一棵完整的决策树， 然后自底向上地对非叶结点进行考察，若将该结点对应的子树替换为叶结点能\n\n80\n\n第4章 决 策 树\n\n带来决策树泛化性能提升，则将该子树替换为叶结点.\n如何判断决策树泛化性能是否提升呢?这可使用 2.2 节介绍的性能评估 方法.本节假定采用留出法，即预留一部分数据用作\"验证集\"以进行性 能评估.例如对表 4.1 的西瓜数据集 2 札我们将其随机划分为两部分，如 表 4.2 所示，编号为 {1 ， 2 ， 3 ， 6 ， 7， 10 ， 14 ， 15 ， 16 ， 17} 的样例组成训练集，编号为 {4， 5 ， 8 ， 9 ， 11 ， 12 ， 13} 的样例组成验证集.\n\n揣 肌 表 4.2 西瓜数据集 2.0 划分出的训练集(双线上部)与验证集(双线下部)\n\n根蒂\n\n敲声\n\n纹理\n\n脐部\n\n触感\n\n一1\n2 3 6 7\n\n一一 蜡缩 蜡缩 蜷缩 稍蜷 稍蜷\n\n一一\n\n浊 沉 浊 浊 浊\n\n响 闷 响 响 响\n\n一清晰 清晰 清晰 清晰 稍糊\n\n一一\n\n凹陷\n\n凹陷\n\n凹陷\n\n稍 稍\n\n凹 凹\n\n一一 硬滑 硬滑 硬滑 软粘 软粘\n\n一 是 是\n\n吨' 4 吨' 2 4 咱 品E 咱\n\nn U A a t k d n\n\nE品 0\n\n青绿\n\n硬挺\n\n浅白\n\n稍蜷\n\n乌黑 浅白 青绿\n\n稍 蜷 蜷\n\n蜷 缩 缩\n\n清脆\n\n沉闷\n\n浊 浊 沉\n\n响 响 闷\n\n清晰\n\n稍糊\n\n清 模 稍\n\n晰 糊 糊\n\n一 平 凹 稍 平 稍\n\n一 坦 陷 凹 坦 凹\n\n一一 软粘 硬滑 软粘 硬滑 硬滑\n\n唱 ' i\n\n月\n4\n\n色泽\n\n椭\n\n敲声\n\n姬\n\n脐部\n\n恻\n\n编号\n\n一-\n\n且τA K U O O\n\n，、\n\n‘ ‘\n\n， 咱\n\nE唱 A\n\ni n\n\n唱' 4\n\n-\n\n青绿\n\n法 乌 一 乌 洗 浅 青\n\n臼 黑 一 黑 白 白 绿\n\n唱\n\na E\n\nA\n\n。 。\n\n跚 跚 棉 一\n\n一一 沉闷 油响 浊响 一一 沉闷 清脆 浊响 浊响\n\n一 制 酬 附 一\n\n一一 凹陷 凹陷 稍凹 一一 稍凹 平坦 平坦 凹陷\n\n一 蹦 蹦 酣 一\n\n是 是 是 一否否否否否肌一是是是一\n\n椭\n\n酬\n\n酣否\n\n跚 酬 酣 否 假定我们采用 4.2.1 节的信息增益准则来进行划分属性选择，则从表 4.2 的\n\n跚 酬 唰 否 训练集将会生成一棵如图 4.5 所示的决策树.为便于讨论，我们对圈中的部分 幡 酬 酣 否 结点做了编号.\n\n4.3.1 预剪枝\n\n我们先讨论预剪枝.基于信息增益准则，我们会选取属性\"脐部\"来对训 练集进行划分，并产生 3 个分支，如图 4.6 所示.然而，是否应该进行这个划分 呢?预剪枝要对划分前后的泛化性能进行估计.\n\n在划分之前，所有样例集中在根结点.若不进行划分，则根据算法 4.2 第 6 行，该结点将被标记为叶结点，其类别标记为训练样例数最多的类别，假设我们\n\n4.3 剪枝处理\n\n81\n\n凹陷\n\n图 4.5 基于农 4 . 2 生成的未剪枝决策树\n\n验证集精度\n\n+一一一一一\"脐部 =? \"划分前 42.9%\n\n划分后 7 1. 4%\n\n凹陷\n\n预剪枝决策:划分\n\n恬b\n\n验证集精度\n\"色泽 = ?\"划分前 71.4% 划分后 57.1%\n预剪枝决策·禁止划分\n\n~\n\n验证集精度\n\n\"根蒂=?\"划分前71. 4% 划分后71. 4%\n\n预剪枝决策:禁止划分\n\n图 4.6 基于农 4.2 生成的预剪枝决策树\n\n当样例最多的类不唯一\n时，可任选其中一类\n\n将这个叶结点标记为\"好瓜\"用表 4.2 的验证集对这个单结点决策树进行评 估?则编号为 {4 ， 5 ， 8} 的样例被分类正确?另外 4 个样例分类错误，于是，验证\n集精度为丰 x 100% = 42.9%\n\n在用属性\"脐部\"划分之后?图 4.6 中的结点②、③、④分别包含编 号为 {1 ， 2 ， 3 ， 14} 、 {6 ， 7 ， 15 ， 17} 、 {10 ， 16} 的训练样例，因此这 3 个结点分别 被标记为叶结点\"好瓜\"、 \"好瓜\"、 \"坏瓜\"此时，验证集中编号为\n{4 ， 5 ， 8 ，1l， 12} 的样例被分类正确，验证集精度为~ x 100% = 71.4% > 42.9%\n于是，用\"脐部\"进行划分得以确定.\n\n82\n\n第 4 章决策树\n\n然后?决策树算法应该对结点②进行划分，基于信息增益准则将挑选出划 分属性\"色泽\"然而，在使用\"色泽\"划分后?编号为 {5} 的验证集样本分类 结果会由正确转为错误，使得验证集精度下降为 57.1%. 于是，预剪枝策略将禁 止结点②被划分.\n对结点③，最优划分属性为\"根蒂\"，划分后验证集精度仍为 7 1. 4%. 这个 划分不能提升验证集精度，于是，预剪枝策略禁止结点③被划分.\n对结点④?其所含训练样例己属于同一类，不再进行划分.\n于是 7 基于预剪枝策略从表 4.2 数据所生成的决策树如图 4.6 所示，其验证 集精度为 71. 4%. 这是一棵仅有一层划分的决策树?亦称\"决策树桩\" (decision\nstump).\n对比图 4.6 和图 4.5 可看出，于预页剪枝使得决策树的很多分支都没有\"展 开 试时间开销.但另一方面，有些分支的当前划分虽不能提升泛化性能、甚至可 能导致泛化性能暂时下降?但在其基础上进行的后续划分却有可能导致性能显 著提高;预剪枝基于\"贪心\"本质禁止这些分支展开 7 给预剪枝决策树带来了 欠拟含的风险\n\n4.3.2 后剪枝\n\n后剪枝先从训练集生成一棵完整决策树?例如基于表 4.2 的数据我们得到 如图 4.5 所示的决策树.易知 7 该决策树的验证集精度为 42.9%.\n\n后剪枝首先考察图 4.5 中的结点⑥.若将其领衔的分支剪除，则相当于 把⑤替换为叶结点.替换后的叶结点包含编号为 {7 ， 15} 的训练样本，于是?该 叶结点的类别标记为\"好瓜\"，此时决策树的验证集精度提高至 57.1%. 于是， 后剪枝策略决定剪枝，如图 4.7 所示.\n\n此种情形下验证集精度 虽无提高，但根据奥卡姆 剃刀准则，剪枝后的模型 灵好因此，实际的决策树 算法在此种情形下通常要 进行剪枝本书为绘图的 方便，采取了不剪枝的保 守策咯\n\n然后考察结点⑤，若将其领衔的子树替换为叶结点，则替换后的叶结点包 含编号为 {6 ， 7， 15} 的训练样例，叶结点类别标记为\"好瓜'七此时决策树验证 集精度仍为 57.1%. 于是，可以不进行剪枝.\n对结点②，若将其领衔的子树替换为叶结点，则替换后的叶结点包含编号 为 {1 ， 2 ， 3 ， 14} 的训练样例，叶结点标记为\"好瓜\"此时决策树的验证集精度 提高至 7 1. 4%. 于是，后剪枝策略决定剪枝.\n\n对结点③和①，若将其领衔的子树替换为叶结点，则所得决策树的验证集 精度分别为 71. 4% 与 42.9% ，均未得到提高.于是它们被保留.\n\n4.4 连续与缺失值\n\n83\n\n原分支\"色泽=?\" 验证集精度\n剪枝前 57. 1% 剪枝后 7 1. 4%\n后剪枝决策:剪枝\n\n验证集精度\n\n图 4 . 7 基于表 4 . 2 生成的后剪枝决策树\n最终?基于后剪枝策略 从表 4.2 数据 所生成的决策树如图 4.7 所示，其验证 集精度 为 7 1. 4%.\n对 比图 4.7 和阁 4 . 6 可看出?后 剪枝决策 树通常比 预剪枝决策树保留 了更 多的分支 . 一般情形下?后剪枝决策树的欠拟合风险很小，泛化性 能往往优于预 剪枝决策树.但后剪枝过程是在生成完全决策树之后进行的 7 并且要白底向上 地对树中的所有非叶结点进行逐一 考察，因此其训练时间开销比未剪枝决策树 和预剪枝 决策树都要大得多.\n4 .4连续与缺失值\n4 .4 .1 连续值处理 到 目前为止我们仅讨论了基于离散居性来生成决策树. 现实 学习任务 中常\n会遇到连续属性，有 必要 讨论如何在决策树学 习中使用 连续属性 . 由于连续属性的可取值数目不再有限， 因 此，不能直接根据连续属性的 可\n取值来对结 点 进行划分 .此 时 7 连续属 性离散化技术可派上用场 . 最简单的策 略是采用 二分法 (bi-partition)对连续属性进行处理，这正 是 C4 . 5 决策树算法中\n采用的机制 [Quinlan， 1993] .\n给定样本集 D 和连续属 性 α，假定 α 在 D 上出现 了 η 个不 同 的取值，将这 些值从小到大进行排序，记为 {α1 α2 γ . . ， an }. 基于划分点 t 可将 D 分为 于集 Dt 和 Df? 其中 Dt 包含那些在属性 α 上取值不大于 t 的 样本 7 时 Df 则 包含\n那些在属 性 α 上取值大于 t 的样本.显然?对相邻 的属性取值 d 与 αi+ l 来说 ， t\n\n84\n\n第4章 决 策 树\n\n在区间[♂ ， ai+ l) 中取任意值所产生的划分结果相同.因此，对连续属性 α? 我们 可考察包含 η 1 个元素的候选划分点集合\n\n年(守主 11 … 1} ,\n\n(4.7)\n\n可将划分点设为该属性 在训练集中出现的不大 于中位点的最大值，从而 使得最终决策树使用的划 分点都在训练集中出现过\n[Quinlan , 1993].\n\n即把区间 [ai ， ai+ 1) 的中位点气出作为候选划分点然后，我们就可像离散\n属性值一样来考察这些划分点，选取最优的划分点进行样本集合的划分.例如， 可对式 (4.2)稍加改造:\nGain(D ,a) =哇哇 Gain(D ， α ， t)\n\n=豆子了 E叫D) 一\n\n三二\n\nIDλ|\n-LEnt(Df) , IDI\n\n(4.8)\n\n其中 Gain(D ， a ,t) 是样本集 D 基于划分点 t 工分后的信息增益.于是，我们就\n可选择使 Gain(D ， α ， t) 最大化的划分点.\n作为一个例子，我们在表 4.1 的西瓜数据集 2.0 上增加两个连续属性\"密 度\"和\"含糖率\"，得到表 4.3 所示的西瓜数据集 3.0. 下面我们用这个数据集 来生成一棵决策树.\n\n表 4.3 西瓜数据集 3.0\n\n色泽\n\n根蒂\n\n敲声\n\n纹理\n\n脐部\n\n刷\n\n编号 一 一\n\n一一\n\n一一\n\n一一\n\n一-\n\n触感 密度 含糖率\n\n， ‘ ‘ '咽 A\n咽' 4 4 t 4 4 t 4 唱E 4\n唱E 4 4 E A\n\n11'nutiq\"qdA且Zvhd民 234直同乌乌青浅青乌乌乌青浅浅青浅乌浅青 5绿黑黑绿白绿黑黑黑绿白白绿白黑白绿 67蜷蜷蜷蜷蜷稍稍稍一稍硬硬蜷稍稍稍蜷蜷 8缩缩缩缩缩蜷蜷蜡一蜡挺挺铺蜷蜷蜷缩缩 U\n\n浊晌\n\n沉 浊 沉 浊 浊 浊 浊\n\n闷 响 闷 响 响 响 响\n\n清晰 清晰 清晰 清晰 清晰 清晰 稍粮 清晰\n\n沉闷 ;需脆 清脆 浊晌 浊晌 沉闷 浊响 浊晌\n\n稍糊 i青晰 模粮 模糊 稍糊 稍糊 清晰 模糊\n\n凹陷 凹陷 凹陷 凹陷 凹陷 稍凹 稍凹 稍凹 一一 稍凹 平坦 平坦 平坦 凹陷 凹陷 稍凹 平汩 稍一\n凹\n\n硬滑 硬滑 硬滑 硬滑 硬滑 软粘 软粘 硬滑\n硬滑 软粘 硬滑 软粘 硬滑 硬滑 软粘 硬滑 硬滑\n\n0.697 0.774 0.634 0.608 0.556 0.403 0.481 0.437\n0.666 0.243 0.245 0.343 0.639 0.657 0.360 0.593\n\n0.460 0.376 0.264 0.318 0.215 0.237 0.149 0.211\n0.091 0.267 0.057 0.099 0.161 0.198 0.370 0.042\n\n一\n\n是\n\n是\n\n是\n\n是\n\n是 是 是\n\n否 否 否 否 否\n\n是沓\n杏\n\n否\n\n否\n\n唱E i\n\n月\n4\n\n沉闷 稍糊\n\n0.719 0.103\n\n4.4 连续与缺失值\n\n85\n对属性\"密度\"在决策树学习开始时?根结点包含的 17 个训练 样本在该属性上取值均不同.根据式 (4.7) ，该属性的候选划分点集合\n包含 16 个候选值 :T密度 {0.244 ， 0.294, 0.351 , 0.381 , 0.420, 0.459, 0.518, 0.574, 0.600, 0.621 , 0.636, 0.648, 0.661 , 0.681 , 0.708, 0.746}. 由式 (4.8) 可计算\n出属性\"密度\"的信息增益为 0.262 ，对应于划分点 0.38 1. 对属性\"含糖率\"其候选划分点集合也包含 16 个候选值:'L含糖率=\n{0.049, 0.074, 0.095, 0.101 , 0.126, 0.155, 0.179, 0.204, 0.213, 0.226, 0.250, 0.265, 0.292 , 0.344, 0.373, 0 .4 18}. 类似的，根据式 (4.8) 可计算出其信息增益为 0.349 ，\n对应于划分点 0.126. 再由 4.2.1 节可知，表 4.3 的数据上各属性的信息增益为\nGain(D ，色泽) = 0.109; Gain(D ，根蒂) = 0.143; Gain(D ，敲声) = 0.141; Gain(D ，纹理) = 0.381; Gain(D ，脐部) = 0.289; Gai丑 (D ， 触感) = 0.006; Gain(D ，密度) = 0.262; Gain(D ，含糖率) = 0.349.\n于是\"纹理\"被选作根结点划分属性?此启结点划分过程递归进行，最终 生成如图 4.8 所示的决策树.\n\n图 4.8 在西瓜数据集 3.0 上基于信息增益生成的决策树\n\n例如在父结点上使用了 \"密度 ';;;0.381\" ，不会禁 止在子结点上使用\"密\n度运 0.294\" .\n\n需注意的是，与离散属性不同，若当前结点划分属性为连续属性?该属性还 可作为其后代结点的划分属性.\n4 .4 .2 缺失值处理\n\n现实任务中常会遇到不完整样本，即样本的某些属性值缺失.例如由于诊 测成本、隐私保护等因素，患者的医疗数据在某些属性上的取值(如 HIV 测试 结果)未知;尤其是在属性数目较多的情况下，往往会有大量样本出现缺失值. 如果简单地放弃不完整样本，仅使用无缺失值的样本来进行学习，显然是对数\n\n86\n\n第4章 决 策 树\n\n据信息极大的浪费.例如，表 4 .4是表 4.1 中的西瓜数据集 2.0 出现缺失值的版\n本，如果放弃不完整样本，则仅有编号 {4， 7, 14, 16} 的 4 个样本能被使用.显\n然，有必要考虑利用有缺失属性值的训练、样例来进行学习.\n\n在决策树学习开始阶段， 根结点中各样本的权重初 始化为 1\n\n表 4.4 西瓜数据集 2.0α\n\n根蒂\n\n敲声\n\n纹理\n\n脐部\n\n触感\n\n肌\n\n编号\n\n色泽\n\n一一\n\n一一\n\n一-\n\n一一\n\n一一\n\ni q a， q d A 吐 w b t u\n月t Q O\n\n‘ 咱\n\n.,.hy n\n\nEE晶 唱 B丰 唱 『 L\n\nυ 1 1 q L q\n\n唱B i\n\nd A\n\n哇 咱\n\n牛\n\nF I\n\n唱 E A\n\nW D R\n\n咱E U\n\n-乌黑 乌黑 青绿\n青绿 乌黑 乌黑 乌黑 青绿 浅' 浅日\n' 自 浅白 乌黑 浅白\n\n蜷缩 蜷缩 蜷缩 蜷缩 蜷缩 稍蜷 稍蜷 稍蜷 -硬挺 硬挺 蜷缩 稍蜷 稍蜷 稍蜷 蜷缩\n\n浊响\n\n沉 一 沉 浊 浊 浊 浊 一 沉 清 清 浊 沉 浊 浊\n\n闷 闷 响 响 响 响 一 问 脆 脆 响 闷 响 响 闷\n\n沉\n\n青绿\n\n洁晰 清晰 清晰 清晰 清晰 清晰 稍糊\n\n稍糊\n\n-叩\n\n模糊\n\n模 稍 稍 清 模 稍\n\n糊 糊 糊 晰 糊 糊\n\n凹陷\n\n硬滑\n\n凹陷\n\n凹陷\n\n凹陷\n\n凹陷\n\n一→\n\n稍凹\n\n稍凹\n\n一 稍 平 平 平 凹 四 平 稍\n\n一 凹 坦 坦 坦 陷 陷 如\n\n一\n\n凹\n\n--\n\n硬滑\n\n硬滑\n\n硬滑\n\n软粘\n\n软粘\n\n硬 一 硬 软 软 硬 硬 软 硬 硬\n\n滑 一 滑 粘 粘 滑 滑 粘 滑 滑\n\n4\n\n1 E L\n\n用\n4\n\n一 是 是 是 是 是 是 是 是 一 否 否\n\n否\n\n沓 我们需解决两个问题: (1) 如何在属性值缺失的情况 F进行划分属性选择?\n\n否 (2) 给定划分属性?若样本在该属性上的值缺失，如何对样本进行划分?\n\n否 给定训练集 D 和属性 α，令 D 表示 D 中在属性 α 上没有缺失值的样本子 否 集.对问题 (1) ，显然我们仅可根据 b 来判断属性 α 的优劣.假定属性 α 有 V 个\n\n否 可取值 {α1 ， α2 …， αV} ， 令 DV 表示 D 中在属性 α 上取值为旷的样本子集 ， ÌJk\n\n否 表示 b 中属于第 k 类 (k = 1, 2, .. . , ly l)的样本子集，则显然有b 己 U巳1 ÌJk ,\n\nbzUL1bu. 假定我们为每个样本 z 贼予→个权重切酌并定义\n\nLZLEL-L ρ 一\n\nr k\n\n一\n\n=\n\n~p = f\n\nD 乌DN-\n\n问-\nw-比\n\nJ N F -\n\nu ω u一\n\n(1 ~ k ~ IYI) ,\n(1 ~ v ~ V) .\n\nJ\n\n(4.9) (4.10) (4.11)\n\n4.4 连续与缺失值\n\n87\n\n直观地看，对属性 α， ρ 表辰无缺失值样本所占的比例 ， Pk 表示无缺失值样本中 第 k 类所占的比例 ?ι 则表示无缺失值样本中在属性 α 上取值旷的样本所占\n的比例显然，艺已l 肌 =LZL1 札 =1\n基于上述定义，我们可将信息增益的计算式 (4.2) 推广为\n\nGain(D,a) = p x Gain(D,a)\n\nJ\n\n一 一\n\nρ\n\n×\n\nf\n\nt\n\nt\n\nt I\n\n飞 \\\n\nEn / 4Lt ， l飞 \\\n\n~\n\nD 、\n、\n\nE\n\nE\n\n，\n\n/\n\nV\n\n\\tll1/\n\nZ叫\n\nN F\n\n忖\n\nEn J\n\n4tu\n\nf t\n\nl飞\n\n、\n\nND 、\n\n们U\n\n、1 l\n\ng\n\n'\n\n'\n\n'\n\n'\n\n其中由式 (4.1) ，有\n\nIYI\nEnt(15) = - 2二岛 10g2 岛\n\n4 -i9\"、· l J\n\n对问题 (2) ，若样本 z 在划分属性 α 上的取值己知?则将 z 划入与其取值对 应的子结点，且样本权值在于结点中保持为 ωæ. 若样本 z 在划分属性 α 上的取 值未知，则将 z 同时划入所有子结点?且样本权值在与属性值 t 对应的子结点 中调整为凡 -ωæ ，直观地看，这就是让同一个样本以不同的概率划入到不同的 子结点中去.\nC4.5 算法使用了上述解决方案 [Quin1an， 1993J. 下面我们以表 4 .4的数据 集为例来生成一棵决策树.\n在学习开始时?根结点包含样本集 D 中全部 17 个样例，各样例的权值 均为1.以属性\"色泽\"为例，该属性上无缺失值的样例子集 b 包含编号为\n{2 ， 3 ， 4 ， 6 ， 7 ， 8 ， 9 ， 10， 11 ， 12 ， 14， 15 ， 16， 17} 的 14 个样例.显然 ， 15 的信息:腐为\nEnt(15) = - LPk 10g2 民\n\n= -\n\nI飞 (-6::-:口 .10酌 \"16+ 4 .\n\n-:8:-:.10区。\n14 口'\"\n\n8 14\n\n\\ J I\n\n=\n\n0.985.\n\n令 b1?b2 与 153 分别表不在属性\"色泽\"上取值为\"青绿 \" ((乌黑\"以 及\"浅白\"的样本子集，有\n\nE ME NM D) ND) / ， ， 、\n\n1\n儿 。 \"\n\n，\n\n，\n\n.•\n\n一 一 一 一\n\n一 一\n\n/ t l t飞 \\\n\n叮 ， \" 一A哇\n\n/\n\n' -『\n\nA哇 -\n\n飞\n\n1、 、\n\na u\n\n- o- o uqa b\"T4。 u+十 b2-42 A\n\n哇\n\n。 \"\n\n二 。\n\n玄 。\n\n2 \\11FE/\\11/\n\n- o- o Fq D 4 -42 F qb L --\n\n1n in unu u u 03 -n\n\n一\n\nδ\n\n一\n\n玄 。\n\n88\n\n第 4 章决策树\n\nEnt(的= - (~叫 +j 叫) =0ω\n\n因此，样本于集 β 上属性\"色泽\"的信息增益为\n\nGain(D ，色泽) = Ent(D) 一 2二 ιEnt(DV )\n。 =1\n\n于是，样本集 D 上属性\"色泽\"的信息增益为\nGain(D ，色泽)=ρx Gain(D ，色泽)=1一4 x 0.306 = 0.252 . 17\n类似地可计算出所有属性在 D 上的信息增益:\nGain(D ，色泽) = 0.252; Gain(D ，根蒂) = 0.171; Gain(D ，敲声) = 0.145; Gain(D ，纹理) = 0.424; Gain(D ，脐部) = 0.289; Gain(D ，触感) = 0.006.\n\"纹理\"在所有属性中取得了最大的倍息增益，被用于对根结点进行划分. 划分结果是使编号为 {1 ， 2 ， 3 ， 4 ， 5 ， 6 ， 15} 的样本进入\"纹理=清晰\"分支，编号\n为 {7 ， 9, 13, 14, 17} 的样本边入\"统理=稍糊\"分支，而编号为 {11 ， 12, 16} 的样\n本进入\"纹理二模糊\"分支，且样本在各子结点中的权重保持为1.需注意的 是，编号为 {8} 的样本在属性\"纹理\"上出现了缺失值，因此它将同时进入三 个分支中，但权重在三个子结点中分别调整为主、圭和 it. 编号为 {10} 的样 本有类似划分结果.\n上述结点划分过程递归执行，最终生成的决策树如图 4.9 所示.\n4.5 多变量决策树\n若我们把每个属性视为坐标空间中的一个坐标轴，则 d 个属性描述的样本 就对应了 d 维空间中的一个数据点，对样本分类则意味着在这个坐标空间中寻 找不同类样本之间的分类边界.决策树所形成的分类边界有一个明显的特点: 轴平行 (axis-parallel) ，即它的分类边界由若干个与坐标轴平行的分段组成.\n\n4.5 多变量决策树\n\n89\n\n图 4.9 在西瓜数据集 2.0α 上基于信息增益生成的决策树\n以表 4.5 中的西瓜数据 3.0α 为例 7 将它作为训练集可学得图 4.10 所示的决 策树，这棵树所对应的分类边界如图 4.11 所示.\n\n西瓜数据集 3.00<是由 表 4.3 的西瓜数据集 3.0 忽 略离散属性而得\n\n刷 表 4.5 西瓜数据集 3.0α\n\n编号\n1\n\n密度\n\n含糖率\n\n一\n\n4 9\n\n0.697 0.460\n\n\" q d\n\n0.774 0.376\n\n是\n\nA\n\n0.634 0.264\n\n哇\n\n0.608 0.318\n\nw\n\nb\n\n0.556 0.215\n\n民\n\n是 是\n\nV\n\n0.403 0.237\n\ni同 R\n\n0.481 0.149\n\n是\n\nU\n0.437 0.211\n\n,.•、， 。\n\n0.666\n\n0.091\n\n叮E 4 4 t 4\n\nu t i q G\n\n0.243 0.245\n\n0.267 0.057\n\n唱 EE盛 唱\n\nq U A\n\n0.343 0.099\n\nB\n\n-\n\n寸\n\na t\n\n4\n\n吐\n\n1 E A\n\nv b\n\n-n\n\n0.639 0.657 0.360\n\n0.161 0.198 0.370\n\n是 是 是 是 一\n\nE E A 1\n\nh v 同\n\n0.593 0.042\n\nEi A\n\n0.719 0.103\n\n否 否\n\n否\n\n否 显然，分类边界的每一段都是与坐标轴平行的这样的分类边界使得学习\n\n否 结果有较好的可解释性，因为每一段划分都直接对应了某个属性取值.但在学\n\n否 习任务的真实分类边界比较复杂时，必须使用很多段划分才能获得较好的近似，\n\n否\n\n90\n\n第 4 章决策树\n\n回 4.10 在西瓜数据集 3‘0α 上生成的决策树\n\n06EZE\n\n特 袋。 .4 φ\no. 2\n\n+ + +\n+\n\no O. 2 O. 4 O. 6 O. 8\n密度\n圄 4.11 图 4.10 决策树对应的分类边界\n\n如图 4.12 所示;此时的决策树会相当复杂，由于要进行大量的属性测试，预测 时间开销会很大.\n\n这样的多变量决策树亦 称\"斜决策树\" (oblique\ndecision tree).\n\n若能使用斜的划分边界，如图 4.12 中红色线段所示，则决策树模型将大为\n简化\"多变量决策树\" (multivariate decision tree) 就是能实现这样的\"斜划\n分\"甚至更复杂划分的决策树.以实现斜划分的多变量决策树为例，在此类决 策树中，非叶结点不再是仅对某个属性，而是对属性的线性组合进行测试;换言\n之，每个非叶结点是一个形如 2乙1 叫向 =t 的线性分类器，其中叫是属性向\n的权重，叫和 t 可在该结点所含的样本集和属性集上学得.于是，与传统的\"单\n变量决策树\" (univariate decision tree) 不同，在多变量决策树的学习过程中，\n不是为每个非叶结点寻找一个最优划分属性，而是试图建立一个合适的线性分\n\n4.5 多变量决策树\n\n91\n\nU\n\n。\n\nZ\n\n图 4.12 决策树对复杂分类边界的分段近似\n\n线性分类器参见第 3 幸 类器.例如对西瓜数据 3.0α? 我们可学得图 4. 13 这样的 多变量决策树，其分类\n边 界如 国 4.14 所示\n\n是\n正二\n一0.365 x 密度 + 0.366 x 含糖率 :::; -0.1 58?\n\n/\n\n'-....\n\n是\n\n~\n\n图 4. 13 在 西瓜数据集 3 .0α 上生成的多交量决策树\n\n-\n\n+\n\n-\n\nE「\n\n一\n\n好一 一瓜 坏瓜 一一\n\n叶\n\n+\n\n枣。 4\n\n叶也\n\nO. 2\n\no 0.2 O. 4 O. 6 0.8\n密度\n图 4.14 图 4 . 13 多交量决 策树对应的分类边界\n\n92\n\n第 4 章决策树\n\n4.6 阅读材料\n\n决策树学习算法最著名的代表是 ID3 [Quinlan, 1979, 1986] 、 C4.5 [Quinla丑， 1993] 和 CART [Breiman et al., 1984]. [Murthy, 1998] 提供了一个关于决\n策树文献的阅读指南. C4.5Rule 是→个将 C4.5 决策树转化为符号规则的算法\n[Quinlan, 1993] ，决策树的每个分支可以容易地重写为一条规则，但 C4.5Rule\n算法在转化过程中会进行规则前件合并、删减等操作?因此最终规则集的泛化 性能甚至可能优于原决策树.\n\n本质上，各种特征选择 方法均可用于决策树的划 分属性选择特征选择参 见第 11 章\n\n在信息增益、增益率、基尼指数之外，人们还设计了许多其他的准则用 于决策树划分选择，然而有实验研究表明 [Mingers ， 1989b]，这些准则虽然对\n决策树的尺寸有较大影响，但对泛化性能的影响很有限. [Raileanu and Stoffel,\n2004] 对信息增益和基尼指数进行的理论分析也显示出，它们仅在 2% 的情况下 会有所不同. 4.3 节介绍了决策树剪枝的基本策略;剪枝方法和程度对决策树泛 化性能的影响相当显著，有实验研究表明 [Minger日， 1989a]，在数据带有噪声时 通过剪枝甚至可将决策树的泛化性能提高 25%.\n\n关于感知机和神经网络，\n参几第 5 章\n\n多变量决策树算法主要有 OC1 [Murthy et al., 1994] 和 [Brodley and Utgoff, 1995] 提出的一系列算法 .OC1 先贪心地寻找每个属性的最优权值，在局 部优化的基础上再对分类边界进行随机扰动以试图找到更好的边界; [Brodley and Utgoff, 1995] 则直接引入了线性分类器学习的最小二乘法，还有一些算法\n试图在决策树的叶结点上嵌入神经网络，以结合这两种学习机制的优势，例如\n\"感知机树\" (Perceptron tree) [Utgoff, 1989b] 在决策树的每个叶结点上训练 一个感知机，而 [Guo and Gelfand, 1992] 则直接在叶结点上嵌入多层神经网络.\n有→些决策树学习算法可进行\"增量学习\" (incrementallearning) ，即在 接收到新样本后可对己学得的模型进行调整，而不用完全重新学习.主要机 制是通过调整分支路径上的划分属性次序来对树进行部分重构，代表性算法\n有 ID4 [Schlimmer and Fisher, 1986] 、 ID5R [Utgoff, 1989a] 、 ITI [Utgoff et al.,\n1997] 等.增量学习可有效地降低每次接收到新样本后的训练时间开销，但多步 增量学习后的模型会与基于全部数据训练而得的模型有较大差别.\n\n习题\n\n93\n\n习题\n4.1 试证明对于不含冲突数据(即特征向量完全相同但标记不同)的训练\n集，必存在与训练集一致(即训练误差为 0) 的决策树.\n4.2 试析使用\"最小训练误差\"作为决策树划分选择准则的缺陷\n\n4.3 试编程实现基于信息;嘀进行划分选择的决策树算法?并为表 4.3 中数\n据生成一棵决策树.\n\n4.4 试编程实现基于基尼指数进行划分选择的决策树算法，为表 4.2 中数\n据生成预剪枝、后剪枝决策树?并与未剪枝决策树进行比较.\n\n4.5\nUCI 数据集见\nhttp://archive.ics.uci.edu/mlj. 4.6\n统计显著性检验参见 2 .4节.\n4.7\n\n试编程实现基于对率回归进行划分选择的决策树算法?并为表 4.3 中 数据生成一棵决策树.\n试选择 4 个 UCI 数据集，对上述 3 种算法所产生的未剪枝、预剪枝、 后剪枝决策树进行实验比较，并进行适当的统计显著性检验.\n图 4.2 是→个递归算法，若面临巨量数据，则决策树的层数会很深，使 用道归方法易导致\"樵\"溢出试使用\"队列\"数据结构，以参数 MaxDepth 控制树的最大深度，写出与图 4.2 等价、但不使用递归的 决策树生成算法.\n\n4.8*\n\n试将决策树生成的深度优先搜索过程修改为广度优先搜索，以参数 MαxNode 控制树的最大结点数，将题 4.7 中基于队列的决策树算法 进行改写.对比题 4.7 中的算法，试析哪种方式更易于控制决策树所 需存储不超出内存.\n\n4.9 试将 4.4.2 节对缺失值的处理机制推广到基尼指数的计算中去.\n\n西瓜数据集 3.0 见 p.84 的表 4.3\n\n4.10\n\n从网上下载或自己编程实现任意一种多变量决策树算法，并观察其在 西瓜数据集 3.0 上产生的结果.\n\n94 参考文献\n\n第 4 章决策树\n\nBreiman, L. , J. Friedman, C. J. Sto肘， and R. A. Olshen. (1984). Classificαtion\nαnd Regression 野ees. Chapman & Hall/CRC, Boca Raton, FL.\nBrodley, C. E. and P. E. Utgoff. (1995). \"Multivariate decision trees.\" Machine\nLearning, 19(1):45-77. Guo, H. and S. B. Gelfand. (1992). \"Cl即日i直cation trees with ncural network\nfeature extraction.\" IEEE Transαctions on Neural Networks, 3(6):923-933 Mingers, J. (1989a). \"An empirical comparison of pruning mcthods for decision\ntree induction.\" Mαchine Learning, 4(2):227-243. Mingers, J. (1989b). \"An empirical comparison of selection measures for\ndecision-tree induction.\" Mαchine Learning, 3(4):319-342. Murthy, S. K. (1998). \"Automatic construction of decision trees from data:\nA ml山i-disciplinary survey.\" Dαtα Mining and K n01帅dge Díscove叩， 2(4): 345-389. Murthy, S. 丘， S. Kasif, and S. Salzberg. (1994). 吐 system for induction of oblique decision trees.\" Jo'urnal of Artíficial Intelligence Reseαrch， 2:1-32. Ql山巾n， J. R. (1979). \"D旭covering rules by induction 仕om large collections of examples.\" 1n Expert Sυstems 肌 the M布icro-el臼 ect衍r的佣 oT旧ηú化c Ag庐巳 (D. 卫M仕 I 168一201 ，巳dinburgh University Press, Edinburgh, UK. Quinlan, J. R. (1986). \"1nduction of decision trees.\" Machine Learni叼， 1(1): 81-106.\nQuinlan, J. R. (1993). C4.5: Programs for Machine Learning. Morgan Kaufmann, San Mateo, CA.\nRaileanu, L. E. a时K. Stoffel. (2004). \"Theoretical comparison between the\nGini index and information gain criteria.\" Annαls of Mathemαtics αnd ArtificialIntelligence, 41(1):77-93.\nSchlimm凹， J. C. and D. Fisher. (1986). 咀 case study of incremental concept induction.\" 1n Proceedings of the 5th Nα， tionαl Conference on Artificial In-\ntelligence (AAAI) , 495-501 , Philadelpl血， PA Utgoff, P. E. (1989a). \"1ncremental induction of decision trees.\" Machíne\nLearning, 4(2):161-186.\n\n休息一会儿\n\n95\nUtgo旺， P. E. (1989b). \"Perceptron tre臼: A case study in hybrid concept rep-\nresenations.\" Connection Science, 1(4):377-391.\nUtgoff, P. E., N. C. Berkman, and J. A. Clouse. (1997). \"Decision t ree induction\nbased on effcient tree restruct盯ing.\" Machine Learning, 29(1 ):5-44.\n\n休息一会儿\n\n小故事:决策树与罗斯·昆兰\n\n说起决策树学习，就必然要谈到澳大利亚计算机科学家\n罗斯·昆兰 (J. Ross Quinlan, 1943- ).\n\n最初的决策树算法是心理学家兼计算机科学家E. B. Hunt 1962 年在研究人类的概念学习过程时提出的 CLS (Concept Learning S)耐em) ，这个算法确立了决策树 \"分而\n治之\"的学习策略.罗 斯 ·昆兰在 Hunt 的指导 下于 1968 年在美国华 盛顿 大学 获得计算机博士学位，然后到悉尼大学任教. 1978 年他在学术假 时 到斯坦福大 学访 问 ，选修了图灵的助手 D. Michie 开 设的 一门研究生 课程.课 上有一个 大 作业，要求写程序来学习出完备正确的规则，以判断国际象棋残局中一方是否 会在两步棋后被将死. 昆 兰写了一个类似于 CLS 的程序来完成 作业， 其中最重 要的改进是引入了信息增益准则.后来他把这个工作整理出来在 1979 年发表， 这就是 ID3 算法.\n\nC4.0 走 Classifier 4.0 的 简称\nC4.5 在 WEKA 中的实 现称为 J4.8\n\n1986 年 Machine Learning 杂志创 刊，昆兰 应邀在创刊号上重新发表了 ID3\n算沽，掀起了决策树研究的热潮 . 短短几年间众多决策树算法问世， ID4、 ID5 等名字迅速被其他研究者提出的算法占用， 昆 兰只好将自 己的 ID3 后继 算法命 名为 C4.0 ，在此基础上进一步提出了著名 的 C4.5. 有趣的是 ，昆兰 自称 C4.5 仅 是对 C4.0 做了些小改进，因 ↓此也将它命名为 \"第 4.5 代分类器 业化版本衬称、为 C5.0.\n\n第 5 章 神经网络\n\n5.1 神经元模型\n\n本书所谈的 是\"人工神 经 网 络\"不是生物学意 义上的神经网络\n这是 T . Kohonen 1988 年在 Neura l Networks 创刊 号 上给出的定义，\n\n神经 网络 (neural networks) 方面 的研究很早就 已 出 现 ? 今天\" 神经 网络\" 己是一个相当大的 、 多学科交叉的 学科领域.各相关学科对神经网络 的定 义多 种多样，本书采用目前使用得最广泛的 一种 ，即\"神 经网络是由具有适应 性的 简单单元组成的广泛并行互连的网络，它的组织能够模拟生物 神经系统对真实\n世界物体所作出的交互反应 \" [Kohonen, 1 988] . 我们在机器学习 中谈论神经网\n络时指 的是\"神经网 络学 习 \" 或者说，是机器学习 与神经网络这两个学科领 域的交叉部分 .\n\nn euron 亦 称 unit\n亦称 bias 注意不是 \"阀值>>虽然其含义的 确类似于 \"阀 门\"\n\n神经网络中最基本的成分是神经元 (neuro且)模型 ，即上述定义中的\" 简单 单元\"在生物神经网络中 1 每个神经元与其他神经元相连，当它\"兴奋\"时， 就会 向 相连的神经元发送化学物质 ，从而改变这些神 经元 内的电位;如果某神 经元的电位超过了 一个\"阔值\" (threshold) ， 那么它就会被激活 ? 即 \"兴奋 \" 起来，向其他神经元发送化学物质.\n\n1943 年， [McCulloch and Pitts, 1943] 将上述情形抽象为国 5 .1 所示 的简单\n模型，这就是 一 直沿用至 今 的 \"M-P 神 经元模 型 \" 在 这个模型 中 ， 神 经元接 收到来自 η 个其他神 经元传递过来的 输入信号 ?这些输入信号通过带权重 的连 接( connection) 进行传 递，神经 元 接收 到的总输入值将与 神经元 的阀值进行比\n\n广+ 当前神经元\n/ 广 输出俨 f(主ω ~ ø)\nU\n\n图 5 .1 M-P 神经元模型\n\n98\n\n第 5 章神经网络\n\n亦称\"Il'l句应函数\"\n\n较，然后通过\"激活函数\" (activation function) 处理以产生神经元 的输出.\n\n这里的阶跃函数是单位\n阶跃函数的变体1 对数几\n率函数则是 Sigmoid 函数\n的典型代表参见 3 .3 节\n\n理想中的激活函数是图 5 .2(a) 所示 的阶跃 函数，它将输入值映射为输出\n值 \"0\" 或勺\"显然 \"1\" 对应于神经元兴奋 ， \"0\" 对应于神 经元抑制 . 然\n3\n而，阶跃函数具有不连 续 、不光滑等不太 好的 性质，因 此实际常 用 Sigmoid\n函数作为激活函数典型的 Sigmoid 函数如 图 5.2(b) 所 示? 它把可能在 较大\n\n范围内变化的输入值挤压到 (0 ， 1) 输出值 范围 内，因此有 时也称为 \"挤 压函 数\" (squashi吨 functio叫.\n\n耶(X)\n\n…一一一- 1.0l~~~芒Ti--…\n\nA\n\nυ\n\n'\n\ncdσ b\n\n、ι\n\nZ) 一一\n\nr E E 4\n\ni n u\n\n1 l\n\n、\n\n1 x\n二E 二~ 0; x< O\n\n(a) 阶跃函数\n\n-1.0 -0.5 10 0.5 1.0 :Í;\n吨rnoid(x) = 一土l十e\n(b) Sigrnoid 函数\n\n图 5.2 典型的 神经元激活函数\n\n\"模拟生 物神经网络\" 是认知科学家对神 经 网络 所做的一个类 比阐 释\n例如 10 个神经元两两 连接，则有 100 个参数 90\n个连接权和 10 个阅值\n\n把许多个这样的神经元按-定的层次 结构连接起来，就得到了 神经网 络 .\n事实上，从计算机科学的角度看，我们可以先不考虑神经网络是否真的模 拟了生物神经网络，只 需将一个神经 网络视为包含了许多参数的数学模型 ，这 个模型是若干个函数， 例如的 = f(艺也叫叫 一 句)相互(嵌套)代入而得.有效的 神经网络学习算法大 多以数学证明为支撑 .\n\n5 . 2 感知机与多层网络\n感知 机 (Perceptron) 由两层 神经元 组成， 如图 5.3 所示，输入层接收外 界输 入信号后传递给输出层， 输出 层是 M-P 神 经元，亦称\"阔值逻辑单\n元\" (threshold logic unit) . 感知机能容易地实现逻辑与、或、非运算 . 注意到 ν = fCI:'i WiXi - e) ， 假\n定 f 是图 5.2 中的阶跃函数， 有\n^ e • \"与 \" (Xl X2) : 令 Wl=ω2 = 1, = 2， 则 ν = f(l . Xl + 1 . X2 - 2) ，仅\n\n5.2 感知机与多层网络\n\n99\n\n'Wl /\n\n\\'W2\n\n输出层\n\n输入层\n\nXl\n\nX2\n\n圈 5.3 两个输入神经元的感知机网络结构示意图\n\n在 Xl = X2 = 1 时 ， y = 1;\ne • \"或 \" (X1 V X2): 令 ω1= 叫= 1, = 0.5 ，则 ν = f(l . Xl 十 1. X2 - 0.5) ,\n当 X1 = 1 或 X2 = 1 时 ， y = 1;\ne + • \"非 \" (-'Xl): 令 ω1 = -0.6 ， ω2 = 0, = -0.5 ，则 ν = f( -0.6. Xl O.\nX2 +0. 时，当 Xl = 1 时 ， y =0; 当 Xl = 0 时 ， y = 1.\n\nXi 是 z 对应于第 2 个输\n入神经元的分量\n\n更一般地，给定训练数据集?权重叫。 =1 ， 2 ，...， n) 以及阔值。可通过学\n习得到.阑值。可看作一个固定输入为 1. 0 的\"哑结点\" (dummy node) 所对 应的连接权重 Wn十 1 ，这样，权重和阑值的学习就可统一为权重的学习.感知机\n学习规则非常简单，对训练样例忡 ， y) ， 若当前感知机的输出为 fj ， 则感知机权 重将这样调整:\n\nWi ← ωz 十 6Wi ，\n\n(5.1)\n\nA叫 =η(ν - ý)Xi ,\n\n(5.2)\n\n数可22;1直为一个小正其中刊仰，刊为学习率(learning rate) 从式 (5.1) 可看出，若刷刷训练\n样例 (x ， y) 预测正确，即 fj = y ， 则感知机不发生变化，否则将根据错误的程度\n进行权重调整.\n\n\"非线性可分\"意味着\n用线性起平面无法划分\n\n需注意的是，感知机只有输出层神经元进行激活函数处理，即只拥有 层 功能神经元 (functionalneuron) ，其学习能力非常有限.事实上，上述与、或、\n非问题都是线性可分(linearly separable) 的问题.可以证明 [Minsky and Papert ,\n1969]，若两类模式是线性可分的，即存在一个线性超平面能将它们分开，如图 5 叫a)-(c) 所示，则感知在fl 的学习过程一定会收敛 (converge) 而求得适当的权向\n量 ω = (W1; 叫;... ;Wn+1); 否则感知机学习过程将会发生振蔼 (fluctuation) ， ω 难以稳定下来，不能求得合适解，例如感知机甚至不能解决如图 5 剧 d) 所示的\n异或这样简单的非线性可分问题.\n\n100\n\n第 5 章 神经 网络\n\nX 2 广一步划分起平函，右 边为\n\nX2\n\n\"+\" ，左边为 \"\n\nγL.....， (1 , 1)\n\n(0, 1)\n\ni+\n\n..., (1,1)\n\n(AU nU)\n\n(1,0) Xl\n\n(功 \"与\" 问题 (Xl 八 X2)\nr_\"_\"F 少划分趋平1日，右边为 , i< ;H \"+\n\n-+\n0\n\n..\n,XXl\n\n(。 1γ 问题(，叫 )\n\n(0,0)\n\n(1,0) X l\n\n(阶 \"或\"问题(叫 V X2)\n\n(0, 0)\n\n(1,0) xl\n\n(d) \"异旷问 题 (Xl E9句)\n\n图 5 .4 线性可分的 \"与 \" \"或\" \"非\"问题与 非线性可分的\"异或\" 问 题\n\n要 解 决非线性可分问题?需 考虑 位 m 多 层 功 能神 经元. 例如 | 国 5.5 中这个 简 单 的 两层感知机就能解决异或 问题. {c!引 5.5 ( a) 中 ， 输出 层与输入居之 间 的 一 层神经元 ，被称为 隐居或隐含层 (hidden layer) ，隐含层 和 输出层神经元都是拥 有激活函数 的功 能神经元.\n史一般的，常见的神 经网 络是形如 图 5 .6 所示的层级结构，每层神经元与下 层 神 经元全互连 3 神 经元之 间不存在同 层连接， 也不存在跨层连接. 这样 的\n神 经网络结构通常称为\" 多 层前馈神经网 络 \" (multi-layer feedforward neural\n\n阂 f直0. 5\n1\n\nXl\n\nX2\n\n(a) 网 f各结构\n\n( ) nu 1i,\n\n‘\n\n.(1, 1)\n\n内Ur\n' tz 、\n\n白U 、 、 h ， t'\n\n、\n\nXl\n\n图 5.5 能解决异或问 题的两 层感知机\n\n"}