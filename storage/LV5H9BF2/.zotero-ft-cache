Theoretical Neuroscience

Computational Neuroscience
Terrence J. Sejnowski and Tomaso Poggio, editors
Neural Nets in Electric Fish, Walter Heiligenberg, 1991.
The Computational Brain, Patricia S. Churchland and Terrence J. Sejnowski, 1992
Dynamic Biological Networks: The Stomatogastric Nervous System, edited by Ronald M. Harris-Warrick, Eve Marder, Allen I. Selverston, and Maurice Moulins, 1992
The Neurobiology of Neural Networks, edited by Daniel Gardner, 1993
Large-Scale Neuronal Theories of the Brain, edited by Christof Koch and Joel L. Davis, 1994
The Theoretical Foundations of Dendritic Function: Selected Papers of Wilfrid Rall with Commentaries, edited by Idan Segev, John Rinzel, and Gordon M. Shepherd, 1995
Models of Information Processing in the Basal Ganglia, edited by James C. Houk, Joel L. Davis, and David G. Beiser, 1995
Spikes: Exploring the Neural Code, Fred Rieke, David Warland, Rob de Ruyter van Steveninck, and William Bialek, 1997
Neurons, Networks, and Motor Behavior, edited by Paul S.G. Stein, Sten Grillner, Allen I. Selverston, and Douglas G. Stuart, 1997
Methods in Neuronal Modeling: From Ions to Networks, second edition, edited by Christof Koch and Idan Segev, 1998
Fundamentals of Neural Network Modeling: Neuropsychology and Cognitive Neuroscience, edited by Randolph W. Parks, Daniel S. Levine, and Debra L. Long, 1998
Neural Codes and Distributed Representations: Foundations of Neural Computation, edited by Laurence Abbott and Terrence J. Sejnowski, 1998
Unsupervised Learning: Foundations of Neural Computation, edited by Geoffrey Hinton and Terrence J. Sejnowski, 1998
Fast Oscillations in Cortical Circuits, Roger D. Traub, John G.R. Jeffreys, and Miles A. Whittington, 1999
Computational Vision: Information Processing in Perception and Visual Behavior, Hanspeter A. Mallot, 2000
Theoretical Neuroscience: Computational and Mathematical Modeling of Neural Systems, Peter Dayan and L.F. Abbott, 2001

Theoretical Neuroscience
Computational and Mathematical Modeling of Neural Systems Peter Dayan and L.F. Abbott
The MIT Press Cambridge, Massachusetts London, England

First MIT Press paperback edition, 2005 c 2001 Massachusetts Institute of Technology All rights reserved. No part of this book may be reproduced in any form by any electronic or mechanical means (including photocopying, recording, or information storage and retrieval) without permission in writing from the publisher.

MIT Press books may be purchased at special quantity discounts for business or sales promotional use. For information, please email special sales@mitpress.mit.edu or write to Special Sales Department, The MIT Press, 55 Hayward Street, Cambridge, MA 02142.

Typeset in Palatino by the authors using LATEX 2ε. Printed and bound in the United States of America.

Library of Congress Cataloging-in-Publication Data

Dayan, Peter.
Theoretical neuroscience : computational and mathematical modeling of neural systems / Peter Dayan and L.F. Abbott.
p. cm. – (Computational neuroscience) Includes bibliographical references. ISBN 0-262-04199-5 (hc. : alk. paper) — 0-262-54185-8 (pb.) 1. Neural networks (Neurobiology) – Computer simulation. 2. Human information processing – Computer simulation. 3. Computational neuroscience. I. Abbott, L.F. II. Title. III. Series

QP363.3 .D39 2001 573.8’01’13- -dc21

2001044005

10 9 8 7 6 5 4

To our families

Contents

Preface

xiii

I Neural Encoding and Decoding

1

1 Neural Encoding I: Firing Rates and Spike Statistics

3

1.1 Introduction

3

1.2 Spike Trains and Firing Rates

8

1.3 What Makes a Neuron Fire?

17

1.4 Spike-Train Statistics

24

1.5 The Neural Code

34

1.6 Chapter Summary

39

1.7 Appendices

40

1.8 Annotated Bibliography

43

2 Neural Encoding II: Reverse Correlation and Visual Receptive

Fields

45

2.1 Introduction

45

2.2 Estimating Firing Rates

45

2.3 Introduction to the Early Visual System

51

2.4 Reverse-Correlation Methods: Simple Cells

60

2.5 Static Nonlinearities: Complex Cells

74

2.6 Receptive Fields in the Retina and LGN

77

2.7 Constructing V1 Receptive Fields

79

2.8 Chapter Summary

81

2.9 Appendices

81

2.10 Annotated Bibliography

84

3 Neural Decoding

87

3.1 Encoding and Decoding

87

3.2 Discrimination

89

3.3 Population Decoding

97

3.4 Spike-Train Decoding

113

3.5 Chapter Summary

118

viii

3.6 Appendices

119

3.7 Annotated Bibliography

122

4 Information Theory

123

4.1 Entropy and Mutual Information

123

4.2 Information and Entropy Maximization

130

4.3 Entropy and Information for Spike Trains

145

4.4 Chapter Summary

149

4.5 Appendix

150

4.6 Annotated Bibliography

150

II Neurons and Neural Circuits

151

5 Model Neurons I: Neuroelectronics

153

5.1 Introduction

153

5.2 Electrical Properties of Neurons

153

5.3 Single-Compartment Models

161

5.4 Integrate-and-Fire Models

162

5.5 Voltage-Dependent Conductances

166

5.6 The Hodgkin-Huxley Model

173

5.7 Modeling Channels

175

5.8 Synaptic Conductances

178

5.9 Synapses on Integrate-and-Fire Neurons

188

5.10 Chapter Summary

191

5.11 Appendices

191

5.12 Annotated Bibliography

193

6 Model Neurons II: Conductances and Morphology

195

6.1 Levels of Neuron Modeling

195

6.2 Conductance-Based Models

195

6.3 The Cable Equation

203

6.4 Multi-compartment Models

217

6.5 Chapter Summary

224

6.6 Appendices

224

6.7 Annotated Bibliography

228

7 Network Models

229

7.1 Introduction

229

7.2 Firing-Rate Models

231

7.3 Feedforward Networks

241

ix

7.4 Recurrent Networks

244

7.5 Excitatory-Inhibitory Networks

265

7.6 Stochastic Networks

273

7.7 Chapter Summary

276

7.8 Appendix

276

7.9 Annotated Bibliography

277

III Adaptation and Learning

279

8 Plasticity and Learning

281

8.1 Introduction

281

8.2 Synaptic Plasticity Rules

284

8.3 Unsupervised Learning

293

8.4 Supervised Learning

313

8.5 Chapter Summary

326

8.6 Appendix

327

8.7 Annotated Bibliography

328

9 Classical Conditioning and Reinforcement Learning

331

9.1 Introduction

331

9.2 Classical Conditioning

332

9.3 Static Action Choice

340

9.4 Sequential Action Choice

346

9.5 Chapter Summary

354

9.6 Appendix

355

9.7 Annotated Bibliography

357

10 Representational Learning

359

10.1 Introduction

359

10.2 Density Estimation

368

10.3 Causal Models for Density Estimation

373

10.4 Discussion

389

10.5 Chapter Summary

394

10.6 Appendix

395

10.7 Annotated Bibliography

396

Mathematical Appendix

399

A.1 Linear Algebra

399

A.2 Finding Extrema and Lagrange Multipliers

408

A.3 Differential Equations

410

x

A.4 Electrical Circuits

413

A.5 Probability Theory

415

A.6 Annotated Bibliography

418

References

419

Index

439

Exercises

http://mitpress.mit.edu/dayan-abbott

Series Foreword
Computational neuroscience is an approach to understanding the information content of neural signals by modeling the nervous system at many different structural scales, including the biophysical, the circuit, and the systems levels. Computer simulations of neurons and neural networks are complementary to traditional techniques in neuroscience. This book series welcomes contributions that link theoretical studies with experimental approaches to understanding information processing in the nervous system. Areas and topics of particular interest include biophysical mechanisms for computation in neurons, computer simulations of neural circuits, models of learning, representation of sensory information in neural networks, systems models of sensory-motor integration, and computational analysis of problems in biological sensing, motor control, and perception.
Terrence J. Sejnowski Tomaso Poggio

Preface

Theoretical analysis and computational modeling are important tools for characterizing what nervous systems do, determining how they function, and understanding why they operate in particular ways. Neuroscience encompasses approaches ranging from molecular and cellular studies to human psychophysics and psychology. Theoretical neuroscience encourages crosstalk among these subdisciplines by constructing compact representations of what has been learned, building bridges between different levels of description, and identifying unifying concepts and principles. In this book, we present the basic methods used for these purposes and discuss examples in which theoretical approaches have yielded insight into nervous system function.

The questions what, how, and why are addressed by descriptive, mechanistic, and interpretive models, each of which we discuss in the following chapters. Descriptive models summarize large amounts of experimental data compactly yet accurately, thereby characterizing what neurons and neural circuits do. These models may be based loosely on biophysical, anatomical, and physiological ﬁndings, but their primary purpose is to describe phenomena, not to explain them. Mechanistic models, on the other hand, address the question of how nervous systems operate on the basis of known anatomy, physiology, and circuitry. Such models often form a bridge between descriptive models couched at different levels. Interpretive models use computational and information-theoretic principles to explore the behavioral and cognitive signiﬁcance of various aspects of nervous system function, addressing the question of why nervous systems operate as they do.

descriptive models mechanistic models interpretive models

It is often difﬁcult to identify the appropriate level of modeling for a particular problem. A frequent mistake is to assume that a more detailed model is necessarily superior. Because models act as bridges between levels of understanding, they must be detailed enough to make contact with the lower level yet simple enough to provide clear results at the higher level.

Organization and Approach
This book is organized into three parts on the basis of general themes. Part I, Neural Encoding and Decoding, (chapters 1–4) is devoted to the coding of information by action potentials and the representation of in-

background exercises

xiv

Preface

formation by populations of neurons with selective responses. Modeling of neurons and neural circuits on the basis of cellular and synaptic biophysics is presented in part II, Neurons and Neural Circuits (chapters 5–7). The role of plasticity in development and learning is discussed in part III, Adaptation and Learning (chapters 8-10). With the exception of chapters 5 and 6, which jointly cover neuronal modeling, the chapters are largely independent and can be selected and ordered in a variety of ways for a one- or two-semester course at either the undergraduate or the graduate level.
Although we provide some background material, readers without previous exposure to neuroscience should refer to a neuroscience textbook such as Kandel, Schwartz, & Jessell (2000); Nicholls, Martin, & Wallace (1992); Bear, Connors, & Paradiso (1996); Shepherd (1997); Zigmond et al. (1998); or Purves et al. (2000).
Theoretical neuroscience is based on the belief that methods of mathematics, physics, and computer science can provide important insights into nervous system function. Unfortunately, mathematics can sometimes seem more of an obstacle than an aid to understanding. We have not hesitated to employ the level of analysis needed to be precise and rigorous. At times, this may stretch the tolerance of some of our readers. We encourage such readers to consult the Mathematical Appendix, which provides a brief review of most of the mathematical methods used in the text, but also to persevere and attempt to understand the implications and consequences of a difﬁcult derivation even if its steps are unclear.
Theoretical neuroscience, like any skill, can be mastered only with practice. Exercises are provided for this purpose on the web site for this book, http://mitpress.mit.edu/dayan-abbott. We urge the reader to do them. In addition, it will be highly instructive for the reader to construct the models discussed in the text and explore their properties beyond what we have been able to do in the available space.

Referencing
In order to maintain the ﬂow of the text, we have kept citations within the chapters to a minimum. Each chapter ends with an annotated bibliography containing suggestions for further reading (which are denoted by a bold font), information about works cited within the chapter, and references to related studies. We concentrate on introducing the basic tools of computational neuroscience and discussing applications that we think best help the reader to understand and appreciate them. This means that a number of systems where computational approaches have been applied with signiﬁcant success are not discussed. References given in the annotated bibliographies lead the reader toward such applications. Many people have contributed signiﬁcantly to the areas we cover. The books and review articles in the annotated bibliographies provide more comprehensive references to work that we have failed to cite.

Preface

xv

Acknowledgments

We are extremely grateful to a large number of students at Brandeis, the Gatsby Computational Neuroscience Unit, and MIT, and colleagues at many institutions who have painstakingly read, commented on, and criticized numerous versions of all the chapters. We particularly thank Bard Ermentrout, Mark Goldman, John Hertz, Mark Kvale, Zhaoping Li, Eve Marder, and Read Montague for providing extensive discussion and advice on the entire book. A number of people read signiﬁcant portions of the text and provided valuable comments, criticism, and insight: Bill Bialek, Pat Churchland, Nathaniel Daw, Dawei Dong, Peter Fo¨ ldia´k, Fabrizio Gabbiani, Zoubin Ghahramani, Geoff Goodhill, David Heeger, Geoff Hinton, Ken Miller, Phil Nelson, Sacha Nelson, Bruno Olshausen, Mark Plumbley, Alex Pouget, Fred Rieke, John Rinzel, Emilio Salinas, Sebastian Seung, Mike Shadlen, Satinder Singh, Rich Sutton, Nick Swindale, Carl van Vreeswijk, Chris Williams, David Willshaw, Charlie Wilson, Angela Yu, and Rich Zemel.
We received signiﬁcant additional assistance and advice from Greg DeAngelis, Andy Barto, Matt Beal, Sue Becker, Tony Bell, Paul Bressloff, Emery Brown, Matteo Carandini, Frances Chance, Yang Dan, Kenji Doya, Ed Erwin, John Fitzpatrick, David Foster, Marcus Frean, Ralph Freeman, Enrique Garibay, Frederico Girosi, Charlie Gross, Andreas Herz, Mike Jordan, Sham Kakade, Szabolcs Ka´li, Christof Koch, Simon Laughlin, John Lisman, Shawn Lockery, Guy Mayraz, Josh McDermott, Markus Meister, Earl Miller, Quaid Morris, Tony Movshon, Yuko Munakata, Randy O’Reilly, Simon Osindero, Tomaso Poggio, Clay Reid, Max Riesenhuber, Dario Ringach, Horacio Rotstein, Sam Roweis, Lana Rutherford, Ken Sugino, Alexei Samsonovich, Bob Shapley, Wolfram Schultz, Idan Segev, Terry Sejnowski, Jesper Sjo¨ stro¨ m, Haim Sompolinksy, Fiona Stevens, David Tank, Emo Todorov, Alessandro Treves, Gina Turrigiano, David Van Essen, Martin Wainwright, Xiao-Jing Wang, Chris Watkins, Max Welling, Jenny Whiting, Matt Wilson, Laurenz Wiskott, Danny Young, and Kechen Zhang. Thanks also to Quentin Huys, Philip Jonkers, Alexander Lerchner, Shih-Chii Liu, Ma´te´ Lengyel, Alex Loebel, Hadi Murr, Iain Murray, Jihwan Myung, John van Opstal, David Simon, Ed Snelson, and Rafael Yuste for pointing out errors in the text.
We thank Maneesh Sahani for advice and for indexing a substantial part of the text, Heidi Cartwright for creating the cover art, and Michael Rutter for his patience and consistent commitment. P.D. acknowledges the support of the Gatsby Charitable Foundation. Karen Abbott provided valuable help with the ﬁgures and with proofreading. Finally, we apologize to anyone we have inadvertently omitted from these lists.

I Neural Encoding and Decoding

1 Neural Encoding I: Firing Rates and Spike Statistics
1.1 Introduction
Neurons are remarkable among the cells of the body in their ability to propagate signals rapidly over large distances. They do this by generating characteristic electrical pulses called action potentials or, more simply, spikes that can travel down nerve ﬁbers. Neurons represent and transmit information by ﬁring sequences of spikes in various temporal patterns. The study of neural coding, which is the subject of the ﬁrst four chapters of this book, involves measuring and characterizing how stimulus attributes, such as light or sound intensity, or motor actions, such as the direction of an arm movement, are represented by action potentials.
The link between stimulus and response can be studied from two opposite points of view. Neural encoding, the subject of chapters 1 and 2, refers to the map from stimulus to response. For example, we can catalog how neurons respond to a wide variety of stimuli, and then construct models that attempt to predict responses to other stimuli. Neural decoding refers to the reverse map, from response to stimulus, and the challenge is to reconstruct a stimulus, or certain aspects of that stimulus, from the spike sequences it evokes. Neural decoding is discussed in chapter 3. In chapter 4, we consider how the amount of information encoded by sequences of action potentials can be quantiﬁed and maximized. Before embarking on this tour of neural coding, we brieﬂy review how neurons generate their responses and discuss how neural activity is recorded. The biophysical mechanisms underlying neural responses and action potential generation are treated in greater detail in chapters 5 and 6.
Properties of Neurons
Neurons are highly specialized for generating electrical signals in response to chemical and other inputs, and transmitting them to other cells. Some important morphological specializations, seen in ﬁgure 1.1, are the dendrites that receive inputs from other neurons and the axon that carries the neuronal output to other cells. The elaborate branching structure of

4

Neural Encoding I: Firing Rates and Spike Statistics

axons and dendrites

the dendritic tree allows a neuron to receive inputs from many other neurons through synaptic connections. The cortical pyramidal neuron of ﬁgure 1.1A and the cortical interneuron of ﬁgure 1.1C each receive thousands of synaptic inputs, and for the cerebellar Purkinje cell of ﬁgure 1.1B the number is over 100,000. Figure 1.1 does not show the full extent of the axons of these neurons. Axons from single neurons can traverse large fractions of the brain or, in some cases, of the entire body. In the mouse brain, it has been estimated that cortical neurons typically send out a total of about 40 mm of axon and have approximately 4 mm of total dendritic cable in their branched dendritic trees. The axon makes an average of 180 synaptic connections with other neurons per mm of length and the dendritic tree receives, on average, 2 synaptic inputs per µm. The cell body or soma of a typical cortical neuron ranges in diameter from about 10 to 50 µm.

ion channels

Along with these morphological features, neurons have physiological specializations. Most prominent among these are a wide variety of membrane-spanning ion channels that allow ions, predominantly sodium (Na+), potassium (K+), calcium (Ca2+), and chloride (Cl−), to move into and out of the cell. Ion channels control the ﬂow of ions across the cell membrane by opening and closing in response to voltage changes and to both internal and external signals.

membrane potential
hyperpolarization and depolarization

The electrical signal of relevance to the nervous system is the difference in electrical potential between the interior of a neuron and the surrounding extracellular medium. Under resting conditions, the potential inside the cell membrane of a neuron is about -70 mV relative to that of the surrounding bath (which is conventionally deﬁned to be 0 mV), and the cell is said to be polarized. Ion pumps located in the cell membrane maintain concentration gradients that support this membrane potential difference. For example, Na+ is much more concentrated outside a neuron than inside it, and the concentration of K+ is signiﬁcantly higher inside the neuron than in the extracellular medium. Ions thus ﬂow into and out of a cell due to both voltage and concentration gradients. Current in the form of positively charged ions ﬂowing out of the cell (or negatively charged ions ﬂowing into the cell) through open channels makes the membrane potential more negative, a process called hyperpolarization. Current ﬂowing into the cell changes the membrane potential to less negative or even positive values. This is called depolarization.

action potential refractory period

If a neuron is depolarized sufﬁciently to raise the membrane potential above a threshold level, a positive feedback process is initiated, and the neuron generates an action potential. An action potential is a roughly 100 mV ﬂuctuation in the electrical potential across the cell membrane that lasts for about 1 ms (ﬁgure 1.2A). Action potential generation also depends on the recent history of cell ﬁring. For a few milliseconds just after an action potential has been ﬁred, it may be virtually impossible to initiate another spike. This is called the absolute refractory period. For a longer interval known as the relative refractory period, lasting up to tens of milliseconds after a spike, it is more difﬁcult to evoke an action potential.

1.1 Introduction

5

A

B

apical dendrite

dendrite

soma
basal C
dendrite dendrite
axon collaterals
axon

soma axon
axon soma

Figure 1.1 Diagrams of three neurons. (A) A cortical pyramidal cell. These are the primary excitatory neurons of the cerebral cortex. Pyramidal cell axons branch locally, sending axon collaterals to synapse with nearby neurons, and also project more distally to conduct signals to other parts of the brain and nervous system. (B) A Purkinje cell of the cerebellum. Purkinje cell axons transmit the output of the cerebellar cortex. (C) A stellate cell of the cerebral cortex. Stellate cells are one of a large class of interneurons that provide inhibitory input to the neurons of the cerebral cortex. These ﬁgures are magniﬁed about 150-fold. (Drawings from Cajal, 1911; ﬁgure from Dowling, 1992.)
Action potentials are of great importance because they are the only form of membrane potential ﬂuctuation that can propagate over large distances. Subthreshold potential ﬂuctuations are severely attenuated over distances of 1 mm or less. Action potentials, on the other hand, are regenerated actively along axon processes and can travel rapidly over large distances without attenuation.
Axons terminate at synapses where the voltage transient of the action potential opens ion channels, producing an inﬂux of Ca2+ that leads to the release of a neurotransmitter (ﬁgure 1.2B). The neurotransmitter binds to receptors at the signal-receiving or postsynaptic side of the synapse,

synapse

6

Neural Encoding I: Firing Rates and Spike Statistics

A
20
0

B
axon terminal of presynaptic neuron

microtubules
mitochondrion synaptic vesicles

membrane potential (mV)

-20

cleft

dendritic

dendritic spine

specialization

of postsynaptic

-40

neuron

dendrite

-60 0

100

200

time (ms)

Figure 1.2 (A) An action potential recorded intracellularly from a cultured rat neocortical pyramidal cell. (B) Diagram of a synapse. The axon terminal or bouton is at the end of the axonal branch seen entering from the top of the ﬁgure. It is ﬁlled with synaptic vesicles containing the neurotransmitter that is released when an action potential arrives from the presynaptic neuron. Transmitter crosses the synaptic cleft and binds to receptors on the dendritic spine, a process roughly 1 µm long that extends from the dendrite of the postsynaptic neuron. Excitatory synapses onto cortical pyramidal cells form on dendritic spines as shown here. Other synapses form directly on the dendrites, axon, or soma of the postsynaptic neuron. (A recorded by L. Rutherford in the laboratory of G. Turrigiano; B adapted from Kandel et al., 1991.)

causing ion-conducting channels to open. Depending on the nature of the ion ﬂow, the synapses can have either an excitatory, depolarizing, or an inhibitory, typically hyperpolarizing, effect on the postsynaptic neuron.

sharp and patch electrodes

Recording Neuronal Responses
Figure 1.3 illustrates intracellular and extracellular methods for recording neuronal responses electrically (they can also be recorded optically). Membrane potentials are measured intracellularly by connecting a hollow glass electrode ﬁlled with a conducting electrolyte to a neuron, and comparing the potential it records with that of a reference electrode placed in the extracellular medium. Intracellular recordings are made either with sharp electrodes inserted through the membrane into the cell, or patch electrodes that have broader tips and are sealed tightly to the surface of the membrane. After the patch electrode seals, the membrane beneath its tip is either broken or perforated, providing electrical contact with the interior of the cell. The top trace in ﬁgure 1.3 is a schematic of an intracellular recording from the soma of a neuron ﬁring a sequence of action potentials. The recording shows rapid spikes riding on top of a more slowly varying subthreshold potential. The bottom trace is a schematic of an intracellular recording made some distance out on the axon of the neuron. These traces

1.1 Introduction

7

dendrite

15 mV 0.1 mV

100 mV

axon

100 ms

Figure 1.3 Three simulated recordings from a neuron. The top trace represents a recording from an intracellular electrode connected to the soma of the neuron. The height of the action potentials has been clipped to show the subthreshold membrane potential more clearly. The time scale is such that the action potential trajectory cannot be resolved. The bottom trace represents a recording from an intracellular electrode connected to the axon some distance away from the soma. The full height of the action potentials is indicated in this trace. The middle trace is a simulated extracellular recording. Action potentials appear as roughly equal positive and negative potential ﬂuctuations with an amplitude of around 0.1 mV. This is roughly 1000 times smaller than the approximately 0.1 V amplitude of an intracellularly recorded action potential. (Neuron drawing is the same as ﬁgure 1.1A.)
are drawings, not real recordings; such intracellular axon recordings, although possible in some types of cells, are difﬁcult and rare. Intracellular recordings from the soma are the norm, but intracellular dendritic recordings are increasingly being made as well. The subthreshold membrane potential waveform, apparent in the soma recording, is completely absent on the axon due to attenuation, but the action potential sequence in the two recordings is the same. This illustrates the important point that spikes, but not subthreshold potentials, propagate regeneratively down axons.
The middle trace in ﬁgure 1.3 illustrates an idealized, noise-free extracellular recording. Here an electrode is placed near a neuron but it does not penetrate the cell membrane. Such recordings can reveal the action potentials ﬁred by a neuron, but not its subthreshold membrane potentials. Extracellular recordings are typically used for in vivo experiments, especially those involving behaving animals. Intracellular recordings are sometimes made in vivo, but this is difﬁcult to do. Intracellular recording is more commonly used for in vitro preparations, such as slices of neural tissue. The responses studied in this chapter are action potential sequences that can be recorded either intra- or extracellularly.

extracellular electrodes

8

Neural Encoding I: Firing Rates and Spike Statistics

From Stimulus to Response

Characterizing the relationship between stimulus and response is difﬁcult because neuronal responses are complex and variable. Neurons typically respond by producing complex spike sequences that reﬂect both the intrinsic dynamics of the neuron and the temporal characteristics of the stimulus. Isolating features of the response that encode changes in the stimulus can be difﬁcult, especially if the time scale for these changes is of the same order as the average interval between spikes. Neural responses can vary from trial to trial even when the same stimulus is presented repeatedly. There are many potential sources of this variability, including variable levels of arousal and attention, randomness associated with various biophysical processes that affect neuronal ﬁring, and the effects of other cognitive processes taking place during a trial. The complexity and trial-to-trial variability of action potential sequences make it unlikely that we can describe and predict the timing of each spike deterministically. Instead, we seek a model that can account for the probabilities that different spike sequences are evoked by a speciﬁc stimulus.
Typically, many neurons respond to a given stimulus, and stimulus features are therefore encoded by the activities of large neural populations. In studying population coding, we must examine not only the ﬁring patterns of individual neurons but also the relationships of these ﬁring patterns to each other across the population of responding cells.
In this chapter, we introduce the ﬁring rate and spike-train correlation functions, which are basic measures of spiking probability and statistics. We also discuss spike-triggered averaging, a method for relating action potentials to the stimulus that evoked them. Finally, we present basic stochastic descriptions of spike generation, the homogeneous and inhomogeneous Poisson models, and discuss a simple model of neural responses to which they lead. In chapter 2, we continue our discussion of neural encoding by showing how reverse-correlation methods are used to construct estimates of ﬁring rates in response to time-varying stimuli. These methods have been applied extensively to neural responses in the retina, lateral geniculate nucleus (LGN) of the thalamus, and primary visual cortex, and we review the resulting models.

1.2 Spike Trains and Firing Rates
Action potentials convey information through their timing. Although action potentials can vary somewhat in duration, amplitude, and shape, they are typically treated as identical stereotyped events in neural encoding studies. If we ignore the brief duration of an action potential (about 1 ms), an action potential sequence can be characterized simply by a list of the times when spikes occurred. For n spikes, we denote these times by ti with i = 1, 2, . . . , n. The trial during which the spikes are recorded is taken to

1.2 Spike Trains and Firing Rates

9

start at time 0 and end at time T, so 0 ≤ ti ≤ T for all i. The spike sequence can also be represented as a sum of inﬁnitesimally narrow, idealized spikes
in the form of Dirac δ functions (see the Mathematical Appendix),

n
ρ(t) = δ(t − ti) .
i=1

(1.1)

We call ρ(t) the neural response function and use it to re-express sums over spikes as integrals over time. For example, for any well-behaved function h(t), we can write

n

∞

h(t − ti) = dτ h(τ)ρ(t − τ) ,

i=1

−∞

(1.2)

where the integral is over the duration of the trial. The equality follows from the basic deﬁning equation for a δ function,

dτ δ(t − τ)h(τ) = h(t) ,

(1.3)

provided that the limits of the integral surround the point t (if they do not, the integral is 0).

Because the sequence of action potentials generated by a given stimulus varies from trial to trial, neuronal responses are typically treated statistically or probabilistically. For example, they may be characterized by ﬁring rates, rather than as speciﬁc spike sequences. Unfortunately, the term “ﬁring rate” is applied conventionally to a number of different quantities. The simplest of these is what we call the spike-count rate, which is obtained by counting the number of action potentials that appear during a trial and dividing by the duration of the trial. We denote the spike-count rate by r, where

r

=

n T

=

1 T

T
dτ ρ(τ) .
0

(1.4)

The second equality follows from the fact that dτ ρ(τ ) = n and indicates

that the spike-count rate is the time average of the neural response func-

tion over the duration of the trial.

The spike-count rate can be determined from a single trial, but at the expense of losing all temporal resolution about variations in the neural response during the course of the trial. A time-dependent ﬁring rate can be deﬁned by counting spikes over short time intervals, but this can no longer be computed from a single trial. For example, we can deﬁne the ﬁring rate at time t during a trial by counting all the spikes that occurred between times t and t + t, for some small interval t, and dividing this count by
t. However, for small t, which allows for high temporal resolution, the result of the spike count on any given trial is apt to be either 0 or 1, giving only two possible ﬁring-rate values. The solution to this problem is to average over multiple trials. Thus, we deﬁne the time-dependent ﬁring rate

neural response function ρ(t) δ function
spike-count rate r

10

Neural Encoding I: Firing Rates and Spike Statistics

as the average number of spikes (averaged over trials) appearing during a short interval between times t and t + t, divided by the duration of the
interval.

trial average ﬁring rate r(t)

The number of spikes occurring between times t and t + t on a single trial is the integral of the neural response function over that time interval. The average number of spikes during this interval is the integral of the trial-averaged neural response function. We use angle brackets, , to denote averages over trials that use the same stimulus, so that z for any quantity z is the sum of the values of z obtained from many trials involving the same stimulus, divided by the number of trials. The trial-averaged neural response function is denoted by ρ(t) , and the time-dependent ﬁring rate is given by

r(t) =

1 t

t+ t

t
dτ

ρ(τ) .

(1.5)

We use the notation r(t) for this important quantity (as opposed to r for the spike-count rate), and when we use the term “ﬁring rate” without any modiﬁers, we mean r(t). Formally, the limit t → 0 should be taken on the right side of this expression, but, in extracting a time-dependent ﬁring rate from data, the value of t must be large enough so there are sufﬁcient numbers of spikes within the interval deﬁning r(t) to obtain a reliable estimate of the average.

spiking probability

For sufﬁciently small t, r(t) t is the average number of spikes occurring between times t and t + t over multiple trials. The average number of spikes over a longer time interval is given by the integral of r(t) over that interval. If t is small, there will never be more than one spike within the interval between t and t + t on any given trial. This means that r(t) t is also the fraction of trials on which a spike occurred between those times. Equivalently, r(t) t is the probability that a spike occurs during this time interval. This probabilistic interpretation provides a formal deﬁnition of the time-dependent ﬁring rate; r(t) t is the probability of a spike occurring during a short interval of duration t around the time t.

In any integral expression such as equation 1.2, the neural response function generates a contribution whenever a spike occurs. If we use the trialaverage response function instead, as in equation 1.5, this generates contributions proportional to the fraction of trials on which a spike occurred. Because of the relationship between this fraction and the ﬁring rate, we can replace the trial-averaged neural response function with the ﬁring rate r(t) within any well-behaved integral, for example,

dτ h(τ) ρ(t − τ) = dτ h(τ)r(t − τ)

(1.6)

for any function h. This establishes an important relationship between the average neural response function and the ﬁring rate; the two are equivalent when used inside integrals. It also provides another interpretation of r(t) as the trial-averaged density of spikes along the time axis.

1.2 Spike Trains and Firing Rates

11

In the same way that the response function ρ(t) can be averaged across trials to give the ﬁring rate r(t), the spike-count ﬁring rate can be averaged over trials, yielding a quantity that we refer to as the average ﬁring rate. This is denoted by r and is given by

r

=

n T

=1 T

T
dτ ρ(τ)
0

=1 T

T
dt r(t) .
0

(1.7)

The ﬁrst equality indicates that r is just the average number of spikes per trial divided by the trial duration. The third equality follows from the equivalence of the ﬁring rate and the trial-averaged neural response function within integrals (equation 1.6). The average ﬁring rate is equal to both the time average of r(t) and the trial average of the spike-count rate r. Of course, a spike-count rate and average ﬁring rate can be deﬁned by counting spikes over any time period, not necessarily the entire duration of a trial.

The term “ﬁring rate” is commonly used for all three quantities, r(t), r, and r . Whenever possible, we use the terms “ﬁring rate”, “spike-count rate”, and “average ﬁring rate” for r(t), r, and r , respectively, but when this becomes too cumbersome, the different mathematical notations serve to distinguish them. In particular, we distinguish the spike-count rate r from the time-dependent ﬁring rate r(t) by using a different font and by including the time argument in the latter expression (unless r(t) is independent of time). The difference between the fonts is rather subtle, but the context should make it clear which rate is being used.

Measuring Firing Rates
The ﬁring rate r(t) cannot be determined exactly from the limited data available from a ﬁnite number of trials. In addition, there is no unique way to approximate r(t). A discussion of the different methods allows us to introduce the concept of a linear ﬁlter and kernel that will be used extensively in the following chapters. We illustrate these methods by extracting ﬁring rates from a single trial, but more accurate results could be obtained by averaging over multiple trials.
Figure 1.4 compares a number of ways of approximating r(t) from a spike sequence. Figure 1.4A shows 3 s of the response of a neuron in the inferotemporal cortex recorded while a monkey watched a video. Neurons in the region of cortex where this recording was made are selective for complex visual images, including faces. A simple way of extracting an estimate of the ﬁring rate from a spike train like this is to divide time into discrete bins of duration t, count the number of spikes within each bin, and divide by t. Figure 1.4B shows the approximate ﬁring rate computed using this procedure with a bin size of 100 ms. Note that with this procedure, the quantity being computed is really the spike-count ﬁring rate over the duration of the bin, and that the ﬁring rate r(t) within a given bin is approximated by this spike-count rate.

average ﬁring rate r

12

Neural Encoding I: Firing Rates and Spike Statistics

A

rate (Hz) rate (Hz) rate (Hz) rate (Hz) spikes

B 100

50

0
C 100

50

0
D
100

50

0
E
100

50

0

0.0

0.5

1.0

1.5

2.0

2.5

3.0

time (s)

Figure 1.4 Firing rates approximated by different procedures. (A) A spike train
from a neuron in the inferotemporal cortex of a monkey recorded while that an-
imal watched a video on a monitor under free viewing conditions. (B) Discretetime ﬁring rate obtained by binning time and counting spikes with t = 100 ms.
(C) Approximate ﬁring rate determined by sliding a rectangular window function along the spike train with t = 100 ms. (D) Approximate ﬁring rate computed using a Gaussian window function with σt = 100 ms. (E) Approximate ﬁring rate using the window function of equation 1.12 with 1/α = 100 ms. (Data from Bad-
deley et al., 1997.)

The binning and counting procedure illustrated in ﬁgure 1.4B generates an estimate of the ﬁring rate that is a piecewise constant function of time, resembling a histogram. Because spike counts can take only integer values, the rates computed by this method will always be integer multiples of 1/ t, and thus they take discrete values. Decreasing the value of t increases temporal resolution by providing an estimate of the ﬁring rate at more ﬁnely spaced intervals of time, but at the expense of decreasing the resolution for distinguishing different rates. One way to avoid quantized ﬁring rates is to vary the bin size so that a ﬁxed number of spikes appears in each bin. The ﬁring rate is then approximated as that ﬁxed number of spikes divided by the variable bin width.
Counting spikes in preassigned bins produces a ﬁring-rate estimate that depends not only on the size of the time bins but also on their placement. To avoid the arbitrariness in the placement of bins, we can instead take a single bin or window of duration t and slide it along the spike train,

1.2 Spike Trains and Firing Rates

13

counting the number of spikes within the window at each location. The
jagged curve in ﬁgure 1.4C shows the result of sliding a 100 ms wide
window along the spike train. The ﬁring rate approximated in this way
can be expressed as the sum of a window function over the times ti for i = 1, 2, . . . , n when the n spikes in a particular sequence occurred,

n
rapprox (t) = w(t − ti ) ,
i=1

where the window function is

w(t) =

1/ t if − t/2 ≤ t <

0

otherwise .

t/2

(1.8) (1.9)

Use of a sliding window avoids the arbitrariness of bin placement and produces a rate that might appear to have a better temporal resolution. However, it must be remembered that the rates obtained at times separated by less than one bin width are correlated because they involve some of the same spikes.

The sum in equation 1.8 can also be written as the integral of the window function times the neural response function (see equation 1.2):

∞
rapprox (t) = dτ w(τ )ρ(t − τ ) .
−∞

(1.10)

The integral in equation 1.10 is called a linear ﬁlter, and the window function w, also called the ﬁlter kernel, speciﬁes how the neural response function evaluated at time t − τ contributes to the ﬁring rate approximated at
time t.

The jagged appearance of the curve in ﬁgure 1.4C is caused by the discontinuous shape of the window function used. An approximate ﬁring rate can be computed using virtually any window function w(τ ) that goes to 0 outside a region near τ = 0, provided that its time integral is equal to 1. For example, instead of the rectangular window function used in ﬁgure 1.4C, w(τ ) can be a Gaussian:

w(τ) = √ 1 exp 2πσw

−

τ2 2σw2

.

(1.11)

In this case, σw controls the temporal resolution of the resulting rate, playing a role analogous to t. A continuous window function like the Gaussian used in equation 1.8 generates a ﬁring-rate estimate that is a smooth function of time (ﬁgure 1.4D).

Both the rectangular and the Gaussian window functions approximate the ﬁring rate at any time, using spikes ﬁred both before and after that time. A postsynaptic neuron monitoring the spike train of a presynaptic cell has access only to spikes that have previously occurred. An approximation of the ﬁring rate at time t that depends only on spikes ﬁred before t can be calculated using a window function that vanishes when its argument

linear ﬁlter and kernel

14

Neural Encoding I: Firing Rates and Spike Statistics

half-wave rectiﬁcation [ ]+

is negative. Such a window function or kernel is called causal. One commonly used form is the α function

w(τ) = [α2τ exp(−ατ)]+

(1.12)

where 1/α determines the temporal resolution of the resulting ﬁring-rate estimate. The notation [z]+ for any quantity z stands for the half-wave rectiﬁcation operation,

[z]+ =

z if z ≥ 0 0 otherwise .

(1.13)

Figure 1.4E shows the ﬁring rate approximated by such a causal scheme. Note that this rate tends to peak later than the rate computed in ﬁgure 1.4D using a temporally symmetric window function.

stimulus s
response tuning curve f (s) primary visual cortex V1
Gaussian tuning curve

Tuning Curves

Neuronal responses typically depend on many different properties of a stimulus. In this chapter, we characterize responses of neurons as functions of just one of the stimulus attributes to which they may be sensitive. The value of this single attribute is denoted by s. In chapter 2, we consider more complete stimulus characterizations.

A simple way of characterizing the response of a neuron is to count the number of action potentials ﬁred during the presentation of a stimulus. This approach is most appropriate if the parameter s characterizing the stimulus is held constant over the trial. If we average the number of action potentials ﬁred over (in theory, an inﬁnite number of) trials and divide by the trial duration, we obtain the average ﬁring rate, r , deﬁned in equation 1.7. The average ﬁring rate written as a function of s, r = f (s), is called the neural response tuning curve. The functional form of a tuning curve depends on the parameter s used to describe the stimulus. The precise choice of parameters used as arguments of tuning curve functions is partially a matter of convention. Because tuning curves correspond to ﬁring rates, they are measured in units of spikes per second or Hz.

Figure 1.5A shows extracellular recordings of a neuron in the primary visual cortex (V1) of a monkey. While these recordings were being made, a bar of light was moved at different angles across the region of the visual ﬁeld where the cell responded to light. This region is called the receptive ﬁeld of the neuron. Note that the number of action potentials ﬁred depends on the angle of orientation of the bar. The same effect is shown in ﬁgure 1.5B in the form of a response tuning curve, which indicates how the average ﬁring rate depends on the orientation of the light bar stimulus. The data have been ﬁtted by a response tuning curve of the form

f (s) = rmax exp

−

1 2

s − smax σf

2

,

(1.14)

1.2 Spike Trains and Firing Rates

15

A

B

60

50

40

f (Hz)

30

20

10

0 -40

-20

0

20

40

s (orientation angle in degrees)

Figure 1.5 (A) Recordings from a neuron in the primary visual cortex of a monkey. A bar of light was moved across the receptive ﬁeld of the cell at different angles. The diagrams to the left of each trace show the receptive ﬁeld as a dashed square and the light source as a black bar. The bidirectional motion of the light bar is indicated by the arrows. The angle of the bar indicates the orientation of the light bar for the corresponding trace. (B) Average ﬁring rate of a cat V1 neuron plotted as a function of the orientation angle of the light bar stimulus. The curve is a ﬁt using the function 1.14 with parameters rmax = 52.14 Hz, smax = 0◦, and σ f = 14.73◦. (A adapted from Wandell, 1995, based on an original ﬁgure from Hubel and Wiesel, 1968; B data points from Henry et al., 1974).)

where s is the orientation angle of the light bar, smax is the orientation angle evoking the maximum average response rate rmax (with s − smax taken to lie in the range between −90◦ and +90◦), and σ f determines the width of the tuning curve. The neuron responds most vigorously when a stimulus having s = smax is presented, so we call smax the preferred orientation angle of the neuron.
Response tuning curves can be used to characterize the selectivities of neurons in visual and other sensory areas to a variety of stimulus parameters. Tuning curves can also be measured for neurons in motor areas, in which case the average ﬁring rate is expressed as a function of one or more parameters describing a motor action. Figure 1.6A shows an example of extracellular recordings from a neuron in primary motor cortex in a monkey that has been trained to reach in different directions. The stacked traces for each direction are rasters showing the results of ﬁve different trials. The horizontal axis in these traces represents time, and each mark indicates an action potential. The ﬁring pattern of the cell, in particular the rate at which spikes are generated, is correlated with the direction of arm movement, and thus encodes information about this aspect of the motor action.

Figure 1.6B shows the response tuning curve of an M1 neuron plotted as a function of the direction of arm movement. Here the data points have been ﬁtted by a tuning curve of the form

f (s) = r0 + (rmax − r0 ) cos(s − smax ) ,

(1.15)

where s is the reaching angle of the arm, smax is the reaching angle associ-

primary motor cortex M1
cosine tuning curve

sigmoidal tuning curve

16

Neural Encoding I: Firing Rates and Spike Statistics

A

B 60

50

f (Hz)

40

30

20

10

0 0 50 100 150 200 250 300 350
s (movement direction in degrees)

Figure 1.6 (A) Recordings from the primary motor cortex of a monkey performing an arm-reaching task. The hand of the monkey started from a central resting location, and reaching movements were made in the directions indicated by the arrows. The rasters for each direction show action potentials ﬁred on ﬁve trials. (B) Average ﬁring rate plotted as a function of the direction in which the monkey moved its arm. The curve is a ﬁt using the function 1.15 with parameters rmax = 54.69 Hz, r0 = 32.34 Hz, and smax = 161.25◦. (A adapted from Georgopoulos et al., 1982, which is also the source of the data points in B.)

ated with the maximum response rmax , and r0 is an offset or background ﬁring rate that shifts the tuning curve up from the zero axis. The minimum ﬁring rate predicted by equation 1.15 is 2r0 − rmax. For the neuron of ﬁgure 1.6B, this is a positive quantity, but for some M1 neurons 2r0 − rmax < 0, and the function 1.15 is negative over some range of angles. Because ﬁring rates cannot be negative, the cosine tuning curve must
be half-wave rectiﬁed in these cases (see equation 1.13),

f (s) = [r0 + (rmax − r0 ) cos(s − smax )]+ .

(1.16)

Figure 1.7B shows how the average ﬁring rate of a V1 neuron depends on retinal disparity and illustrates another important type of tuning curve. Retinal disparity is a difference in the retinal location of an image between the two eyes (ﬁgure 1.7A). Some neurons in area V1 are sensitive to disparity, representing an early stage in the representation of viewing distance. In ﬁgure 1.7B, the data points have been ﬁtted with a tuning curve called a logistic or sigmoidal function,

f (s) =

1 + exp

rmax (s1/2 − s)/

s

.

(1.17)

In this case, s is the retinal disparity, the parameter s1/2 is the disparity that produces a ﬁring rate half as big as the maximum value rmax , and s controls how quickly the ﬁring rate increases as a function of s. If s is negative, the ﬁring rate is a monotonically decreasing function of s rather
than a monotonically increasing function as in ﬁgure 1.7B.

Spike-Count Variability
Tuning curves allow us to predict the average ﬁring rate, but they do not describe how the spike-count ﬁring rate r varies about its mean value

1.3 What Makes a Neuron Fire?

17

A F

B
40

f (Hz)

30
s
20

10

0

-1.0 -0.5

0.0

0.5

1.0

s (retinal disparity in degrees)

Figure 1.7 (A) Deﬁnition of retinal disparity. The gray lines with arrows show the location on each retina of an object located nearer than the ﬁxation point F. The image from the ﬁxation point falls at the fovea in each eye, the small pit where the black lines meet the retina. The image from a nearer object falls to the left of the fovea in the left eye and to the right of the fovea in the right eye. For objects farther away than the ﬁxation point, this would be reversed. The disparity angle s is indicated in the ﬁgure. (B) Average ﬁring rate of a cat V1 neuron responding to separate bars of light illuminating each eye, plotted as a function of the disparity. Because this neuron ﬁres for positive s values, it is called a far-tuned cell. The curve is a ﬁt using the function 1.17 with parameters rmax = 36.03 Hz, s1/2 = 0.036◦, and
s = 0.029◦. (A adapted from Wandell, 1995; B data points from Poggio and Talbot, 1981.)

r = f (s) from trial to trial. While the map from stimulus to average response may be described deterministically, it is likely that single-trial responses such as spike-count rates can be modeled only in a probabilistic manner. For example, r values can be generated from a probability distribution with mean f (s). The trial-to-trial deviation of r from f (s) is considered to be noise, and such models are often called noise models. The standard deviation for the noise distribution either can be independent of f (s), in which case the variability is called additive noise, or it can depend on f (s). Multiplicative noise corresponds to having the standard deviation proportional to f (s).
Response variability extends beyond the level of spike counts to the entire temporal pattern of action potentials. Later in this chapter, we discuss a model of the neuronal response that uses a stochastic spike generator to produce response variability. This approach takes a deterministic estimate of the ﬁring rate, rest(t), and produces a stochastic spiking pattern from it. The spike generator produces variable numbers and patterns of action potentials, even if the same estimated ﬁring rate is used on each trial.

1.3 What Makes a Neuron Fire?
Response tuning curves characterize the average response of a neuron to a given stimulus. We now consider the complementary procedure of av-

18

Neural Encoding I: Firing Rates and Spike Statistics

eraging the stimuli that produce a given response. To average stimuli in this way, we need to specify what ﬁxed response we will use to “trigger” the average. The most obvious choice is the ﬁring of an action potential. Thus, we ask, “What, on average, did the stimulus do before an action potential was ﬁred?” The resulting quantity, called the spike-triggered average stimulus, provides a useful way of characterizing neuronal selectivity. Spike-triggered averages are computed using stimuli characterized by a parameter s(t) that varies over time. Before beginning our discussion of spike triggering, we describe some features of such stimuli.

Describing the Stimulus

Weber’s law Fechner’s law

Neurons responding to sensory stimuli face the difﬁcult task of encoding parameters that can vary over an enormous dynamic range. For example, photoreceptors in the retina can respond to single photons or can operate in bright light with an inﬂux of millions of photons per second. To deal with such wide-ranging stimuli, sensory neurons often respond most strongly to rapid changes in stimulus properties and are relatively insensitive to steady-state levels. Steady-state responses are highly compressed functions of stimulus intensity, typically with logarithmic or weak powerlaw dependences. This compression has an interesting psychophysical correlate. Weber measured how different the intensity of two stimuli had to be for them to be reliably discriminated, the “just noticeable” difference
s. He found that, for a given stimulus, s is proportional to the magnitude of the stimulus s, so that s/s is constant. This relationship is called Weber’s law. Fechner suggested that noticeable differences set the scale for perceived stimulus intensities. Integrating Weber’s law, this means that the perceived intensity of a stimulus of absolute intensity s varies as log s. This is known as Fechner’s law.

T 0

dt

s(t)/

T

=

0

stimulus and time averages

Sensory systems make numerous adaptations, using a variety of mech-

anisms, to adjust to the average level of stimulus intensity. When a

stimulus generates such adaptation, the relationship between stimulus

and response is often studied in a potentially simpler regime by describ-

ing responses to ﬂuctuations about a mean stimulus level. In this case,

s(t) is deﬁned so that its time average over the duration of a trial is 0,

T 0

dt

s(t)/

T

=

0.

We

frequently

impose

this

condition.

Our analysis of neural encoding involves two different types of averages: averages over repeated trials that employ the same stimulus, which we denote by angle brackets, and averages over different stimuli. We could introduce a second notation for averages over stimuli, but this can be avoided when using time-dependent stimuli. Instead of presenting a number of different stimuli and averaging over them, we can string together all of the stimuli we wish to consider into a single time-dependent stimulus sequence and average over time. Thus, stimulus averages are replaced by time averages.

Although a response recorded over a trial depends only on the values

1.3 What Makes a Neuron Fire?

19

taken by s(t) during that trial, some of the mathematical analyses presented in this chapter and in chapter 2 are simpliﬁed if we deﬁne the stimulus at other times as well. It is convenient if integrals involving the stimulus are time-translationally invariant so that for any function h and time interval τ

T

T+τ

T

dt h(s(t + τ)) =

dt h(s(t)) = dt h(s(t)) .

0

τ

0

(1.18)

To assure the last equality, we deﬁne the stimulus outside the time limits of the trial by the relation s(T + τ ) = s(τ ) for any τ, thereby making the
stimulus periodic.

periodic stimulus

The Spike-Triggered Average

The spike-triggered average stimulus, C(τ ), is the average value of the
stimulus a time interval τ before a spike is ﬁred. In other words, for a spike occurring at time ti, we determine s(ti − τ ), and then we sum over all n spikes in a trial, i = 1, 2, . . . , n, and divide the total by n. In addition,
we average over trials. Thus,

C(τ) =

1 n

n i=1

s(ti

−

τ)

≈

1 n

n
s(ti − τ) .
i=1

(1.19)

The approximate equality of the last expression follows from the fact that if n is large, the total number of spikes on each trial is well approximated by the average number of spikes per trial, n ≈ n . We make use of this approximation because it allows us to relate the spike-triggered average to other quantities commonly used to characterize the relationship between stimulus and response (see below). Figure 1.8 provides a schematic description of the computation of the spike-triggered average. Each time a spike appears, the stimulus in a time window preceding the spike is recorded. Although the range of τ values in equation 1.19 is unlimited, the response is typically affected only by the stimulus in a window a few hundred milliseconds wide immediately preceding a spike. More precisely, we expect C(τ ) to approach 0 for positive τ values larger than the correlation time between the stimulus and the response. If the stimulus has no temporal correlations with itself, we also expect C(τ ) to be 0 for τ < 0, because the response of a neuron cannot depend on future stimuli. In practice, the stimulus is recorded only over a ﬁnite time period, as indicated by the shaded areas in ﬁgure 1.8. The recorded stimuli for all spikes are then summed and the procedure is repeated over multiple trials.

The spike-triggered average stimulus can be expressed as an integral of the stimulus times the neural response function of equation 1.1. If we replace the sum over spikes with an integral, as in equation 1.2, and use the approximate expression for C(τ ) in equation 1.19, we ﬁnd

C(τ) =

1 n

T
dt
0

ρ(t) s(t − τ) =

1 n

T
dt r(t)s(t − τ) .
0

(1.20)

spike-triggered average C(τ )

20

Neural Encoding I: Firing Rates and Spike Statistics

s
time

spike-triggered average

Figure 1.8 Schematic of the procedure for computing the spike-triggered average stimulus. Each gray rectangle contains the stimulus prior to one of the spikes shown along the time axis. These are averaged to produce the waveform shown at the lower right, which is the average stimulus before a spike. The stimulus in this example is a piecewise constant function of time. (Adapted from Rieke et al., 1997.)

The second equality is due to the equivalence of ρ(t) and r(t) within integrals. Equation 1.20 allows us to relate the spike-triggered average to the correlation function of the ﬁring rate and the stimulus.

Correlation functions are a useful way of determining how two quantities

that vary over time are related to one another. The two quantities being

ﬁring-rate stimulus related are evaluated at different times, one at time t and the other at time

correlation function t + τ. The correlation function is then obtained by averaging their product

Qrs

over all t values, and it is a function of τ. The correlation function of the

ﬁring rate and the stimulus is

Qrs (τ )

=

1 T

T
dt r(t)s(t + τ) .
0

By comparing equations 1.20 and 1.21, we ﬁnd that

(1.21)

C(τ) =

1 r

Qrs(−τ) ,

(1.22)

reverse correlation function

where r = n / T is the average ﬁring rate over the set of trials. Because the argument of the correlation function in equation 1.22 is −τ, the spiketriggered average stimulus is often called the reverse correlation function. It is proportional to the correlation of the ﬁring rate with the stimulus at preceding times.

1.3 What Makes a Neuron Fire?

21

600 mV

100

C(τ) (mV)

C (mV)
50 mV

300 200 100
ττ((mms)s)
-100

200 ms

-200 -300

Figure 1.9 The spike-triggered average stimulus for a neuron of the electrosensory lateral-line lobe of the weakly electric ﬁsh Eigenmannia. The upper left trace is the potential used to generate the electric ﬁeld to which this neuron is sensitive. The evoked spike train is plotted below the stimulus potential. The plot on the right is the spike-triggered average stimulus. (Adapted from Gabbiani et al., 1996.)

The spike-triggered average stimulus is widely used to study and characterize neural responses. Because C(τ ) is the average value of the stimulus at a time τ before a spike, larger values of τ represent times farther in the past relative to the time of the triggering spike. For this reason, we plot spike-triggered averages with the time axis going backward compared to the normal convention. This allows the average spike-triggering stimulus to be read off from the plots in the usual left-to-right order.
Figure 1.9 shows the spike-triggered average stimulus for a neuron in the electrosensory lateral-line lobe of the weakly electric ﬁsh Eigenmannia. Weakly electric ﬁsh generate oscillating electric ﬁelds from an internal electric organ. Distortions in the electric ﬁeld produced by nearby objects are detected by sensors spread over the skin of the ﬁsh. The lateral-line lobe acts as a relay station along the processing pathway for electrosensory signals. Fluctuating electrical potentials, such as that shown in the upper left trace of ﬁgure 1.9, elicit responses from electrosensory lateral-line lobe neurons, as seen in the lower left trace. The spike-triggered average stimulus, plotted at the right, indicates that, on average, the electric potential made a positive upswing followed by a large negative deviation prior to a spike being ﬁred by this neuron.
The results obtained by spike-triggered averaging depend on the particular set of stimuli used during an experiment. How should this set be chosen? In chapter 2, we show that there are certain advantages to using a stimulus that is uncorrelated from one time to the next, a white-noise stimulus. A heuristic argument supporting the use of such stimuli is that in asking what makes a neuron ﬁre, we may want to sample its responses to stimulus ﬂuctuations at all frequencies with equal weight (i.e., equal power), and this is one of the properties of white-noise stimuli. In practice, white-noise stimuli can be generated with equal power only up to a ﬁnite frequency cutoff, but neurons respond to stimulus ﬂuctuations only within a limited frequency range anyway. Figure 1.9 is based on such an approximate white-noise stimulus. The power in a signal as a function

22

Neural Encoding I: Firing Rates and Spike Statistics

of its frequency is called the power spectrum or power spectral density. White noise has a ﬂat power spectrum.

stimulus autocorrelation function Qss

White-Noise Stimuli

The deﬁning characteristic of a white-noise stimulus is that its value at any one time is uncorrelated with its value at any other time. This condition can be expressed using the stimulus-stimulus correlation function, also called the stimulus autocorrelation, which is deﬁned by analogy with equation 1.21 as

Qss (τ)

=

1 T

T
dt s(t)s(t + τ) .
0

(1.23)

Just as a correlation function provides information about the temporal re-

lationship between two quantities, so an autocorrelation function tells us

about how a quantity at one time is related to itself evaluated at another
time. For white noise, the stimulus autocorrelation function is 0 in the range −T/2 < τ < T/2 except when τ = 0, and over this range

Qss (τ ) = σs2 δ(τ ) .

(1.24)

The constant σs, which has the units of the stimulus times the square root of the unit of time, reﬂects the magnitude of the variability of the white noise. In appendix A, we show that equation 1.24 is equivalent to the statement that white noise has equal power at all frequencies.

No physical system can generate noise that is white to arbitrarily high frequencies. Approximations of white noise that are missing high-frequency components can be used, provided the missing frequencies are well above the sensitivity of the neuron under investigation. To approximate white noise, we consider times that are integer multiples of a basic unit of duration t, that is, times t = m t for m = 1, 2, . . . , M where M t = T. The function s(t) is then constructed as a discrete sequence of stimulus values. This produces a steplike stimulus waveform, like the one that appears in ﬁgure 1.8, with a constant stimulus value sm presented during time bin m. In terms of the discrete-time values sm, the condition that the stimulus is uncorrelated is

1 M

M
sm sm+p
m=1

=

σs2 / t if p = 0

0

otherwise .

(1.25)

The factor of 1/ t on the right side of this equation reproduces the δ function of equation 1.24 in the limit t → 0. For approximate white noise, the autocorrelation function is 0 except for a region around τ = 0 with width
of order t. Similarly, the binning of time into discrete intervals of size t means that the noise generated has a ﬂat power spectrum only up to
frequencies of order 1/(2 t).

1.3 What Makes a Neuron Fire?

23

A
50

B

50

velocity (degs/ s )

velocity (degs/ s )

0
C
50

0 25 ms

10 ms

velocity (degs/ s )

0
5 ms
Figure 1.10 Single- and multiple-spike-triggered average stimuli for a blowﬂy H1 neuron responding to a moving visual image. (A) The average stimulus velocity triggered on a single spike. (B) The average stimulus velocity before two spikes with a separation of 10 ± 1 ms. (C) The average stimulus before two spikes with a separation of 5 ± 1 ms. (Data from de Ruyter van Steveninck and Bialek, 1988; ﬁgure adapted from Rieke et al., 1997.)
An approximation to white noise can be generated by choosing each sm independently from a probability distribution with mean 0 and variance σs2/ t. Any reasonable probability function satisfying these two conditions can be used to generate the stimulus values within each time bin. A special class of white-noise stimuli, Gaussian white noise, results when the probability distribution used to generate the sm values is a Gaussian function. The factor of 1/ t in the variance indicates that the variability must be increased as the time bins get smaller. A number of other schemes for efﬁciently generating approximations of white-noise stimuli are discussed in the references at the end of this chapter.

Multiple-Spike-Triggered Averages and Spike-Triggered Correlations
In addition to triggering on single spikes, stimulus averages can be computed by triggering on various combinations of spikes. Figure 1.10 shows some examples of two-spike triggers. These results come from a study of the H1 movement-sensitive visual neuron of the blowﬂy. The H1 neuron detects the motion of visual images during ﬂight in order to generate and guide stabilizing motor corrections. It responds to motion of the visual scene. In the experiments, the ﬂy is held ﬁxed while a visual image with a time-varying velocity s(t) is presented. Figure 1.10A, showing the spike-triggered average stimulus, indicates that this neuron responds to positive angular velocities after a latency of about 15 ms. Figure 1.10B is the average stimulus prior to the appearance of two spikes separated by 10 ± 1 ms. In this case, the two-spike average is similar to the sum of two single-spike-triggered average stimuli displaced from one another by 10 ms. Thus, for 10 ms separations, two spikes occurring together tell us no more as a two-spike unit than they would individually. This result changes when shorter separations are considered. Figure 1.10C shows the

24

Neural Encoding I: Firing Rates and Spike Statistics

average stimulus triggered on two spikes separated by 5 ± 1 ms. The average stimulus triggered on a pair of spikes separated by 5 ms is not the same as the sum of the average stimuli for each spike separately.
Spike-triggered averages of other stimulus-dependent quantities can provide additional insight into neural encoding, for example, spike-triggered average autocorrelation functions. Obviously, spike-triggered averages of higher-order stimulus combinations can be considered as well.

1.4 Spike-Train Statistics
A complete description of the stochastic relationship between a stimulus and a response would require us to know the probabilities corresponding to every sequence of spikes that can be evoked by the stimulus. Spike times are continuous variables, and, as a result, the probability for a spike to occur at any precisely speciﬁed time is actually zero. To get a nonzero value, we must ask for the probability that a spike occurs within a speciﬁed interval, for example, the interval between times t and t + t. For small t, the probability of a spike falling in this interval is proportional to the size of the interval, t. A similar relation holds for any continuous stochastic variable z. The probability that z takes a value between z and z + z, for small z (strictly speaking, as z → 0), is equal to p[z] z, where p[z] is called a probability density.
Throughout this book, we use the notation P[ ] to denote probabilities and p[ ] to denote probability densities. We use the bracket notation P[ ] generically for the probability of something occurring and also to denote a speciﬁc probability function. In the latter case, the notation P( ) would be more appropriate, but switching between square brackets and parentheses is confusing, so the reader will have to use the context to distinguish between these cases.
The probability of a spike sequence appearing is proportional to the probability density of spike times, p[t1, t2, . . . , tn]. In other words, the probability P[t1, t2, . . . , tn] that a sequence of n spikes occurs with spike i falling between times ti and ti + t for i = 1, 2, . . . , n is given in terms of this density by the relation P[t1, t2, . . . , tn] = p[t1, t2, . . . , tn]( t)n.
Unfortunately, the number of possible spike sequences is typically so large that determining or even roughly estimating all of their probabilities of occurrence is impossible. Instead, we must rely on some statistical model that allows us to estimate the probability of an arbitrary spike sequence occurring, given our knowledge of the responses actually recorded. The ﬁring rate r(t) determines the probability of ﬁring a single spike in a small interval around the time t, but r(t) is not, in general, sufﬁcient information to predict the probabilities of spike sequences. For example, the probability of two spikes occurring together in a sequence is not necessarily equal to the product of the probabilities that they occur individually, because

1.4 Spike-Train Statistics

25

the presence of one spike may effect the occurrence of the other. If, however, the probability of generating an action potential is independent of the presence or timing of other spikes (i.e., if the spikes are statistically independent) the ﬁring rate is all that is needed to compute the probabilities for all possible action potential sequences.
A stochastic process that generates a sequence of events, such as action potentials, is called a point process. In general, the probability of an event occurring at any given time could depend on the entire history of preceding events. If this dependence extends only to the immediately preceding event, so that the intervals between successive events are independent, the point process is called a renewal process. If there is no dependence at all on preceding events, so that the events themselves are statistically independent, we have a Poisson process. The Poisson process provides an extremely useful approximation of stochastic neuronal ﬁring. To make the presentation easier to follow, we separate two cases, the homogeneous Poisson process, for which the ﬁring rate is constant over time, and the inhomogeneous Poisson process, which involves a time-dependent ﬁring rate.

point process
renewal process Poisson process

The Homogeneous Poisson Process

We denote the ﬁring rate for a homogeneous Poisson process by r(t) = r
because it is independent of time. When the ﬁring rate is constant, the Poisson process generates every sequence of n spikes over a ﬁxed time interval with equal probability. As a result, the probability P[t1, t2, . . . , tn] can be expressed in terms of another probability function PT [n], which is the probability that an arbitrary sequence of exactly n spikes occurs within a trial of duration T. Assuming that the spike times are ordered so that 0 ≤ t1 ≤ t2 ≤ . . . ≤ tn ≤ T, the relationship is

P[t1, t2, . . . , tn] = n!PT [n]

t

n
.

T

(1.26)

This relationship is a special case of equation 1.37 derived below.

To compute PT [n], we divide the time T into M bins of size t = T/ M. We can assume that t is small enough so that we never get two spikes
within any one bin because, at the end of the calculation, we take the limit t → 0. PT [n] is the product of three factors: the probability of gener-
ating n spikes within a speciﬁed set of the M bins, the probability of not generating spikes in the remaining M − n bins, and a combinatorial factor
equal to the number of ways of putting n spikes into M bins. The proba-
bility of a spike occurring in one speciﬁc bin is r t, and the probability of n spikes appearing in n speciﬁc bins is (r t)n. Similarly, the probability of not having a spike in a given bin is (1 − r t), so the probability of having the remaining M − n bins without any spikes in them is (1 − r t)M−n.
Finally, the number of ways of putting n spikes into M bins is given by the

Poisson distribution

26

Neural Encoding I: Firing Rates and Spike Statistics

PT[n] PT[n]

A
1.0 0.8 0.6 0.4 0.2

n = 0 n = 1 n = 2 n = 5

B
0.15 0.10 0.05

0.0

0.00

0123456

0

rT

5

10 15 20

n

Figure 1.11 (A) The probability that a homogeneous Poisson process generates n spikes in a time period of duration T plotted for n = 0, 1, 2, and 5. The probability is plotted as function of the rate times the duration of the interval, rT, to make the plot applicable for any rate. (B) The probability of ﬁnding n spikes during a time period for which rT = 10 (dots) compared with a Gaussian distribution with mean
and variance equal to 10 (line).

binomial coefﬁcient M!/( M − n)!n!. Putting all these factors together, we

ﬁnd

PT [n] =

lim
t→0

(M

M! − n)!n!

(r

t)n(1 − r

t)M−n .

(1.27)

To take the limit, we note that as t → 0, M grows without bound because M t = T. Because n is ﬁxed, we can write M − n ≈ M = T/ t. Using this approximation and deﬁning ǫ = −r t, we ﬁnd that

lim (1 − r t)M−n = lim (1 + ǫ)1/ǫ −rT = e−rT = exp(−rT ) (1.28)

t→0

ǫ→0

because limǫ→0 (1 + ǫ)1/ǫ is, by deﬁnition, e = exp(1). For large M, M!/( M − n)! ≈ Mn = (T/ t)n, so

PT [n]

=

(rT )n n!

exp(−rT) .

(1.29)

This is called the Poisson distribution. The probabilities PT [n], for a few n values, are plotted as a function of rT in ﬁgure 1.11A. Note that as n increases, the probability reaches its maximum at larger T values and that large n values are more likely than small ones for large T. Figure 1.11B shows the probabilities of various numbers of spikes occurring when the average number of spikes is 10. For large rT, which corresponds to a large expected number of spikes, the Poisson distribution approaches a Gaussian distribution with mean and variance equal to rT. Figure 1.11B shows that this approximation is already quite good for rT = 10.

We can compute the variance of spike counts produced by a Poisson pro-

cess from the probabilities in equation 1.29. For spikes counted over an

interval of duration T, the variance of the spike count (derived in ap-

pendix B) is

σn2 = n2 − n 2 = rT .

(1.30)

1.4 Spike-Train Statistics

27

Thus the variance and mean of the spike count are equal. The ratio of these two quantities, σn2/ n , is called the Fano factor and takes the value 1 for a homogeneous Poisson process, independent of the time interval T.

Fano factor

The probability density of time intervals between adjacent spikes is called
the interspike interval distribution, and it is a useful statistic for character-
izing spiking patterns. Suppose that a spike occurs at a time ti for some value of i. The probability of a homogeneous Poisson process generating the next spike somewhere in the interval ti + τ ≤ ti+1 < ti + τ + t, for small t, is the probability that no spike is ﬁred for a time τ, times the
probability, r t, of generating a spike within the following small interval t. From equation 1.29, with n = 0, the probability of not ﬁring a spike
for period τ is exp(−rτ ), so the probability of an interspike interval falling between τ and τ + t is

interspike interval distribution

P[τ ≤ ti+1 − ti < τ + t] = r t exp(−rτ) .

(1.31)

The probability density of interspike intervals is, by deﬁnition, this probability with the factor t removed. Thus, the interspike interval distribution for a homogeneous Poisson spike train is an exponential. The most likely interspike intervals are short ones, and long intervals have a probability that falls exponentially as a function of their duration.

From the interspike interval distribution of a homogeneous Poisson spike train, we can compute the mean interspike interval,

τ=

∞
dτ τr exp(−rτ)

=

1

,

0

r

(1.32)

and the variance of the interspike intervals,

στ2 =

∞
dτ τ2r exp(−rτ) −
0

τ

2

=

1 r2

.

(1.33)

The ratio of the standard deviation to the mean is called the coefﬁcient of variation,

CV =

στ τ

,

(1.34)

and it takes the value 1 for a homogeneous Poisson process. This is a necessary, though not sufﬁcient, condition to identify a Poisson spike train.
Recall that the Fano factor for a Poisson process is also 1. For any renewal
process, the Fano factor evaluated over long time intervals approaches the value CV2 .

coefﬁcient of variation CV

The Spike-Train Autocorrelation Function
The spike interval distribution measures the distribution of times between successive action potentials in a train. It is useful to generalize this concept and determine the distribution of times between any two spikes in

28

Neural Encoding I: Firing Rates and Spike Statistics

spike-train autocorrelation function Qρρ

a train. This is called the spike-train autocorrelation function, and it is particularly useful for detecting patterns in spike trains, most notably oscillations. The spike-train autocorrelation function is the autocorrelation of the neural response function of equation 1.1 with its average over time and trials subtracted out. The time average of the neural response function, from equation 1.4, is the spike-count rate r, and the trial average of this quantity is r = n / T. Thus, the spike-train autocorrelation function is

Qρρ (τ )

=

1 T

T
dt
0

(ρ(t) − r ) (ρ(t + τ) −

r)

.

(1.35)

Because the average is subtracted from the neural response function in this expression, Qρρ should really be called an autocovariance, not an autocorrelation, but in practice it isn’t.

The spike-train autocorrelation function is constructed from data in the
form of a histogram by dividing time into bins. The value of the histogram
for a bin labeled with a positive or negative integer m is computed by
determining the number of the times that any two spikes in the train are separated by a time interval lying between (m − 1/2) t and (m + 1/2) t
with t the bin size. This includes all pairings, even between a spike and itself. We call this number Nm. If the intervals between the n2 spike pairs
in the train were uniformly distributed over the range from 0 to T, there would be n2 t/ T intervals in each bin. This uniform term is removed from the autocorrelation histogram by subtracting n2 t/ T from Nm for all
m. The spike-train autocorrelation histogram is then deﬁned by dividing the resulting numbers by T, so the value of the histogram in bin m is Hm = Nm/ T − n2 t/ T2. For small bin sizes, the m = 0 term in the histogram counts the average number of spikes, that is N0 = n and in the limit
t → 0, H0 = n / T is the average ﬁring rate r . Because other bins have Hm of order t, the large m = 0 term is often removed from histogram plots. The spike-train autocorrelation function is deﬁned as Hm/ t in the limit t → 0, and it has the units of a ﬁring rate squared. In this limit, the m = 0 bin becomes a δ function, H0/ t → r δ(τ ).

As we have seen, the distribution of interspike intervals for adjacent spikes
in a homogeneous Poisson spike train is exponential (equation 1.31). By contrast, the intervals between any two spikes (not necessarily adjacent) in
such a train are uniformly distributed. As a result, the subtraction procedure outlined above gives Hm = 0 for all bins except for the m = 0 bin that contains the contribution of the zero intervals between spikes and them-
selves. The autocorrelation function for a Poisson spike train generated at a constant rate r = r is thus

Qρρ (τ ) = rδ(τ ) .

(1.36)

cross-correlation function

A cross-correlation function between spike trains from two different neurons can be deﬁned by analogy with the autocorrelation function by determining the distribution of intervals between pairs of spikes, one taken

1.4 Spike-Train Statistics

29

A

B

-80

0

+80

-80

0

+80

time (ms)

time (ms)

Figure 1.12 Autocorrelation and cross-correlation histograms for neurons in the primary visual cortex of a cat. (A) Autocorrelation histograms for neurons recorded in the right (upper) and left (lower) hemispheres show a periodic pattern indicating oscillations at about 40 Hz. The lower diagram indicates stronger oscillations in the left hemisphere. (B) The cross-correlation histogram for these two neurons shows that their oscillations are synchronized with little time delay. (Adapted from Engel et al., 1991.)

from each train. The spike-train autocorrelation function is an even function of τ, Qρρ (τ ) = Qρρ (−τ ), but the cross-correlation function is not necessarily even. A peak at zero interval in a cross-correlation function signiﬁes that the two neurons are ﬁring synchronously. Asymmetric shifts in this peak away from 0 result from ﬁxed delays between the ﬁring of the two neurons, and they indicate nonsynchronous but phase-locked ﬁring. Periodic structure in either an autocorrelation or a cross-correlation function or histogram indicates that the ﬁring probability oscillates. Such periodic structure is seen in the histograms of ﬁgure 1.12, showing 40 Hz oscillations in neurons of cat primary visual cortex that are roughly synchronized between the two cerebral hemispheres.

The Inhomogeneous Poisson Process

When the ﬁring rate depends on time, different sequences of n spikes oc-
cur with different probabilities, and p[t1, t2, . . . , tn] depends on the spike times. Because spikes are still generated independently by an inhomoge-
neous Poisson process, their times enter into p[t1, t2, . . . , tn] only through the time-dependent ﬁring rate r(t). Assuming, as before, that the spike times are ordered 0 ≤ t1 ≤ t2 ≤ . . . ≤ tn ≤ T, the probability density for n spike times (derived in appendix C) is

T

n

p[t1, t2, . . . , tn] = exp − dt r(t) r(ti ) .

0

i=1

(1.37)

30

Neural Encoding I: Firing Rates and Spike Statistics

This result applies if the spike times have been written in temporal order. If the spike times are not ordered, so that, for example, we are interested in the probability density for any spike occurring at the time t1, not necessarily the ﬁrst spike, this expression should be divided by a factor of n! to account for the number of different possible orderings of spike times.

The Poisson Spike Generator

Spike sequences can be simulated by using some estimate of the ﬁring rate, rest(t), predicted from knowledge of the stimulus, to drive a Poisson process. A simple procedure for generating spikes in a computer program is based on the fact that the estimated probability of ﬁring a spike during a short interval of duration t is rest(t) t. The program progresses through time in small steps of size t and generates, at each time step, a random number xrand chosen uniformly in the range between 0 and 1. If rest (t) t > xrand at that time step, a spike is ﬁred; otherwise it is not.
For a constant ﬁring rate, it is faster to compute spike times ti for i = 1, 2, . . . n iteratively by generating interspike intervals from an exponential probability density (equation 1.31). If xrand is uniformly distributed over the range between 0 and 1, the negative of its logarithm is exponentially distributed. Thus, we can generate spike times iteratively from the formula ti+1 = ti − ln(xrand )/r. Unlike the algorithm discussed in the previous paragraph, this method works only for constant ﬁring rates. However, it can be extended to time-dependent rates by using a procedure called rejection sampling or spike thinning. The thinning technique requires a bound rmax on the estimated ﬁring rate such that rest (t) ≤ rmax at all times. We ﬁrst generate a spike sequence corresponding to the constant rate rmax by iterating the rule ti+1 = ti − ln(xrand )/rmax . The spikes are then thinned by generating another xrand for each i and removing the spike at time ti from the train if rest (ti )/rmax < xrand. If rest(ti )/rmax ≥ xrand, spike i is retained. Thinning corrects for the difference between the estimated time-dependent rate and the maximum rate.

Figure 1.13 shows an example of a model of an orientation-selective V1 neuron constructed in this way. In this model, the estimated ﬁring rate is determined from the response tuning curve of ﬁgure 1.5B,

rest (t) = f (s(t)) = rmax exp

−

1 2

s(t) − smax 2 σf

.

(1.38)

This is an extremely simpliﬁed model of response dynamics, because the ﬁring rate at any given time depends only on the value of the stimulus at that instant of time and not on its recent history. Models that allow for a dependence of ﬁring rate on stimulus history are discussed in chapter 2. In ﬁgure 1.13, the orientation angle increases in a sequence of steps. The ﬁring rate follows these changes, and the Poisson process generates an irregular ﬁring pattern that reﬂects the underlying rate but varies from trial to trial.

1.4 Spike-Train Statistics

31

stimulus orientation (degrees)

60 40 20
0 -20 -40 -60
60
40
20
0 0

50

100

150

200

250

300

350

400

450

500

time (ms)

firing rate (Hz)

spikes

Figure 1.13 Model of an orientation-selective neuron. The orientation angle (top panel) was increased from an initial value of -40◦ by 20◦ every 100 ms. The ﬁring rate (middle panel) was used to generate spikes (bottom panel) using a Poisson spike generator. The bottom panel shows spike sequences generated on ﬁve different trials.
Certain features of neuronal ﬁring violate the independence assumption that forms the basis of the Poisson model, at least if a constant ﬁring rate is used. We have already mentioned the absolute and relative refractory periods, which are periods of time following the generation of an action potential when the probability of a spike occurring is greatly or somewhat reduced. Frequently, these are most prominent features of real neuronal spike trains that are not captured by a Poisson model. Refractory effects can be incorporated into a Poisson model of spike generation by setting the ﬁring rate to 0 immediately after a spike is ﬁred, and then letting it return to its predicted value according to some dynamic rule such as an exponential recovery.
Comparison with Data
The Poisson process is simple and useful, but does it match data on neural response variability? To address this question, we examine Fano factors, interspike interval distributions, and coefﬁcients of variation.

area MT

32

Neural Encoding I: Firing Rates and Spike Statistics

variance (spikes2)

A
1000 100
10
1 0.1
0.1

B
1.1

multiplier

1

0.9

C
1.1

exponent

1

0.9

1

10

100

3

mean (spikes)

10

30

100

300

count duration (ms)

1000

Figure 1.14 Variability of MT neurons in alert macaque monkeys responding to moving visual images. (A) Variance of the spike counts for a 256 ms counting period plotted against the mean spike count. The straight line is the prediction of the Poisson model. Data are from 94 cells recorded under a variety of stimulus conditions. (B) The multiplier A in the relationship between spike-count variance and mean as a function of the duration of the counting interval. (C) The exponent B in this relation as a function of the duration of the counting interval. (Adapted from O’Keefe et al., 1997.)

The Fano factor describes the relationship between the mean spike count over a given interval and the spike-count variance. Mean spike counts n and variances σn2 from a wide variety of neuronal recordings have been ﬁtted to the equation σn2 = A n B, and the multiplier A and exponent B have been determined. The values of both A and B typically lie between 1.0 and 1.5. Because the Poisson model predicts A = B = 1, this indicates that the data show a higher degree of variability than the Poisson model would predict. However, many of these experiments involve anesthetized animals, and it is known that response variability is higher in anesthetized than in alert animals.
Figure 1.14 shows data for spike-count means and variances extracted from recordings of MT neurons in alert macaque monkeys using a number of different stimuli. The MT (medial temporal) area is a visual region of the primate cortex where many neurons are sensitive to image motion. The individual means and variances are scattered in ﬁgure 1.14A, but they cluster around the diagonal which is the Poisson prediction. Similarly, the results show A and B values close to 1, the Poisson values (ﬁgure 1.14B). Of course, many neural responses cannot be described by Poisson statistics, but it is reassuring to see a case where the Poisson model seems a reasonable approximation. As mentioned previously, when spike trains are not described very accurately by a Poisson model, refractory effects are often the primary reason.
Interspike interval distributions are extracted from data as interspike interval histograms by counting the number of intervals falling in discrete time bins. Figure 1.15A presents an example from the responses of a nonbursting cell in area MT of a monkey in response to images consisting of

1.4 Spike-Train Statistics

33

A 6.4

B 6.4

percent of isi

3.2

3.2

0

0

0

20

40

60

80 100

0

20

40

60 80 100

interspike interval (ms)

interspike interval (ms)

Figure 1.15 (A) Interspike interval distribution from an MT neuron responding to a moving, random-dot image. The probability of interspike intervals falling into the different bins, expressed as a percentage, is plotted against interspike interval. (B) Interspike interval histogram generated from a Poisson model with a stochastic refractory period. (Adapted from Bair et al., 1994.)

randomly moving dots with a variable amount of coherence imposed on their motion (see chapter 3 for a more detailed description). For interspike intervals longer than about 10 ms, the shape of this histogram is exponential, in agreement with equation 1.31. However, for shorter intervals there is a discrepancy. While the homogeneous Poisson distribution of equation 1.31 rises for short interspike intervals, the experimental results show a rapid decrease. This is the result of refractoriness making short interspike intervals less likely than the Poisson model would predict. Data on interspike intervals can be ﬁtted more accurately by a gamma distribution,

p[τ]

=

r(rτ )k

exp (−rτ ) k!

(1.39)

with k > 0, than by the exponential distribution of the Poisson model, which has k = 0.

Figure 1.15B shows a theoretical histogram obtained by adding a refractory period of variable duration to the Poisson model. Spiking was prohibited during the refractory period, and then was described once again by a homogeneous Poisson process. The refractory period was randomly chosen from a Gaussian distribution with a mean of 5 ms and a standard deviation of 2 ms (only random draws that generated positive refractory periods were included). The resulting interspike interval distribution of ﬁgure 1.15B agrees quite well with the data.

CV values extracted from the spike trains of neurons recorded in monkeys from area MT and primary visual cortex (V1) are shown in ﬁgure 1.16. The data have been divided into groups based on the mean interspike interval, and the coefﬁcient of variation is plotted as a function of this mean interval, equivalent to 1/ r . Except for short mean interspike intervals, the values are near 1, although they tend to cluster slightly lower than 1, the Poisson value. The small CV values for short interspike intervals are due to the refractory period. The solid curve is the prediction of a Poisson model with refractoriness.

The Poisson model with refractoriness provides a reasonably good description of a signiﬁcant amount of data, especially considering its sim-

gamma distribution

34

Neural Encoding I: Firing Rates and Spike Statistics

CV

1.2

1.0

0.8

0.6

0.4

0.2

00

10

20

30

average isi (ms)

Figure 1.16 Coefﬁcients of variation for a large number of V1 and MT neurons plotted as a function of mean interspike interval. The solid curve is the result of a Poisson model with a refractory period. (Adapted from Softky and Koch, 1992.)

plicity. However, there are cases in which the accuracy in the timing and numbers of spikes ﬁred by a neuron is considerably higher than would be implied by Poisson statistics. Furthermore, even when it successfully describes data, the Poisson model does not provide a mechanistic explanation of neuronal response variability. Spike generation, by itself, is highly reliable in real neurons. Figure 1.17 compares the response of V1 cells to constant current injection in vivo and in vitro. The in vitro response is a regular and reproducible spike train (left panel). The same current injection paradigm applied in vivo produces a highly irregular pattern of ﬁring (center panel) similar to the response to a moving bar stimulus (right panel). Although some of the basic statistical properties of ﬁring variability may be captured by the Poisson model of spike generation, the spikegenerating mechanism itself in real neurons is clearly not responsible for the variability. We explore ideas about possible sources of spike-train variability in chapter 5.
Some neurons ﬁre action potentials in clusters or bursts of spikes that cannot be described by a Poisson process with a ﬁxed rate. Bursting can be included in a Poisson model by allowing the ﬁring rate to ﬂuctuate in order to describe the high rate of ﬁring during a burst. Sometimes the distribution of bursts themselves can be described by a Poisson process (such a doubly stochastic process is called a Cox process).

1.5 The Neural Code
The nature of the neural code is a topic of intense debate within the neuroscience community. Much of the discussion has focused on whether neurons use rate coding or temporal coding, often without a clear deﬁnition of what these terms mean. We feel that the central issue in neural coding is whether individual action potentials and individual neurons encode inde-

1.5 The Neural Code

35

in vitro current injection

in vivo current injection in vivo visual stimulation

20 mV 100 ms

Figure 1.17 Intracellular recordings from cat V1 neurons. The left panel is the response of a neuron in an in vitro slice preparation to constant current injection. The center and right panels show recordings from neurons in vivo responding to either injected current (center) or a moving visual image (right). (Adapted from Holt et al., 1996.)
pendently of each other, or whether correlations between different spikes and different neurons carry signiﬁcant amounts of information. We therefore contrast independent-spike and independent-neuron codes with correlation codes before addressing the issue of temporal coding.

Independent-Spike, Independent-Neuron, and Correlation Codes

The neural response, and its relation to the stimulus, are completely characterized by the probability distribution of spike times as a function of the stimulus. If spike generation can be described as an inhomogeneous Poisson process, this probability distribution can be computed from the time-dependent ﬁring rate r(t), using equation 1.37. In this case, r(t) contains all the information about the stimulus that can be extracted from the spike train, and the neural code could reasonably be called a rate code. Unfortunately, this deﬁnition does not agree with common usage. Instead, we will call a code based solely on the time-dependent ﬁring rate an independent-spike code. This refers to the fact that the generation of each spike is independent of all the other spikes in the train. If individual spikes do not encode independently of each other, we call the code a correlation code, because correlations between spike times may carry additional information. In reality, information is likely to be carried both by individual spikes and through correlations, and some arbitrary dividing line must be established to characterize the code. Identifying a correlation code should require that a signiﬁcant amount of information be carried by correlations, for example, as much as is carried by the individual spikes.

independent-spike code
correlation code

A simple example of a correlation code would occur if signiﬁcant amounts of information about a stimulus were carried by interspike intervals. In this case, if we considered spike times individually, independently of each other, we would miss the information carried by the intervals between them. This is just one example of a correlation code. Information could be carried by more complex relationships between spikes.

independentneuron code
synchrony and oscillations
hippocampal place cells

36

Neural Encoding I: Firing Rates and Spike Statistics

Independent-spike codes are much simpler to analyze than correlation codes, and most work on neural coding assumes spike independence. When careful studies have been done, it has been found that some information is carried by correlations between two or more spikes, but this information is rarely larger than 10% of the information carried by spikes considered independently. Of course, it is possible that, due to our ignorance of the “real” neural code, we have not yet uncovered or examined the types of correlations that are most signiﬁcant for neural coding. Although this is not impossible, we view it as unlikely and feel that the evidence for independent-spike coding, at least as a fairly accurate approximation, is quite convincing.
The discussion to this point has focused on information carried by single neurons, but information is typically encoded by neuronal populations. When we study population coding, we must consider whether individual neurons act independently, or whether correlations between different neurons carry additional information. The analysis of population coding is easiest if the response of each neuron is considered statistically independent, and such independent-neuron coding is typically assumed in the analysis of population codes (chapter 3). The independent-neuron hypothesis does not mean that the spike trains of different neurons are not combined into an ensemble code. Rather, it means that they can be combined without taking correlations into account. To test the validity of this assumption, we must ask whether correlations between the spiking of different neurons provide additional information about a stimulus that cannot be obtained by considering all of their ﬁring patterns individually.
Synchronous ﬁring of two or more neurons is one mechanism for conveying information in a population correlation code. Rhythmic oscillations of population activity provide another possible mechanism, as discussed below. Both synchronous ﬁring and oscillations are common features of the activity of neuronal populations. However, the existence of these features is not sufﬁcient for establishing a correlation code, because it is essential to show that a signiﬁcant amount of information is carried by the resulting correlations. The assumption of independent-neuron coding is a useful simpliﬁcation that is not in gross contradiction with experimental data, but it is less well established and more likely to be challenged in the future than the independent-spike hypothesis.
Place-cell coding of spatial location in the rat hippocampus is an example in which at least some additional information appears to be carried by correlations between the ﬁring patterns of neurons in a population. The hippocampus is a structure located deep inside the temporal lobe that plays an important role in memory formation and is involved in a variety of spatial tasks. The ﬁring rates of many hippocampal neurons, recorded when a rat is moving around a familiar environment, depend on the location of the animal and are restricted to spatially localized areas called the place ﬁelds of the cells. In addition, when a rat explores an environment, hippocampal neurons ﬁre collectively in a rhythmic pattern with a frequency in the theta range, 7-12 Hz. The spiking time of an individual

1.5 The Neural Code

37

phase (degrees)

360

180

0

spikes

20 0 1.1

1.2 1.3 1.4 position (m)

Figure 1.18 Position versus phase for a hippocampal place cell. Each dot in the upper ﬁgure shows the phase of the theta rhythm plotted against the position of the animal at the time when a spike was ﬁred. The linear relation shows that information about position is contained in the relative phase of ﬁring. The lower plot is a conventional place ﬁeld tuning curve of spike count versus position. (Adapted from O’Keefe and Recce, 1993.)

place cell relative to the phase of the population theta rhythm gives additional information about the location of the rat not provided by place cells considered individually. The relationship between location and phase of place-cell ﬁring shown in ﬁgure 1.18 means, for example, that we can distinguish two locations on opposite sides of the peak of a single neuron’s tuning curve that correspond to the same ﬁring rate, by knowing when the spikes occurred relative to the theta rhythm. However, the amount of additional information carried by correlations between place-ﬁeld ﬁring and the theta rhythm has not been fully quantiﬁed.

Temporal Codes
The concept of temporal coding arises when we consider how precisely we must measure spike times to extract most of the information from a neuronal response. This precision determines the temporal resolution of the neural code. A number of studies have found that this temporal resolution is on a millisecond time scale, indicating that precise spike timing is a signiﬁcant element in neural encoding. Similarly, we can ask whether high-frequency ﬁring-rate ﬂuctuations carry signiﬁcant information about a stimulus. When precise spike timing or high-frequency ﬁring-rate ﬂuctuations are found to carry information, the neural code is often identiﬁed as a temporal code.

38

Neural Encoding I: Firing Rates and Spike Statistics

The temporal structure of a spike train or ﬁring rate evoked by a stimulus is determined both by the dynamics of the stimulus and by the nature of the neural encoding process. Stimuli that change rapidly tend to generate precisely timed spikes and rapidly changing ﬁring rates no matter what neural coding strategy is being used. Temporal coding refers to (or should refer to) temporal precision in the response that does not arise solely from the dynamics of the stimulus, but that nevertheless relates to properties of the stimulus. The interplay between stimulus and encoding dynamics makes the identiﬁcation of a temporal code difﬁcult.
The issue of temporal coding is distinct and independent from the issue of independent-spike coding discussed above. If the independent-spike hypothesis is valid, the temporal character of the neural code is determined by the behavior of r(t). If r(t) varies slowly with time, the code is typically called a rate code, and if it varies rapidly, the code is called temporal. Figure 1.19 provides an example of different ﬁring-rate behaviors for a neuron in area MT of a monkey recorded over multiple trials with three different stimuli (consisting of moving random dots). The activity in the top panel would typically be regarded as reﬂecting rate coding, and the activity in the bottom panel as reﬂecting temporal coding. However, the identiﬁcation of rate and temporal coding in this way is ambiguous because it is not obvious what criterion should be used to characterize the changes in r(t) as slow or rapid.
One possibility is to use the spikes to distinguish slow from rapid, so that a temporal code is identiﬁed when peaks in the ﬁring rate occur with roughly the same frequency as the spikes themselves. In this case, each peak corresponds to the ﬁring of only one, or at most a few action potentials. While this deﬁnition makes intuitive sense, it is problematic to extend it to the case of population coding. When many neurons are involved, any single neuron may ﬁre only a few spikes before its ﬁring rate changes, but collectively the population may produce a large number of spikes over the same time period. Thus, by this deﬁnition, a neuron that appears to employ a temporal code may be part of a population that does not.
Another proposal is to use the stimulus, rather than the response, to establish what makes a temporal code. In this case, a temporal code is deﬁned as one in which information is carried by details of spike timing on a scale shorter than the fastest time characterizing variations of the stimulus. This requires that information about the stimulus be carried by Fourier components of r(t) at frequencies higher than those present in the stimulus. Many of the cases where a temporal code has been reported using spikes to deﬁne the nature of the code would be called rate codes if the stimulus were used instead.
The debate between rate and temporal coding dominates discussions about the nature of the neural code. Determining the temporal resolution of the neural code is clearly important, but much of this debate seems uninformative. We feel that the central challenge is to identify relationships

1.6 Chapter Summary

39

140

spikes/s

0

500

1000

1500

2000

time (ms)

Figure 1.19 Time-dependent ﬁring rates for different stimulus parameters. The rasters show multiple trials during which an MT neuron responded to the same moving, random-dot stimulus. Firing rates, shown above the raster plots, were constructed from the multiple trials by counting spikes within discrete time bins and averaging over trials. The three different results are from the same neuron but using different stimuli. The stimuli were always patterns of moving random dots, but the coherence of the motion was varied (see chapter 3 for more information about this stimulus). (Adapted from Bair and Koch, 1996.)

between the ﬁring patterns of different neurons in a responding population and to understand their signiﬁcance for neural coding.

1.6 Chapter Summary
With this chapter, we have begun our study of the way that neurons encode information using spikes. We used a sequence of δ functions, the neural response function, to represent a spike train and deﬁned three types of ﬁring rates: the time-dependent ﬁring rate r(t), the spike-count rate r,

40

Neural Encoding I: Firing Rates and Spike Statistics

and the average ﬁring rate r . In the discussion of how the ﬁring rate r(t) could be extracted from data, we introduced the important concepts of a linear ﬁlter and a kernel acting as a sliding window function. The average ﬁring rate expressed as a function of a static stimulus parameter is called the response tuning curve, and we presented examples of Gaussian, cosine, and sigmoidal tuning curves. Spike-triggered averages of stimuli, or reverse correlation functions, were introduced to characterize the selectivity of neurons to dynamic stimuli. The homogeneous and inhomogeneous Poisson processes were presented as models of stochastic spike sequences. We deﬁned correlation functions, auto- and cross-correlations, and power spectra, and used the Fano factor, interspike-interval histogram, and coefﬁcient of variation to characterize the stochastic properties of spiking. We concluded with a discussion of independent-spike and independentneuron codes versus correlation codes, and of the temporal precision of spike timing as addressed in discussions of temporal coding.

1.7 Appendices

power spectrum

A: The Power Spectrum of White Noise

The Fourier transform of the stimulus autocorrelation function (see the Mathematical Appendix),

Q˜ ss (ω)

=

1 T

T/2
dτ Qss(τ) exp(iωτ) ,
−T/2

(1.40)

is called the power spectrum. Because we have deﬁned the stimulus as periodic outside the range of the trial T, we have used a ﬁnite-time Fourier transform and ω should be restricted to values that are integer multiples of 2π/ T. We can compute the power spectrum for a white-noise stimulus using the fact that Qss (τ ) = σs2δ(τ ) for white noise,

Q˜ ss (ω)

=

σs2 T

T/2
dτ
−T/2

δ(τ) exp(iωτ)

=

σs2 T

.

(1.41)

This is the deﬁning characteristic of white noise; its power spectrum is independent of frequency.

Using the deﬁnition of the stimulus autocorrelation function, we can also write

Q˜ ss (ω)

=

1 T

0

T
dt

s

(t

)

1 T

T/2
dτ s(t + τ) exp(iωτ)
−T/2

(1.42)

=

1 T

0

T
dt

s

(t

)

exp

(−i

ωt

)

1 T

T/2
dτ s(t + τ) exp(iω(t + τ)) .
−T/2

1.7 Appendices

41

The ﬁrst integral on the right side of the second equality is the complex conjugate of the Fourier transform of the stimulus,

s˜( ω )

=

1 T

T
dτ s(τ) exp(iωτ) .
0

(1.43)

The second integral, because of the periodicity of the integrand (when ω is an integer multiple of 2π/ T) is equal to s˜(ω). Therefore,

Q˜ ss (ω) = |s˜(ω)|2 ,

(1.44)

which provides another deﬁnition of the stimulus power spectrum. It is the absolute square of the Fourier transform of the stimulus.

Although equations 1.40 and 1.44 are both sound, they do not provide a statistically efﬁcient method of estimating the power spectrum of discrete approximations to white-noise sequences generated by the methods described in this chapter. That is, the apparently natural procedure of taking a white-noise sequence s(m t) for m = 1, 2, . . . , T/ t, and computing the square amplitude of its Fourier transform at frequency ω,

T T

T/ t
s(m
m=1

t) exp(−iωm

2
t) ,

is a biased and extremely noisy way of estimating Q˜ ss (ω). This estimator is called the periodogram. The statistical problems with the periodogram, and some of the many suggested solutions, are discussed in almost any textbook on spectral analysis (see, e.g., Percival and Waldron, 1993).

periodogram

B: Moments of the Poisson Distribution

The average number of spikes generated by a Poisson process with constant rate r over a time T is

n

=

∞ n=0

nPT [n]

=

∞ n=0

n(rT )n n!

exp(−rT) ,

(1.45)

and the variance in the spike count is

∞
σn2 (T ) = n2 PT [n] −
n=0

n

2

=

∞ n=0

n2 (rT)n n!

exp (−rT )

−

n 2.

(1.46)

To compute these quantities, we need to calculate the two sums appearing

in these equations. A good way to do this is to compute the moment-

generating function

moment-generating

g(α)

=

∞ n=0

(rT )n

exp(αn) n!

exp(−rT) .

(1.47)

function

42

Neural Encoding I: Firing Rates and Spike Statistics

The kth derivative of g with respect to α, evaluated at the point α = 0, is

dk g dαk

α=0

= ∞ nk (rT)n n=0 n!

exp(−rT) ,

(1.48)

so once we have computed g, we need to calculate only its ﬁrst and second
derivatives to determine the sums we need. Rearranging the terms a bit, and recalling that exp(z) = zn / n!, we ﬁnd

∞
g(α) = exp(−rT)
n=0

rT exp(α) n!

n

=

exp(−rT ) exp (rTeα )

.

(1.49)

The derivatives are then

dg dα

=

rTeα

exp(−rT ) exp(rTeα )

(1.50)

and

d2 g dα2

= (rTeα )2 exp(−rT ) exp(rTeα ) + rTeα exp(−rT ) exp(rTeα ) .

(1.51)

Evaluating these at α = 0 and putting the results into equations 1.45 and 1.46 gives the results n = rT and σn2 (T ) = (rT )2 + rT − (rT )2 = rT.

C: Inhomogeneous Poisson Statistics

The probability density for a particular spike sequence with spike times ti for i = 1, 2, . . . , n is obtained from the corresponding probability distribution by multiplying the probability that the spikes occur when they
do by the probability that no other spikes occur. We begin by computing
the probability that no spikes are generated during the time interval from
ti to ti+1 between two adjacent spikes. We determine this by dividing the interval into M bins of size t and setting M t = ti+1 − ti. We will ultimately take the limit t → 0. The ﬁring rate during bin m within this interval is r(ti + m t). Because the probability of ﬁring a spike in this bin is r(ti + m t) t, the probability of not ﬁring a spike is 1 − r(ti + m t) t. To have no spikes during the entire interval, we must string together M
such bins, and the probability of this occurring is the product of the indi-
vidual probabilities,

M
P[no spikes] = (1 − r(ti + m t) t) .
m=1
We evaluate this expression by taking its logarithm,

(1.52)

M
ln P[no spikes] = ln (1 − r(ti + m t) t) ,
m=1

(1.53)

1.8 Annotated Bibliography

43

using the fact that the logarithm of a product is the sum of the loga-
rithms of the multiplied terms. Using the approximation ln(1 − r(ti + m t) t) ≈ −r(ti + m t) t, valid for small t, we can simplify this to

M
ln P[no spikes] = − r(ti + m t) t .
m=1

(1.54)

In the limit t → 0, the approximation becomes exact and this sum becomes the integral of r(t) from ti to ti+1,

ti+1
ln P[no spikes] = − dt r(t) .
ti

(1.55)

Exponentiating this equation gives the result we need,

ti+1
P[no spikes] = exp − dt r(t) .
ti

(1.56)

The probability density p[t1, t2, . . . , tn] is the product of the densities for the individual spikes and the probabilities of not generating spikes during the interspike intervals, between time 0 and the ﬁrst spike, and between the time of the last spike and the end of the trial period:

t1

T

p[t1, t2, . . . , tn] = exp − dt r(t) exp − dt r(t) ×

0

tn

n−1

ti+1

r(tn ) r(ti) exp − dt r(t) .

(1.57)

i=1

ti

The exponentials in this expression all combine because the product of exponentials is the exponential of the sum, so the different integrals in this sum add up to form a single integral:

t1

T

n−1

ti+1

exp − dt r(t) exp − dt r(t) exp − dt r(t)

0

tn

i=1

ti

= exp −

t1

n−1 ti+1

T

dt r(t) +

dt r(t) + dt r(t)

0

i=1 ti

tn

T
= exp − dt r(t) .
0

(1.58)

Substituting this into 1.57 gives the result in equation 1.37.

1.8 Annotated Bibliography
Braitenberg & Schuz (1991) provides some of the quantitative measures of neuroanatomical properties of cortex that we quote. Rieke et al. (1997)

44

Neural Encoding I: Firing Rates and Spike Statistics

describes the analysis of spikes and the relationships between neural responses and stimuli, and is a general reference for material we present in chapters 1–4. Gabbiani & Koch (1998) provides another account of some of this material. The mathematics underlying point processes, the natural statistical model for spike sequences, is found in Cox (1962) and Cox & Isham (1980), including the relationship between the Fano factor and the coefﬁcient of variation. A general analysis of histogram representations appears in Scott (1992), and white-noise and ﬁltering techniques (our analysis of which continues in chapter 2) are described in de Boer & Kuyper (1968), Marmarelis & Marmarelis (1978), and Wiener (1958). Berry & Meister (1998) discuss the effects of refractoriness on patterns of spiking.
In chapters 1 and 3, we discuss two systems associated with studies of spike encoding; the H1 neuron in the visual system of ﬂies, reviewed by Rieke et al. (1997), and area MT of monkeys, discussed by Parker & Newsome (1998). Wandell (1995) introduces orientation and disparity tuning, relevant to examples presented in this chapter.

2 Neural Encoding II: Reverse Correlation and Visual Receptive Fields

2.1 Introduction
The spike-triggered average stimulus introduced in chapter 1 is a standard way of characterizing the selectivity of a neuron. In this chapter, we show how spike-triggered averages and reverse-correlation techniques can be used to construct estimates of ﬁring rates evoked by arbitrary time-dependent stimuli. Firing rates calculated directly from reversecorrelation functions provide only a linear estimate of the response of a neuron, but in this chapter we also present various methods for including nonlinear effects such as ﬁring thresholds.
Spike-triggered averages and reverse-correlation techniques have been used extensively to study properties of visually responsive neurons in the retina (retinal ganglion cells), lateral geniculate nucleus (LGN), and primary visual cortex (V1 or area 17). At these early stages of visual processing, the responses of some neurons (simple cells in primary visual cortex, for example) can be described quite accurately using this approach. Other neurons (complex cells in primary visual cortex, for example) can be described by extending the formalism. Reverse-correlation techniques have also been applied to responses of neurons in visual areas V2, area 18, and MT, but they generally fail to capture the more complex and nonlinear features typical of responses at later stages of the visual system. Descriptions of visual responses based on reverse correlation are approximate, and they do not explain how visual responses arise from the synaptic, cellular, and network properties of retinal, LGN, and cortical circuits. Nevertheless, they provide an important framework for characterizing response selectivities, a reference point for identifying and characterizing novel effects, and a basis for building mechanistic models, some of which are discussed at the end of this chapter and in chapter 7.
2.2 Estimating Firing Rates
In chapter 1, we discussed a simple model in which ﬁring rates were estimated as instantaneous functions of the stimulus, using response tuning

retina LGN V1, area 17

46

Reverse Correlation and Visual Receptive Fields

ﬁring rate estimate rest (t)

curves. The activity of a neuron at time t typically depends on the behavior of the stimulus over a period of time starting a few hundred milliseconds prior to t and ending perhaps tens of milliseconds before t. Reversecorrelation methods can be used to construct a more accurate model that includes the effects of the stimulus over such an extended period of time. The basic problem is to construct an estimate rest(t) of the ﬁring rate r(t) evoked by a stimulus s(t). The simplest way to construct an estimate is to assume that the ﬁring rate at any given time can be expressed as a weighted sum of the values taken by the stimulus at earlier times. Because time is a continuous variable, this “sum” actually takes the form of an integral, and we write

∞
rest(t) = r0 + dτ D(τ )s(t − τ ) .
0

(2.1)

The term r0 accounts for any background ﬁring that may occur when s = 0. D(τ ) is a weighting factor that determines how strongly, and with what sign, the value of the stimulus at time t − τ affects the ﬁring rate at time t.
Note that the integral in equation 2.1 is a linear ﬁlter of the same form as the expressions used to compute rapprox (t) in chapter 1.

As discussed in chapter 1, sensory systems tend to adapt to the absolute intensity of a stimulus. It is easier to account for the responses to ﬂuctuations of a stimulus around some mean background level than it is to account for adaptation processes. We therefore assume throughout this chapter that the stimulus parameter s(t) has been deﬁned with its mean value subtracted out. This means that the time integral of s(t) over the duration of a trial is 0.

Volterra expansion

We have provided a heuristic justiﬁcation for the terms in equation 2.1 but, more formally, they correspond to the ﬁrst two terms in a systematic expansion of the response in powers of the stimulus. Such an expansion, called a Volterra expansion, is the functional equivalent of the Taylor series expansion used to generate power series approximations of functions. For the case we are considering, it takes the form

rest (t) = r0 + dτ D(τ )s(t − τ ) + dτ1dτ2 D2 (τ1 , τ2 )s(t − τ1 )s(t − τ2 )+ dτ1dτ2 dτ3 D3 (τ1 , τ2, τ3 )s(t − τ1 )s(t − τ2 )s(t − τ3 ) + . . . . (2.2)

Wiener expansion Wiener kernel

This series was rearranged by Wiener to make the terms easier to compute. The ﬁrst two terms of the Volterra and Wiener expansions take the same mathematical forms and are given by the two expressions on the right side of equation 2.1. For this reason, D is called the ﬁrst Wiener kernel, the linear kernel, or, when higher-order terms (terms involving more than one factor of the stimulus) are not being considered, simply the kernel.
To construct an estimate of the ﬁring rate based on equation 2.1, we choose the kernel D to minimize the squared difference between the estimated response to a stimulus and the actual measured response averaged over the

2.2 Estimating Firing Rates

47

duration of the trial, T,

E

=

1 T

T
dt (rest (t) − r(t))2 .
0

(2.3)

This expression can be minimized by setting its derivative with respect

to the function D to 0 (see appendix A). The result is that D satisﬁes an
equation involving two quantities introduced in chapter 1, the ﬁring ratestimulus correlation function, Qrs (τ ) = dt r(t) s(t + τ )/ T, and the stimulus autocorrelation function, Qss (τ ) = dt s(t) s(t + τ )/ T:

∞
dτ′ Qss (τ − τ′ )D(τ′ ) = Qrs(−τ) .
0

(2.4)

The method we are describing is called reverse correlation because the ﬁring rate–stimulus correlation function is evaluated at −τ in this equation.

optimal kernel

Equation 2.4 can be solved most easily if the stimulus is white noise, al-
though it can be solved in the general case as well (see appendix A). For a white-noise stimulus Qss (τ ) = σs2δ(τ ) (see chapter 1), so the left side of equation 2.4 is

∞
σs2 dτ′ δ(τ − τ′ )D(τ′ ) = σs2 D(τ ) .
0

(2.5)

As a result, the kernel that provides the best linear estimate of the ﬁring

rate is

D(τ)

=

Qrs (−τ ) σs2

=

r

C(τ) σs2

,

(2.6)

where C(τ ) is the spike-triggered average stimulus and r is the average ﬁring rate of the neuron. For the second equality, we have used the relation Qrs (−τ ) = r C(τ ) from chapter 1. Based on this result, the standard method used to determine the optimal kernel is to measure the spiketriggered average stimulus in response to a white-noise stimulus.

white-noise kernel

In chapter 1, we introduced the H1 neuron of the ﬂy visual system, which responds to moving images. Figure 2.1 shows a prediction of the ﬁring rate of this neuron obtained from a linear ﬁlter. The velocity of the moving image is plotted in 2.1A, and two typical responses are shown in 2.1B. The ﬁring rate predicted from a linear estimator, as discussed above, and the ﬁring rate computed from the data by binning and counting spikes are compared in ﬁgure 2.1C. The agreement is good in regions where the measured rate varies slowly, but the estimate fails to capture high-frequency ﬂuctuations of the ﬁring rate, presumably because of nonlinear effects not captured by the linear kernel. Some such effects can be described by a static nonlinear function, as discussed below. Others may require including higher-order terms in a Volterra or Wiener expansion.

48

A

60

40

s (degrees/s)

20

0

-20

-40

-60
B

Reverse Correlation and Visual Receptive Fields

spikes

C
100

firing rate (Hz)

50

0

0

100

200

300

400 500

time (ms)

Figure 2.1 Prediction of the ﬁring rate for an H1 neuron responding to a moving visual image. (A) The velocity of the image used to stimulate the neuron. (B) Two of the 100 spike sequences used in this experiment. (C) Comparison of the measured and computed ﬁring rates. The dashed line is the ﬁring rate extracted directly from the spike trains. The solid line is an estimate of the ﬁring rate constructed by linearly ﬁltering the stimulus with an optimal kernel. (Adapted from Rieke et al., 1997.)

The Most Effective Stimulus

Neuronal selectivity is often characterized by describing stimuli that evoke maximal responses. The reverse-correlation approach provides a basis for this procedure by relating the optimal kernel for ﬁring-rate estimation to the stimulus predicted to evoke the maximum ﬁring rate, subject to a constraint. A constraint is essential because the linear estimate in equation 2.1 is unbounded. The constraint we use is that the time integral of the square of the stimulus over the duration of the trial is held ﬁxed. We call this integral the stimulus energy. The stimulus for which equation 2.1 predicts the maximum response at some ﬁxed time subject to this constraint, is computed in appendix B. The result is that the stimulus producing the maximum response is proportional to the optimal linear kernel or, equivalently, to the white-noise spike-triggered average stimulus. This is an important result because in cases where a white-noise analysis has not been done, we may still have some idea what stimulus produces the maximum response.
The maximum stimulus analysis provides an intuitive interpretation of

2.2 Estimating Firing Rates

49

the linear estimate of equation 2.1. At ﬁxed stimulus energy, the integral in 2.1 measures the overlap between the actual stimulus and the most effective stimulus. In other words, it indicates how well the actual stimulus matches the most effective stimulus. Mismatches between these two reduce the value of the integral and result in lower predictions for the ﬁring rate.

Static Nonlinearities

The optimal kernel produces an estimate of the ﬁring rate that is a linear function of the stimulus. Neurons and nervous systems are nonlinear, so a linear estimate is only an approximation, albeit a useful one. The linear prediction has two obvious problems: there is nothing to prevent the predicted ﬁring rate from becoming negative, and the predicted rate does not saturate, but instead increases without bound as the magnitude of the stimulus increases. One way to deal with these and some of the other deﬁciencies of a linear prediction is to write the ﬁring rate as a background rate plus a nonlinear function of the linearly ﬁltered stimulus. We use L to represent the linear term we have been discussing thus far:

∞

L(t) = dτD(τ)s(t − τ) .

(2.7)

0

The modiﬁcation is to replace the linear prediction rest(t) = r0 + L(t) with the generalization

rest (t) = r0 + F(L(t)) ,

(2.8)

where F is an arbitrary function. F is called a static nonlinearity to stress that it is a function of the linear ﬁlter value evaluated instantaneously at the time of the rate estimation. If F is appropriately bounded from above and below, the estimated ﬁring rate will never be negative or unrealistically large.

F can be extracted from data by means of the graphical procedure illustrated in ﬁgure 2.2A. First, a linear estimate of the ﬁring rate is computed using the optimal kernel deﬁned by equation 2.4. Next a plot is made of the pairs of points (L(t), r(t)) at various times and for various stimuli, where r(t) is the actual rate extracted from the data. There will be a certain amount of scatter in this plot due to the inaccuracy of the estimation. If the scatter is not too large, however, the points should fall along a curve, and this curve is a plot of the function F(L). It can be extracted by ﬁtting a function to the points on the scatter plot. The function F typically contains constants used to set the ﬁring rate to realistic values. These give us the freedom to normalize D(τ ) in some convenient way, correcting for the arbitrary normalization by adjusting the parameters within F.

Static nonlinearities are used to introduce both ﬁring thresholds and saturation into estimates of neural responses. Thresholds can be described by

rest (t) with static nonlinearity

50

Reverse Correlation and Visual Receptive Fields

r (Hz) F (Hz)

A
100 80 60

B
100
80
60

Eq. 2.9 Eq. 2.10 Eq. 2.11

40

40

20

20

0

0

1

2

3

4

5

L

0

0

1

2

3

4

5

L

Figure 2.2 (A) A graphical procedure for determining static nonlinearities. Linear
estimates L and actual ﬁring rates r are plotted (solid points) and ﬁtted by the function F(L) (solid line). (B) Different static nonlinearities used in estimating
neural responses. L is dimensionless, and equations 2.9, 2.10, and 2.11 have been used with G = 25 Hz, L0 = 1, L1/2 = 3, rmax = 100 Hz, g1 = 2, and g2 = 1/2.

writing

threshold function rectiﬁcation
sigmoidal function

F(L) = G[L − L0]+ ,

(2.9)

where L0 is the threshold value that L must attain before ﬁring begins. Above the threshold, the ﬁring rate is a linear function of L, with G acting
as the constant of proportionality. Half-wave rectiﬁcation is a special case of this with L0 = 0. That this function does not saturate is not a problem if large stimulus values are avoided. If needed, a saturating nonlinearity can
be included in F, and a sigmoidal function is often used for this purpose,

F(L) = 1 + exp

rmax g1(L1/2 − L)

.

(2.10)

Here rmax is the maximum possible ﬁring rate, L1/2 is the value of L for which F achieves half of this maximal value, and g1 determines how rapidly the ﬁring rate increases as a function of L. Another choice that combines a hard threshold with saturation uses a rectiﬁed hyperbolic tan-
gent function,

F(L) = rmax [tanh g2 (L − L0 ) ]+ ,

(2.11)

where rmax and g2 play similar roles as in equation 2.10, and L0 is the threshold. Figure 2.2B shows the different nonlinear functions that we
have discussed.

Although the static nonlinearity can be any function, the estimate of equation 2.8 is still restrictive because it allows for no dependence on weighted autocorrelations of the stimulus or other higher-order terms in the Volterra series. Furthermore, once the static nonlinearity is introduced, the linear kernel derived from equation 2.4 is no longer optimal because it was chosen to minimize the squared error of the linear estimate rest(t) = r0 + L(t),

2.3 Introduction to the Early Visual System

51

stimulus

Linear Filter

Ê

Ä

×

Static Nonlinearity

· ´ µ Ö ×Ø Ö¼

Ä

Spike Generator
¡ Ö ×Ø Ø ÜÖ Ò

response

Figure 2.3 Simulating spiking responses to stimuli. The integral of the stimulus s times the optimal kernel D is ﬁrst computed. The estimated ﬁring rate is the background rate r0 plus a nonlinear function of the output of the linear ﬁlter calculation. Finally, the estimated ﬁring rate is used to drive a Poisson process that generates spikes.

not the estimate with the static nonlinearity rest(t) = r0 + F(L(t)). A theorem due to Bussgang (see appendix C) suggests that equation 2.6 will provide a reasonable kernel, even in the presence of a static nonlinearity, if the white noise stimulus used is Gaussian.

In some cases, the linear term of the Volterra series fails to predict the response even when static nonlinearities are included. Systematic improvements can be attempted by including more terms in the Volterra or Wiener series, but in practice it is quite difﬁcult to go beyond the ﬁrst few terms. The accuracy with which the ﬁrst term, or ﬁrst few terms, in a Volterra series can predict the responses of a neuron can sometimes be improved by replacing the parameter s in equation 2.7 with an appropriately chosen function of s, so that

∞
L(t) = dτD(τ) f (s(t − τ)) .
0

(2.12)

A reasonable choice for this function is the response tuning curve. With this choice, the linear prediction is equal to the response tuning curve, L = f (s), for static stimuli, provided that the integral of the kernel D is equal to 1. For time-dependent stimuli, we can think of equation 2.12 as a dynamic extension of the response tuning curve.

A model of the spike trains evoked by a stimulus can be constructed by using the ﬁring-rate estimate of equation 2.8 to drive a Poisson spike generator (see chapter 1). Figure 2.3 shows the structure of such a model with a linear ﬁlter, a static nonlinearity, and a stochastic spike generator. In the ﬁgure, spikes are shown being generated by comparing the spiking probability r(t) t to a random number, although the other methods discussed in chapter 1 could be used instead. Also, the linear ﬁlter acts directly on the stimulus s in ﬁgure 2.3, but it could act instead on some function f (s), such as the response tuning curve.

2.3 Introduction to the Early Visual System
Before discussing how reverse-correlation methods are applied to visually responsive neurons, we review the basic anatomy and physiology of the

52

Reverse Correlation and Visual Receptive Fields

A

B

R rod and cone receptors (R)

horizontal (H)

bipolar (B)

B

amacrine (A)

R
H B
A

retinal

ganglion (G)

G1

light

G2
to optic nerve

Figure 2.4 (A) An anatomical diagram of the circuitry of the retina of a dog. Cell types are identiﬁed at right. In the intact eye, counterintuitively, light enters through the side opposite from the photoreceptors. (B) Intracellular recordings from retinal neurons of the mud puppy responding to a ﬂash of light lasting for 1 s. In the column of cells on the left side of the diagram, the resulting hyperpolarizations are about 4 mV in the rod and retinal ganglion cells, and 8 mV in the bipolar cell. Pluses and minuses represent excitatory and inhibitory synapses, respectively. (A adapted from Nicholls et al., 1992; drawing from Cajal, 1911. B data from Werblin and Dowling 1969; ﬁgure adapted from Dowling, 1992.)

retinal ganglion cells

early stages of the visual system. The conversion of a light stimulus into an electrical signal and ultimately an action potential sequence occurs in the retina. Figure 2.4A is an anatomical diagram showing the ﬁve principal cell types of the retina, and ﬁgure 2.4B is a rough circuit diagram. In the retina, light is ﬁrst converted into an electrical signal by a phototransduction cascade within rod and cone photoreceptor cells. Figure 2.4B shows intracellular recordings made in neurons of the retina of a mud puppy (an amphibian). The stimulus used for these recordings was a ﬂash of light falling primarily in the region of the photoreceptor at the left of ﬁgure 2.4B. The rod cells, especially the one on the left side of ﬁgure 2.4B, are hyperpolarized by the light ﬂash. This electrical signal is passed along to bipolar and horizontal cells through synaptic connections. Note that in one of the bipolar cells, the signal has been inverted, leading to depolarization. These smoothly changing membrane potentials provide a graded representation of the light intensity during the ﬂash. This form of coding is adequate for signaling within the retina, where distances are small. However, it is inadequate for the task of conveying information from the retina to the brain.
The output neurons of the retina are the retinal ganglion cells, whose axons form the optic nerve. As seen in ﬁgure 2.4B, the subthreshold potentials

2.3 Introduction to the Early Visual System

53

retina

lateral geniculate
nucleus

retina

optic chiasm
lateral geniculate nucleus

primary visual cortex

Figure 2.5 Pathway from the retina through the lateral geniculate nucleus (LGN) of the thalamus to the primary visual cortex in the human brain. (Adapted from Nicholls et al., 1992.)

of the two retinal ganglion cells shown are similar to those of the bipolar cells immediately above them in the ﬁgure, but now with superimposed action potentials. The two retinal ganglion cells shown in the ﬁgure have different responses and transmit different sequences of action potentials. G2 ﬁres while the light is on, and G1 ﬁres when it turns off. These are called ON and OFF responses, respectively. The optic nerve conducts the output spike trains of retinal ganglion cells to the lateral geniculate nucleus of the thalamus, which acts as a relay station between the retina and primary visual cortex (ﬁgure 2.5). Prior to arriving at the LGN, some retinal ganglion cell axons cross the midline at the optic chiasm. This allows the left and right sides of the visual ﬁelds from both eyes to be represented on the right and left sides of the brain, respectively (ﬁgure 2.5).
Neurons in the retina, LGN, and primary visual cortex respond to light stimuli in restricted regions of the visual ﬁeld called their receptive ﬁelds. Patterns of illumination outside the receptive ﬁeld of a given neuron cannot generate a response directly, although they can signiﬁcantly affect responses to stimuli within the receptive ﬁeld. We do not consider such effects, although they are of considerable experimental and theoretical interest. In the monkey, cortical receptive ﬁelds range in size from around a tenth of a degree near the fovea to several degrees in the periphery. Within the receptive ﬁelds, there are regions where illumination higher than the background light intensity enhances ﬁring, and other regions where lower illumination enhances ﬁring. The spatial arrangement of these regions determines the selectivity of the neuron to different inputs. The term “receptive ﬁeld” is often generalized to refer not only to the overall region where light affects neuronal ﬁring, but also to the spatial and temporal structure within this region.
Visually responsive neurons in the retina, LGN, and primary visual cortex are divided into two classes, depending on whether or not the contribu-

ON and OFF responses
receptive ﬁelds

simple and complex cells

54

Reverse Correlation and Visual Receptive Fields

tions from different locations within the visual ﬁeld sum linearly. X cells in the cat retina and LGN, P cells in the monkey retina and LGN, and simple cells in primary visual cortex appear to satisfy this assumption. Other neurons, such as Y cells in the cat retina and LGN, M cells in the monkey retina and LGN, and complex cells in primary visual cortex, do not show linear summation across the spatial receptive ﬁeld, and nonlinearities must be included in descriptions of their responses. We do this for complex cells later in this chapter.
A ﬁrst step in studying the selectivity of any neuron is to identify the types of stimuli that evoke strong responses. Retinal ganglion cells and LGN neurons have similar selectivities and respond best to circular spots of light surrounded by darkness or dark spots surrounded by light. In primary visual cortex, many neurons respond best to elongated light or dark bars or to boundaries between light and dark regions. Gratings with alternating light and dark bands are effective and frequently used stimuli for these neurons.
Many visually responsive neurons react strongly to sudden transitions in the level of image illumination, a temporal analogue of their responsiveness to light-dark spatial boundaries. Static images are not very effective at evoking visual responses. In awake animals, images are constantly kept in motion across the retina by eye movements. In experiments in which the eyes are ﬁxed, moving light bars and gratings, or gratings undergoing periodic light-dark reversals (called counterphase gratings) are more effective stimuli than static images. Some neurons in primary visual cortex are directionally selective; they respond more strongly to stimuli moving in one direction than in the other.
To streamline the discussion in this chapter, we consider only gray-scale images, although the methods presented can be extended to include color. We also restrict the discussion to two-dimensional visual images, ignoring how visual responses depend on viewing distance and encode depth. In discussing the response properties of retinal, LGN, and V1 neurons, we do not follow the path of the visual signal, nor the historical order of experimentation, but instead begin with primary visual cortex and then move back to the LGN and retina. In this chapter, the emphasis is on properties of individual neurons; we discuss encoding by populations of visually responsive neurons in chapter 10.

The Retinotopic Map
A striking feature of most visual areas in the brain, including primary visual cortex, is that the visual world is mapped onto the cortical surface in a topographic manner. This means that neighboring points in a visual image evoke activity in neighboring regions of visual cortex. The retinotopic map refers to the transformation from the coordinates of the visual world to the corresponding locations on the cortical surface.

2.3 Introduction to the Early Visual System

55

A

B

¯a
F

x y

¯a
F

Figure 2.6 (A) Two coordinate systems used to parameterize image location. Each rectangle represents a tangent screen, and the ﬁlled circle is the location of a particular image point on the screen. The upper panel shows polar coordinates. The origin of the coordinate system is the ﬁxation point F, the eccentricity ǫ is proportional to the radial distance from the ﬁxation point to the image point, and a is the angle between the radial line from F to the image point and the horizontal axis. The lower panel shows Cartesian coordinates. The location of the origin for these coordinates and the orientation of the axes are arbitrary. They are usual chosen to center and align the coordinate system with respect to a particular receptive ﬁeld being studied. (B) A bull’s-eye pattern of radial lines of constant azimuth, and circles of constant eccentricity. The center of this pattern at zero eccentricity is the ﬁxation point F. Such a pattern was used to generate the image in ﬁgure 2.7A.
Objects located a ﬁxed distance from one eye lie on a sphere. Locations on this sphere can be represented using the same longitude and latitude angles used for the surface of the earth. Typically, the “north pole” for this spherical coordinate system is located at the ﬁxation point, the image point that focuses onto the fovea or center of the retina. In this system of coordinates (ﬁgure 2.6), the latitude coordinate is called the eccentricity, ǫ, and the longitude coordinate, measured from the horizontal meridian, is called the azimuth, a. In primary visual cortex, the visual world is split in half, with the region −90◦ ≤ a ≤ +90◦ for ǫ from 0◦ to about 70◦ (for both eyes) represented on the left side of the brain, and the reﬂection of this region about the vertical meridian represented on the right side of the brain.
In most experiments, images are displayed on a ﬂat screen (called a tangent screen) that does not coincide exactly with the sphere discussed in the previous paragraph. However, if the screen is not too large, the difference is negligible, and the eccentricity and azimuth angles approximately coincide with polar coordinates on the screen (ﬁgure 2.6A). Ordinary Cartesian coordinates can also be used to identify points on the screen (ﬁgure 2.6A). The eccentricity ǫ and the x and y coordinates of the Cartesian system are based on measuring distances on the screen. However, it is customary to divide these measured distances by the distance from the eye to the screen and to multiply the result by 180◦/π so that these coordinates are ultimately expressed in units of degrees. This makes sense because it is the angular, not the absolute, size and location of an image that is typically relevant for studies of the visual system.

eccentricity ǫ azimuth a

cortical magniﬁcation factor

56

Reverse Correlation and Visual Receptive Fields

A

¯ ½Æ ¯ ¾ ¿Æ ¯

Æ

B
2

1

0

¯ ½Æ ¯ ¾Æ

¯Æ

¯

Æ

¯ ½¼Æ

¼Æ ¼Æ

Y (cm)

1 cm

-1

· ¼Æ

-2

0

1

2

3

X (cm)

Figure 2.7 (A) An autoradiograph of the posterior region of the primary visual cortex from the left side of a macaque monkey brain. The pattern is a radioactive trace of the activity evoked by an image like that in ﬁgure 2.6B. The vertical lines correspond to circles at eccentricities of 1◦, 2.3◦, and 5.4◦, and the horizontal lines (from top to bottom) represent radial lines in the visual image at a values of −90◦, −45◦, 0◦, 45◦, and 90◦. Only the part of cortex corresponding to the central region of the visual ﬁeld on one side is shown. (B) The mathematical map from the visual coordinates ǫ and a to the cortical coordinates X and Y described by equations 2.15 and 2.17. (A adapted from Tootell et al., 1982.)

Figure 2.7A shows a dramatic illustration of the retinotopic map in the primary visual cortex of a monkey. The pattern on the cortex seen in ﬁgure 2.7A was produced by imaging a radioactive analogue of glucose that was taken up by active neurons while a monkey viewed a visual image consisting of concentric circles and radial lines, similar to the pattern in ﬁgure 2.6B. The vertical lines correspond to the circles in the image, and the roughly horizontal lines are due to the activity evoked by the radial lines. The fovea is represented at the leftmost pole of this piece of cortex, and eccentricity increases toward the right. Azimuthal angles are positive in the lower half of the piece of cortex shown, and negative in the upper half.
To describe the map in ﬁgure 2.7A mathematically, we write the horizontal and vertical coordinates, X and Y, describing points on the cortical surface as functions of the eccentricity ǫ and azimuth a of the corresponding points in the visual ﬁeld, X(ǫ, a), Y(ǫ, a). This map is characterized by local factors, each called a cortical magniﬁcation factor, that indicate the relationship between small displacements X, Y across the cortex and the corresponding small image displacements ǫ, a. In general, these factors can be derived from the four elements of the Jacobian matrix, ∂X/∂ǫ, ∂X/∂a, ∂Y/∂ǫ, and ∂Y/∂a. However, few experiments characterize all four elements, and it is common to include additional constraints.
Figure 2.7B shows an example of such a map. Here, we assume that X(ǫ) is only a function of eccentricity, and that Y(ǫ, a) is proportional to the azimuth angle a. Further, we assume that purely radial ( a = 0) and purely

2.3 Introduction to the Early Visual System

57

meridional ( ǫ = 0) displacements have the same cortical magniﬁcation factor M(ǫ), which itself is only a function of eccentricity. Consider two nearby image points with coordinates ǫ, a and ǫ + ǫ, a, separated by an angular distance ǫ. The distance separating the activity evoked by these two image points on the cortex is X. By the deﬁnition of the cortical magniﬁcation factor, these two quantities satisfy X = M(ǫ) ǫ or, taking the limit as X and ǫ go to 0,

dX dǫ

=

M(ǫ) .

For the macaque monkey, results such as ﬁgure 2.7A suggest that

(2.13)

M(ǫ)

=

λ ǫ0 +

ǫ

,

(2.14)

with λ ≈ 12 mm and ǫ0 ≈ 1◦. Integrating equation 2.13 and deﬁning X = 0 to be the point representing ǫ = 0, we ﬁnd

X = λ ln(1 + ǫ/ǫ0) .

(2.15)

For purely meridional displacements, the angular distance between two points at eccentricity ǫ with an azimuthal angle difference a is aǫπ/180◦. Here, the factor of ǫ corrects for the increase of arc length as a function of eccentricity, and the factor of π/180◦ converts ǫ from degrees to radians. The separation on the cortex, Y, corresponding to these points has a magnitude given by the cortical ampliﬁcation times this distance. Taking the limit a → 0, we ﬁnd that

dY da

=

−

ǫπ 180◦

M(ǫ) .

(2.16)

The minus sign in this relationship appears because the visual ﬁeld is inverted on the cortex. Solving equation 2.16 gives

Y

=

−

(ǫ0

λǫaπ + ǫ)180◦

.

(2.17)

The map deﬁned by equations 2.15 and 2.17 is only approximate, particularly for small eccentricities. It is also not isotropic, which means that the magniﬁcation factor M(ǫ) only describes displacements for which either
ǫ = 0 or a = 0. Nevertheless, ﬁgure 2.7B shows that these coordinates agree fairly well with the map in ﬁgure 2.7A.

For eccentricities appreciably greater than 1◦, equations 2.15 and 2.17 reduce to X ≈ λ ln(ǫ/ǫ0 ) and Y ≈ −λπa/180◦. These two formulas can be combined by deﬁning the complex numbers Z = X + iY and z = (ǫ/ǫ0 ) exp(−iπa/180◦ ) (with i equal to the square root of -1) and writing Z =
λ ln(z). For this reason, the cortical map is sometimes called a complex logarithmic map. For an image scaled radially by a factor γ, eccentricities change according to ǫ → γ ǫ while a is unaffected. Scaling of the eccentricity produces a shift X → X + λ ln(γ ) over the range of values where the
simple logarithmic form of the map is valid. The logarithmic transforma-
tion thus causes images that are scaled radially outward on the retina to
be represented at locations on the cortex translated in the X direction.

complex logarithmic map

58

Reverse Correlation and Visual Receptive Fields

Visual Stimuli

contrast

Earlier in this chapter, we used the function s(t) to characterize a timedependent stimulus. The description of visual stimuli is more complex. Gray-scale images appearing on a two-dimensional surface, such as a video monitor, can be described by giving the luminance, or light intensity, at each point on the screen. These pixel locations are parameterized by Cartesian coordinates x and y, as in the lower panel of ﬁgure 2.6A. However, pixel-by-pixel light intensities are not a useful way of parameterizing a visual image for the purposes of characterizing neuronal responses. This is because visually responsive neurons, like many sensory neurons, adapt to the overall level of screen illumination. To avoid dealing with adaptation effects, we describe the stimulus by a function s(x, y, t) that is proportional to the difference between the luminance at the point (x, y) at time t and the average or background level of luminance. Often s(x, y, t) is also divided by the background luminance level, making it dimensionless. The resulting quantity is called the contrast.

counterphase sinusoidal grating

During recordings, visual neurons are usually stimulated by images that vary over both space and time. A commonly used stimulus, the counterphase sinusoidal grating, is described by

s(x, y, t) = A cos Kx cos + Ky sin − cos(ωt) .

(2.18)

spatial frequency K frequency ω orientation spatial phase amplitude A

Figure 2.8 shows a similar grating (a spatial square wave is drawn rather than a sinusoid) and illustrates the signiﬁcance of the parameters K, , , and ω. K and ω are the spatial and temporal frequencies of the grating (these are angular frequencies), is its orientation, is its spatial phase, and A is its contrast amplitude. This stimulus oscillates in both space and time. At any ﬁxed time, it oscillates in the direction perpendicular to the orientation angle as a function of position, with wavelength 2π/K (ﬁgure 2.8A). At any ﬁxed position, it oscillates in time with period 2π/ω (ﬁgure 2.8B). For convenience, is measured relative to the y axis rather than the x axis, so that a stimulus with = 0 varies in the x, but not in the y, direction. determines the spatial location of the light and dark stripes of the grating. Changing by an amount shifts the grating in the direction perpendicular to its orientation by a fraction /2π of its wavelength. The contrast amplitude A controls the maximum degree of difference between light and dark areas. Because x and y are measured in degrees, K is expressed in the rather unusual units of radians per degree and K/2π is typically reported in units of cycles per degree. has units of radians, ω is in radians/s, and ω/2π is in Hz.

white-noise image

Experiments that consider reverse correlation and spike-triggered averages use various types of random and white-noise stimuli in addition to bars and gratings. A white-noise stimulus, in this case, is one that is uncorrelated in both space and time so that

1 T

T
dt s(x, y, t)s(x′, y′, t + τ ) = σs2δ(τ )δ(x − x′ )δ( y − y′ ) .
0

(2.19)

2.3 Introduction to the Early Visual System

59

A

Θ

B

¾

y

s

0

¾Ã

x

t

Figure 2.8 A counterphase grating. (A) A portion of a square-wave grating analogous to the sinusoidal grating of equation 2.18. The lighter stripes are regions where s > 0, and s < 0 within the darker stripes. K determines the wavelength of the grating and , its orientation. Changing its spatial phase, , shifts the entire light-dark pattern in the direction perpendicular to the stripes. (B) The light-dark intensity at any point of the spatial grating oscillates sinusoidally in time with period 2π/ω.

Of course, in practice a discrete approximation of such a stimulus must be used by dividing the image space into pixels and time into small bins. In addition, more structured random sets of images (randomly oriented bars, for example) are sometimes used to enhance the responses obtained during stimulation.

The Nyquist Frequency

Many factors limit the maximal spatial frequency that can be resolved by the visual system, but one interesting effect arises from the size and spacing of individual photoreceptors on the retina. The region of the retina with the highest resolution is the fovea at the center of the visual ﬁeld. Within the macaque or human fovea, cone photoreceptors are densely packed in a regular array. Along any direction in the visual ﬁeld, a regular array of tightly packed photoreceptors of size x samples points at locations m x for m = 1, 2, . . .. The (angular) frequency that deﬁnes the resolution of such an array is called the Nyquist frequency and is given by

Knyq =

π x

.

(2.20)

To understand the signiﬁcance of the Nyquist frequency, consider sampling two cosine gratings with spatial frequencies of K and 2Knyq−K, with K < Knyq. These are described by s = cos(Kx) and s = cos((2Knyq−K)x). At the sampled points, these functions are identical because cos((2Knyq − K)m x) = cos(2πm − Km x) = cos(−Km x) = cos(Km x) by the
periodicity and evenness of the cosine function (see ﬁgure 2.9). As a result,
these two gratings cannot be distinguished by examining them only at the sampled points. Any two spatial frequencies K < Knyq and 2Knyq − K

Nyquist frequency

60

Reverse Correlation and Visual Receptive Fields

cos(πx/6) or cos(πx/2)

1.0

0.5

0.0

-0.5

-1.0

0

3

6

9

12

x

Figure 2.9 Aliasing and the Nyquist frequency. The two curves are the functions
cos(πx/6) and cos(πx/2) plotted against x, and the dots show points sampled with a spacing of x = 3. The Nyquist frequency in this case is π/3, and the two
cosine curves match at the sampled points because their spatial frequencies satisfy the relation 2π/3 − π/6 = π/2.

can be confused with one another in this way, a phenomenon known as aliasing. Conversely, if an image is constructed solely of frequencies less
than Knyq, it can be reconstructed perfectly from the ﬁnite set of samples provided by the array. There are 120 cones per degree at the fovea of the macaque retina, which makes Knyq/(2π) = 1/(2 x) = 60 cycles per degree. In this result, we have divided the right side of equation 2.20, which gives Knyq in units of radians per degree, by 2π to convert the answer to cycles per degree.

2.4 Reverse-Correlation Methods: Simple Cells

The spike-triggered average for visual stimuli is deﬁned, as in chapter 1, as the average over trials of stimuli evaluated at times ti − τ, where ti for i = 1, 2, . . . , n are the spike times. Because the light intensity of a visual
image depends on location as well as time, the spike-triggered average
stimulus is a function of three variables,

C(x, y, τ) =

1 n

n
s(x, y, ti − τ) .
i=1

(2.21)

Here, as in chapter 1, the brackets denote trial averaging, and we have used the approximation 1/ n ≈ 1/ n . C(x, y, τ ) is the average value of
the visual stimulus at the point (x, y) a time τ before a spike was ﬁred.
Similarly, we can deﬁne the correlation function between the ﬁring rate at time t and the stimulus at time t + τ, for trials of duration T, as

Qrs (x,

y, τ)

=

1 T

T
dt r(t)s(x, y, t + τ) .
0

(2.22)

2.4 Reverse-Correlation Methods: Simple Cells

61

The spike-triggered average is related to the reverse-correlation function, as discussed in chapter 1, by

C(x, y, τ)

=

Qrs(x, y, −τ ) r

,

(2.23)

where r is, as usual, the average ﬁring rate over the entire trial, r = n /T.

To estimate the ﬁring rate of a neuron in response to a particular image, we add a function of the output of a linear ﬁlter of the stimulus to the background ﬁring rate r0, as in equation 2.8, rest(t) = r0 + F (L(t)). As in equation 2.7, the linear estimate L(t) is obtained by integrating over the past history of the stimulus with a kernel acting as the weighting function. Because visual stimuli depend on spatial location, we must decide how contributions from different image locations are to be combined to determine L(t). The simplest assumption is that the contributions from different spatial points sum linearly, so that L(t) is obtained by integrating over all x and y values:

∞
L(t) = dτ dxdy D(x, y, τ)s(x, y, t − τ) .
0

(2.24)

The kernel D(x, y, τ ) determines how strongly, and with what sign, the

visual stimulus at the point (x, y) and at time t − τ affects the ﬁring

rate of the neuron at time t. As in equation 2.6, the optimal kernel is

given in terms of the ﬁring rate-stimulus correlation function, or the spike-

triggered average, for a white-noise stimulus with variance parameter σs2

by

D(x, y, τ)

=

Qrs(x, y, −τ ) σs2

=

r

C(x, y, τ) σs2

.

(2.25)

The kernel D(x, y, τ ) deﬁnes the space-time receptive ﬁeld of a neuron. Because D(x, y, τ ) is a function of three variables, it can be difﬁcult to measure and visualize. For some neurons, the kernel can be written as a product of two functions, one that describes the spatial receptive ﬁeld and the other, the temporal receptive ﬁeld,

D(x, y, τ) = Ds(x, y)Dt(τ) .

(2.26)

Such neurons are said to have separable space-time receptive ﬁelds. Separability requires that the spatial structure of the receptive ﬁeld not change over time except by an overall multiplicative factor. When D(x, y, τ ) cannot be written as the product of two terms, the neuron is said to have a nonseparable space-time receptive ﬁeld. Given the freedom in equation 2.8 to set the scale of D (by suitably adjusting the function F), we typically normalize Ds so that its integral is 1, and use a similar rule for the components from which Dt is constructed. We begin our analysis by studying ﬁrst the spatial and then the temporal components of a separable space-time receptive ﬁeld, and then proceed to the nonseparable case. For simplicity, we ignore the possibility that cells can have slightly different receptive ﬁelds for the two eyes, which underlies the disparity tuning considered in chapter 1.

linear response estimate
space-time receptive ﬁeld
separable receptive ﬁeld nonseparable receptive ﬁeld

62

Reverse Correlation and Visual Receptive Fields

Spatial Receptive Fields

Gabor function
rf size σx, σy preferred spatial frequency k preferred spatial phase φ

Figures 2.10A and C show the spatial structure of spike-triggered average stimuli for two simple cells in the primary visual cortex of a cat (area 17) with approximately separable space-time receptive ﬁelds. These receptive ﬁelds are elongated in one direction. There are some regions within the receptive ﬁeld where Ds is positive, called ON regions, and others where it is negative, called OFF regions. The integral of the linear kernel times the stimulus can be visualized by noting how the OFF (black) and ON (white) regions overlap the image (see ﬁgure 2.11) . The response of a neuron is enhanced if ON regions are illuminated (s > 0) or if OFF regions are darkened (s < 0) relative to the background level of illumination. Conversely, they are suppressed by darkening ON regions or illuminating OFF regions. As a result, the neurons of ﬁgures 2.10A and C respond most vigorously to light-dark edges positioned along the border between the ON and OFF regions, and oriented parallel to this border and to the elongated direction of the receptive ﬁelds (ﬁgure 2.11). Figures 2.10 and 2.11 show receptive ﬁelds with two major subregions. Simple cells are found with from one to ﬁve subregions. Along with the ON-OFF patterns we have seen, another typical arrangement is a three-lobed receptive ﬁeld with OFF-ON-OFF or ON-OFF-ON subregions.
A mathematical approximation of the spatial receptive ﬁeld of a simple cell is provided by a Gabor function, which is a product of a Gaussian function and a sinusoidal function. Gabor functions are by no means the only functions used to ﬁt spatial receptive ﬁelds of simple cells. For example, gradients of Gaussians are sometimes used. However, we will stick to Gabor functions, and to simplify the notation, we choose the coordinates x and y so that the borders between the ON and OFF regions are parallel to the y axis. We also place the origin of the coordinates at the center of the receptive ﬁeld. With these choices, we can approximate the observed receptive ﬁeld structures using the Gabor function

Ds ( x ,

y)

=

1 2πσxσy

exp

−

x2 2σx2

−

y2

2

σ

2 y

cos(kx − φ) .

(2.27)

The parameters in this function determine the properties of the spatial receptive ﬁeld: σx and σy determine its extent in the x and y directions, respectively; k, the preferred spatial frequency, determines the spacing of light and dark bars that produce the maximum response (the preferred spatial wavelength is 2π/ k); and φ is the preferred spatial phase, which determines where the ON-OFF boundaries fall within the receptive ﬁeld. For this spatial receptive ﬁeld, the sinusoidal grating described by equation 2.18 that produces the maximum response for a ﬁxed value of A has K = k, = φ, and = 0.
Figures 2.10B and 2.10D show Gabor functions chosen speciﬁcally to match the data in ﬁgures 2.10A and 2.10C. Figure 2.12 shows x and y plots of a variety of Gabor functions with different parameter values. As

2.4 Reverse-Correlation Methods: Simple Cells

63

A

B

Ds
0

-4

-2

0

2

Ü ´ Ö ×µ

0
4 -5 Ý ´

5 ×µ
Ö

C

D

Ds
0

-4

-2

0

2

Ü ´ Ö ×µ

5

0

×µ

4

-5
Ý´

Ö

Figure 2.10 Spatial receptive ﬁeld structure of simple cells. (A) and (C) Spatial structure of the receptive ﬁelds of two neurons in cat primary visual cortex determined by averaging stimuli between 50 ms and 100 ms prior to an action potential. The upper plots are three-dimensional representations, with the horizontal dimensions acting as the x-y plane and the vertical dimension indicating the magnitude and sign of Ds(x, y). The lower contour plots represent the x-y plane. Regions with solid contour curves are ON areas where Ds (x, y) > 0, and regions with dashed contours are OFF areas where Ds(x, y) < 0. (B) and (D) Gabor functions (equation 2.27) with σx = 1◦, σy = 2◦, 1/ k = 0.56◦, and φ = 1 − π/2 (B) or φ = 1 − π (D), chosen to match the receptive ﬁelds in A and C. (A and C adapted from Jones and Palmer, 1987a.)

64 A
y

Reverse Correlation and Visual Receptive Fields

B

C

bandwidth

x
Figure 2.11 Grating stimuli superimposed on spatial receptive ﬁelds similar to those shown in ﬁgure 2.10. The receptive ﬁeld is shown as two oval regions, one dark to represent an OFF area where Ds < 0 and one white to denote an ON region where Ds > 0. (A) A grating with the spatial wavelength, orientation, and spatial phase shown produces a high ﬁring rate because a dark band completely overlaps the OFF area of the receptive ﬁeld and a light band overlaps the ON area. (B) The grating shown is nonoptimal due to a mismatch in both the spatial phase and frequency, so that the ON and OFF regions each overlap both light and dark stripes. (C) The grating shown is at a nonoptimal orientation because each region of the receptive ﬁeld overlaps both light and dark stripes.

seen in ﬁgure 2.12, Gabor functions can have various types of symme-
try, and variable numbers of signiﬁcant oscillations (or subregions) within
the Gaussian envelope. The number of subregions within the receptive ﬁeld is determined by the product kσx and is typically expressed in terms of a quantity known as the bandwidth b. The bandwidth is deﬁned as b = log2 (K+ /K− ), where K+ > k and K− < k are the spatial frequencies of gratings that produce one-half the response amplitude of a grating with K = k. High bandwidths correspond to low values of kσx, meaning that the receptive ﬁeld has few subregions and poor spatial frequency selectiv-
ity. Neurons with more subﬁelds are more selective to spatial frequency, and they have smaller bandwidths and larger values of kσx.

The bandwidth is the width of the spatial frequency tuning curve mea-

sured in octaves. The spatial frequency tuning curve as a function of K for

a Gabor receptive ﬁeld with preferred spatial frequency k and receptive

ﬁeld width σx is proportional to exp(−σx2 (k − K)2 /2) (see equation 2.34
below). The values of K+ and K− needed to compute the bandwidth are thus determined by the condition exp(−σx2 (k − K± )2 /2) = 1/2. Solving this equation gives K± = k ± (2 ln(2))1/2 /σx, from which we obtain

√

b = log2

kσx + √2 ln(2) kσx − 2 ln(2)

or kσx =

2 ln(2)

2b 2b

+1 −1

.

(2.28)

Bandwidth is deﬁned only if kσx > (2 ln(2))1/2 , but this is usually the case. Bandwidths typically range from about 0.5 to 2.5, corresponding to kσx between 1.7 and 6.9.

The response characterized by equation 2.27 is maximal if light-dark edges are parallel to the y axis, so the preferred orientation angle is 0. An arbitrary preferred orientation, θ, can be created by rotating the coordinates,

2.4 Reverse-Correlation Methods: Simple Cells

65

2 x yDsºx 0» 2 x yDsº0 y»

A

B

0.8 0.8
0.4 0.4
0.0

0.0

-0.4

-0.4

-0.8

-2 0 2
x (degrees)

-2 0 2
x (degrees)

C
1.0 0.5 0.0 -0.5
-2 0 2
x (degrees)

D
1.0 0.8 0.6 0.4 0.2 0.0
-4 0 4
y (degrees)

Figure 2.12 Gabor functions of the form given by equation 2.27. For convenience we plot the dimensionless function 2πσxσy Ds. (A) A Gabor function with σx = 1◦, 1/ k = 0.5◦, and φ = 0 plotted as a function of x for y = 0. This function is symmetric about x = 0. (B) A Gabor function with σx = 1◦, 1/ k = 0.5◦, and φ = π/2 plotted as a function of x for y = 0. This function is antisymmetric about x = 0 and corresponds to using a sine instead of a cosine function in equation 2.27. (C) A Gabor function with σx = 1◦, 1/ k = 0.33◦, and φ = π/4 plotted as a function of x for y = 0. This function has no particular symmetry properties with respect to x = 0. (D) The Gabor function of equation 2.27 with σy = 2◦ plotted as a function of y for x = 0. This function is simply a Gaussian.

making the substitutions x → x cos(θ) + y sin(θ) and y → y cos(θ) −
x sin(θ) in equation 2.27. This produces a spatial receptive ﬁeld that is maximally responsive to a grating with = θ. Similarly, a receptive ﬁeld
centered at the point (x0 , y0 ) rather than at the origin can be constructed by making the substitutions x → x − x0 and y → y − y0.

preferred orientation θ
rf center x0, y0

Temporal Receptive Fields
Figure 2.13 reveals the temporal development of the space-time receptive ﬁeld of a neuron in the cat primary visual cortex through a series of snapshots of its spatial receptive ﬁeld. More than 300 ms prior to a spike, there is little correlation between the visual stimulus and the upcoming spike. Around 210 ms before the spike (τ = 210 ms), a two-lobed OFF-ON receptive ﬁeld, similar to the ones in ﬁgure 2.10, is evident. As τ decreases (recall that τ measures time in a reversed sense), this structure ﬁrst fades away and then reverses, so that the receptive ﬁeld 75 ms before a spike has the opposite sign from what appeared at τ = 210 ms. Due to latency effects, the spatial structure of the receptive ﬁeld is less signiﬁcant for τ < 75 ms. The stimulus preferred by this cell is thus an appropriately aligned dark-light boundary that reverses to a light-dark boundary over time.
Reversal effects like those seen in ﬁgure 2.13 are a common feature of space-time receptive ﬁelds. Although the magnitudes and signs of the different spatial regions in ﬁgure 2.13 vary over time, their locations and shapes remain fairly constant. This indicates that the neuron has, to a good approximation, a separable space-time receptive ﬁeld. When a space-time receptive ﬁeld is separable, the reversal can be described by a function Dt(τ ) that rises from 0, becomes positive, then negative, and ultimately

66

Reverse Correlation and Visual Receptive Fields

τ = 255 ms 5

210 ms

165 ms

120 ms

75 ms

30 ms

y (degrees)

00 x (degrees) 5

Figure 2.13 Temporal evolution of a spatial receptive ﬁeld. Each panel is a plot
of D(x, y, τ ) for a different value of τ. As in ﬁgure 2.10, regions with solid con-
tour curves are areas where D(x, y, τ ) > 0 and regions with dashed contours have
D(x, y, τ ) < 0. The curves below the contour diagrams are one-dimensional plots
of the receptive ﬁeld as a function of x alone. The receptive ﬁeld is maximally different from 0 for τ = 75 ms with the spatial receptive ﬁeld reversed from what it was at τ = 210 ms. (Adapted from DeAngelis et al., 1995.)

8 6 4 2

Dt (Hz)

300

250

200

150

100

50

τ (ms)

-2

-4

Figure 2.14 Temporal structure of a receptive ﬁeld. The function Dt (τ ) of equation 2.29 with α = 1/(15 ms).

returns to 0 as τ increases. Adelson and Bergen (1985) proposed the function shown in ﬁgure 2.14,

Dt(τ) = α exp(−ατ)

(ατ)5 − (ατ)7

5!

7!

,

(2.29)

for τ ≥ 0, and Dt(τ ) = 0 for τ < 0. Here, α is a constant that sets the scale for the temporal development of the function. Single-phase responses are also seen for V1 neurons, and these can be described by eliminating the second term in equation 2.29. Three-phase responses, which are sometimes seen, must be described by a more complicated function.

Response of a Simple Cell to a Counterphase Grating

The response of a simple cell to a counterphase grating stimulus (equation 2.18) can be estimated by computing the function L(t). For the separable receptive ﬁeld given by the product of the spatial factor in equation 2.27 and the temporal factor in 2.29, the linear estimate of the response can be written as the product of two terms,

L(t) = LsLt(t) ,

(2.30)

2.4 Reverse-Correlation Methods: Simple Cells

67

A
0.4
Ls 0.2

B
0.4 0.2

0.0

0.0

-1.0 0.0 1.0

0

Θ

1

2

K/k

C
0.5

0.0

-0.5

3

-2

0

2

Φ

Figure 2.15 Selectivity of a Gabor ﬁlter with θ = φ = 0, σx = σy = σ, and kσ = 2 acting on a cosine grating with A = 1. (A) Ls as a function of stimulus orientation
for a grating with the preferred spatial frequency and phase, K = k and = 0.
(B) Ls as a function of the ratio of the stimulus spatial frequency to its preferred value, K/ k, for a grating oriented in the preferred direction = 0 and with the preferred phase = 0. (C) Ls as a function of stimulus spatial phase for a grating with the preferred spatial frequency and orientation, K = k and = 0.

where

Ls = dxdy Ds(x, y)A cos Kx cos( ) + Ky sin( ) −

(2.31)

and

∞

Lt(t) = dτ Dt(τ) cos (ω(t − τ)) .

(2.32)

0

The reader is invited to compute these integrals for the case σx = σy = σ. To show the selectivity of the resulting spatial receptive ﬁelds, we plot (in

ﬁgure 2.15) Ls as functions of the parameters , K, and that determine the orientation, spatial frequency, and spatial phase of the stimulus. It is

also instructive to write out Ls for various special parameter values. First, if the spatial phase of the stimulus and the preferred spatial phase of the

receptive ﬁeld are 0 ( = φ = 0), we ﬁnd that

Ls = A exp

− σ2 (k2 + K2 ) 2

cosh σ2kK cos(

),

(2.33)

which determines the orientation and spatial frequency tuning for an op-
timal spatial phase. Second, for a grating with the preferred orientation = 0 and a spatial frequency that is not too small, the full expression for Ls can be simpliﬁed by noting that exp(−σ2 kK) ≈ 0 for the values of kσ normally encountered (for example, if K = k and kσ = 2, exp(−σ2 kK) = 0.02). Using this approximation, we ﬁnd

Ls

=

A 2

exp

− σ2(k − K)2 2

cos(φ −

),

(2.34)

which reveals a Gaussian dependence on spatial frequency and a cosine dependence on spatial phase.

The amplitude of the sinusoidally oscillating linear response estimate (equation 2.32) is plotted as a function of the temporal frequency of the

68

Reverse Correlation and Visual Receptive Fields

amplitude

0.5 0.4 0.3 0.2 0.1 0.0
0

5

10

15

20

frequency (Hz)

Figure 2.16 Frequency response of a model simple cell based on the temporal ker-
nel of equation 2.29. The amplitude of the sinusoidal oscillations of Lt (t) produced by a counterphase grating is plotted as a function of the temporal oscillation fre-
quency, ω/2π.

A

B

0

D
0

´Ñ×µ

250
0 Ü ´ Ö ×µ 6

-2

-1
Ü´

0
Ö

1
×µ

20

200 150
50 100 ´Ñ×µ

Figure 2.17 A separable space-time receptive ﬁeld. (A) An x-τ plot of an approximately separable space-time receptive ﬁeld from cat primary visual cortex. OFF regions are shown with dashed contour lines and ON regions with solid contour lines. The receptive ﬁeld has side-by-side OFF and ON regions that reverse as a function of τ. (B) Mathematical description of the space-time receptive ﬁeld in A constructed by multiplying a Gabor function (evaluated at y = 0) with σx = 1◦, 1/ k = 0.56◦, and φ = π/2 by the temporal kernel of equation 2.29 with 1/α = 15 ms. (A adapted from DeAngelis et al., 1995.)

stimulus (ω/2π rather than the angular frequency ω) in ﬁgure 2.16. The peak value around 4 Hz and roll-off above 10 Hz are typical for V1 neurons and for cortical neurons in other primary sensory areas as well.

Space-Time Receptive Fields
To display the function D(x, y, τ ) in a space-time plot rather than as a sequence of spatial plots (as in ﬁgure 2.13), we suppress the y dependence and plot an x-τ projection of the space-time kernel. Figure 2.17A shows a space-time plot of the receptive ﬁeld of a simple cell in the cat primary visual cortex. This receptive ﬁeld is approximately separable, and it has OFF and ON subregions that reverse to ON and OFF subregions as a function of τ, similar to the reversal seen in ﬁgure 2.13. Figure 2.17B shows an

2.4 Reverse-Correlation Methods: Simple Cells

69

A

B

y

t

x

x

Figure 2.18 Space and space-time diagrams of a moving grating. (A) A vertically oriented grating moves to the left on a two-dimensional screen. (B) The space-time diagram of the image in A. The x location of the dark and light bands moves to the left as time progresses upward, representing the motion of the grating.

x-τ plot of a separable space-time kernel, similar to the one in ﬁgure 2.17A, generated by multiplying a Gabor function by the temporal kernel of equation 2.29.
We can also plot the visual stimulus in a space-time diagram, suppressing the y coordinate by assuming that the image does not vary as a function of y. For example, ﬁgure 2.18A shows a grating of vertically oriented stripes moving to the left on an x-y plot. In the x-t plot of ﬁgure 2.18B, this image appears as a series of sloped dark and light bands. These represent the projection of the image in ﬁgure 2.18A onto the x axis evolving as a function of time. The leftward slope of the bands corresponds to the leftward movement of the image.
Most neurons in primary visual cortex do not respond strongly to static images, but respond vigorously to ﬂashed and moving bars and gratings. The receptive ﬁeld structure of ﬁgure 2.17 reveals why this is the case, as is shown in ﬁgures 2.19 and 2.20. The image in ﬁgures 2.19A-C is a dark bar that is ﬂashed on for a brief period of time. To describe the linear response estimate at different times, we consider a space-time receptive ﬁeld similar to the one in ﬁgure 2.17A. The receptive ﬁeld is positioned at three different times in ﬁgures 2.19A, B, and C. The height of the horizontal axis of the receptive ﬁeld diagram indicates the time when the estimation is being made. Figure 2.19A corresponds to an estimate of L(t) at the moment when the image ﬁrst appears. At this time, L(t) = 0. As time progresses, the receptive ﬁeld diagram moves upward. Figure 2.19B generates an estimate at the moment of maximum response, when the dark image overlaps the OFF area of the space-time receptive ﬁeld, producing a positive contribution to L(t). Figure 2.19C shows a later time when the dark image overlaps an ON region, generating a negative L(t). The response for this ﬂashed image is thus transient ﬁring followed by suppression, as shown in Figure 2.19D.
Figures 2.19E and 2.19F show why a static dark bar is an ineffective stimulus. The static bar overlaps both the OFF region for small τ and the re-

70
A
t

Reverse Correlation and Visual Receptive Fields

B

C

D

E

F

t

L(t) L(t)

x - location of bar

x

Figure 2.19 Responses to dark bars estimated from a separable space-time receptive ﬁeld. Dark ovals in the receptive ﬁeld diagrams are OFF regions and light circles are ON regions. The linear estimate of the response at any time is determined by positioning the receptive ﬁeld diagram so that its horizontal axis matches the time of response estimation and noting how the OFF and ON regions overlap with the image. (A-C) The image is a dark bar that is ﬂashed on for a short interval of time. There is no response (A) until the dark image overlaps the OFF region (B) when L(t) > 0. The response is later suppressed when the dark bar overlaps the ON region (C) and L(t) < 0. (D) A plot of L(t) versus time corresponding to the responses generated in A-C. Time runs vertically in this plot, and L(t) is plotted horizontally with the dashed line indicating the zero axis and positive values plotted to the left. (E) The image is a static dark bar. The bar overlaps both an OFF and an ON region, generating opposing positive and negative contributions to L(t). (F) The weak response corresponding to E, plotted as in D.

versed ON region for large τ, generating opposing positive and negative contributions to L(t). The ﬂashed dark bar of ﬁgures 2.19A-C is a more effective stimulus because there is a time when it overlaps only the OFF region.
Figure 2.20 shows why a moving grating is a particularly effective stimulus. The grating moves to the left in 2.20A-C. At the time corresponding to the positioning of the receptive ﬁeld diagram in 2.20A, a dark band stimulus overlaps both OFF regions and light bands overlap both ON regions. Thus, all four regions contribute positive amounts to L(t). As time progresses and the receptive ﬁeld moves upward in the ﬁgure, the alignment will sometimes be optimal, as in 2.20A, and sometimes nonoptimal, as in 2.20B. This produces an L(t) that oscillates as a function of time between positive and negative values (2.20C). Figures 2.20D-F show that a neuron with this receptive ﬁeld responds equally to a grating moving to the right. Like the left-moving grating in ﬁgures 2.20A-C, the right-moving grating can overlap the receptive ﬁeld in an optimal manner (2.20D), producing a strong response, or in a maximally negative manner (2.20E), producing strong suppression of response, again resulting in an oscillating response (2.20F). Separable space-time receptive ﬁelds can produce responses that are maximal for certain speeds of grating motion, but they are not sensitive to the direction of motion.

2.4 Reverse-Correlation Methods: Simple Cells

A

B

t

71 C

L(t)

x

D

E

F

t

L(t)

x
Figure 2.20 Responses to moving gratings estimated from a separable space-time receptive ﬁeld. The receptive ﬁeld is the same as in ﬁgure 2.19. (A-C) The stimulus is a grating moving to the left. At the time corresponding to A, OFF regions overlap with dark bands and ON regions with light bands, generating a strong response. At the time of the estimate in B, the alignment is reversed, and L(t) is negative. (C) A plot of L(t) versus time corresponding to the responses generated in A-B. Time runs vertically in this plot and L(t) is plotted horizontally, with the dashed line indicating the zero axis and positive values plotted to the left. (D-F) The stimulus is a grating moving to the right. The responses are identical to those in A-C.

Nonseparable Receptive Fields

Many neurons in primary visual cortex are selective for the direction of motion of an image. Accounting for direction selectivity requires nonseparable space-time receptive ﬁelds. An example of a nonseparable receptive ﬁeld is shown in ﬁgure 2.21A. This neuron has a three-lobed OFF-ONOFF spatial receptive ﬁeld, and these subregions shift to the left as time moves forward (and τ decreases). This means that the optimal stimulus for this neuron has light and dark areas that move toward the left. One way to describe a nonseparable receptive ﬁeld structure is to use a separable function constructed from a product of a Gabor function for Ds and equation 2.29 for Dt, but to write these as functions of a mixture or rotation of the x and τ variables. The rotation of the space-time receptive ﬁeld, as seen in ﬁgure 2.21B, is achieved by mixing the space and time coordinates, using the transformation

D(x, y, τ ) = Ds(x′, y)Dt(τ′ )

(2.35)

72

Reverse Correlation and Visual Receptive Fields

A
0

B
D
0

´Ñ×µ

200

0 Ü ´ Ö ×µ

6

-3

-2

-1

0

Ü ´ Ö ×µ

1

20

200

150

100

50

´Ñ×µ

Figure 2.21 A nonseparable space-time receptive ﬁeld. (A) An x-τ plot of the spacetime receptive ﬁeld of a neuron from cat primary visual cortex. OFF regions are shown with dashed contour lines and ON regions with solid contour lines. The receptive ﬁeld has a central ON region and two ﬂanking OFF regions that shift to the left over time. (B) Mathematical description of the space-time receptive ﬁeld in A constructed from equations 2.35 - 2.37. The Gabor function used (evaluated at y = 0) had σx = 1◦, 1/ k = 0.5◦, and φ = 0. Dt is given by the expression in equation 2.29 with α = 20 ms, except that the second term, with the seventh power function, was omitted because the receptive ﬁeld does not reverse sign in this example. The x-τ rotation angle used was ψ = π/9, and the conversion factor was c = 0.02 ◦/ms. (A adapted from DeAngelis et al., 1995.)

with

x′ = x cos(ψ) − cτ sin(ψ)

(2.36)

and

τ′

=

τ

cos(ψ)

+

x c

sin(ψ)

.

(2.37)

The factor c converts between the units of time (ms) and space (degrees), and ψ is the space-time rotation angle. The rotation operation is not the only way to generate nonseparable space-time receptive ﬁelds. They are often constructed by adding together two or more separable space-time receptive ﬁelds with different spatial and temporal characteristics.

Figure 2.22 shows how a nonseparable space-time receptive ﬁeld can produce a response that is sensitive to the direction of motion of a grating. Figures 2.22A-C show a left-moving grating and, in 2.22A, the receptive ﬁeld is positioned at a time when a light area of the image overlaps the central ON region and dark areas overlap the ﬂanking OFF regions. This produces a large positive L(t). At other times, the alignment is nonoptimal (2.22B), and over time, L(t) oscillates between large positive and negative values (2.22C). The nonseparable space-time receptive ﬁeld does not overlap optimally with the right-moving grating of ﬁgures 2.22D-F at any time, and the response is correspondingly weaker (2.22F). Thus, a direction selectivity neuron with a nonseparable space-time receptive ﬁeld can be selective for preferred velocity the direction of motion of a grating and for its velocity, responding most vigorously to an optimally spaced grating moving at a velocity given, in terms of the parameters in equation 2.36, by c tan(ψ).

2.4 Reverse-Correlation Methods: Simple Cells

A

B

t

73 C

L(t)

D
t

x

E

F

L(t)

x
Figure 2.22 Responses to moving gratings estimated from a nonseparable spacetime receptive ﬁeld. Dark areas in the receptive ﬁeld diagrams represent OFF regions and light areas, ON regions. (A-C) The stimulus is a grating moving to the left. At the time corresponding to A, OFF regions overlap with dark bands and the ON region overlaps a light band, generating a strong response. At the time of the estimate in B, the alignment is reversed, and L(t) is negative. (C) A plot of L(t) versus time corresponding to the responses generated in A and B. Time runs vertically in this plot, and L(t) is plotted horizontally with the dashed line indicating the zero axis. (D-F) The stimulus is a grating moving to the right. Because of the tilt of the space-time receptive ﬁeld, the alignment with the right-moving grating is never optimal and the response is weak (F).

Static Nonlinearities: Simple Cells

Once the linear response estimate L(t) has been computed, the ﬁring
rate of a visually responsive neuron can be approximated by using equation 2.8, rest(t) = r0 + F(L(t)), where F is an appropriately chosen static nonlinearity. The simplest choice for F consistent with the positive nature of ﬁring rates is rectiﬁcation, F = G[L]+, with G set to ﬁt the magnitude of the measured ﬁring rates. However, this choice makes the ﬁring rate a
linear function of the contrast amplitude, which does not match the data
on the contrast dependence of visual responses. Neural responses saturate
as the contrast of the image increases, and are more accurately described by r ∝ An /( An1/2 + An ) where n is near 2, and A1/2 is a parameter equal to the contrast amplitude that produces a half-maximal response. This led
Heeger (1992) to propose that an appropriate static nonlinearity to use is

contrast saturation

F(L)

=

G [ L ] 2+

A21/2

+

G[

L]

2 +

,

(2.38)

74

Reverse Correlation and Visual Receptive Fields

because this reproduces the observed contrast dependence. A number of variants and extensions of this idea have also been considered, including, for example, that the denominator of this expression should include L factors for additional neurons with nearby receptive ﬁelds. This can account for the effects of visual stimuli outside the “classical” receptive ﬁeld. Discussion of these effects is beyond the scope of this chapter.

2.5 Static Nonlinearities: Complex Cells

spatial-phase invariance

Recall that neurons in primary visual cortex are characterized as simple or complex. While linear methods, such as spike-triggered averages, are useful for revealing the properties of simple cells, at least to a ﬁrst approximation, complex cells display features that are fundamentally incompatible with a linear description. The spatial receptive ﬁelds of complex cells cannot be divided into separate ON and OFF regions that sum linearly to generate the response. Areas where light and dark images excite the neuron overlap, making it difﬁcult to measure and interpret spike-triggered average stimuli. Nevertheless, like simple cells, complex cells are selective to the spatial frequency and orientation of a grating. However, unlike simple cells, complex cells respond to bars of light or dark no matter where they are placed within the overall receptive ﬁeld. Likewise, the responses of complex cells to grating stimuli show little dependence on spatial phase. Thus, a complex cell is selective for a particular type of image independent of its exact spatial position within the receptive ﬁeld. This may represent an early stage in the visual processing that ultimately leads to positioninvariant object recognition.

frequency doubling

Complex cells also have temporal response characteristics that distinguish them from simple cells. Complex cell responses to moving gratings are approximately constant, not oscillatory as in ﬁgures 2.20 and 2.22. The ﬁring rate of a complex cell responding to a counterphase grating oscillating with frequency ω has both a constant component and an oscillatory component with a frequency of 2ω, a phenomenon known as frequency doubling.

Even though spike-triggered average stimuli and reverse-correlation functions fail to capture the response properties of complex cells, complexcell responses can be described, to a ﬁrst approximation, by a relatively straightforward extension of the reverse-correlation approach. The key observation comes from equation 2.34, which shows how the linear response estimate of a simple cell depends on spatial phase for an optimally oriented grating with K not too small. Consider two such responses, labeled L1 and L2, with preferred spatial phases φ and φ − π/2. Including both the spatial and the temporal response factors, we ﬁnd, for preferred spatial phase φ,

L1 = AB(ω, K) cos(φ − ) cos(ωt − δ) ,

(2.39)

2.5 Static Nonlinearities: Complex Cells

75

A
0.2

B
0.2

L12 + L22

0.1

0.1

0.0

0.0

-1.0 0.0 1.0

0

Θ

1

2

K/k

C
0.3

0.2

0.1

0.0

3

-2

0

2

Φ

Figure 2.23 Selectivity of a complex cell model in response to a sinusoidal grat-

ing. The width and preferred spatial frequency of the Gabor functions underlying

the estimated ﬁring rate satisfy kσ = 2. (A) The complex cell response estimate,

L21 + L22, as a function of stimulus orientation for a grating with the preferred

spatial

frequency

K

=

k.

(B)

L21

+

L

2 2

as

a

function

of

the

ratio

of

the

stimulus

spa-

tial frequency to its preferred value, K/ k, for a grating oriented in the preferred

direction

=

0.

(C)

L

2 1

+

with the preferred spatial

L22 as a function of stimulus frequency and orientation,

spatial phase K = k and =

for 0.

a

grating

where B(ω, K) is a temporal and spatial frequency-dependent amplitude
factor. We do not need the explicit form of B(ω, K) here, but the reader is urged to derive it. For preferred spatial phase φ − π/2,

L2 = AB(ω, K) sin(φ − ) cos(ωt − δ)

(2.40)

because cos(φ − π/2 − ) = sin(φ − ). If we square and add these two terms, we obtain a result that does not depend on ,

L21 + L22 = A2 B2 (ω, K) cos2 (ωt − δ) ,

(2.41)

because cos2 (φ − ) + sin2 (φ − ) = 1. Thus, we can describe the spatial-phase-invariant response of a complex cell by writing

r(t) = r0 + G L21 + L22 ,

(2.42)

for some constant G. The selectivities of such a response estimate to grating orientation, spatial frequency, and spatial phase are shown in ﬁgure 2.23. The response of the model complex cell is tuned to orientation and spatial frequency, but the spatial phase dependence, illustrated for a simple cell in ﬁgure 2.15C, is absent. In computing the curve for ﬁgure 2.23C, we used the exact expressions for L1 and L2 from the integrals in equations 2.31 and 2.32, not the approximation used in equation 2.34 to simplify the previous discussion. Although it is not visible in the ﬁgure, there is a weak dependence on when the exact expressions are used.

The complex cell response given by equations 2.41 and 2.42 reproduces

the frequency-doubling effect seen in complex cell responses because the

factor cos2 (ωt − δ) oscillates with frequency 2ω. This follows from the

identity

cos2 (ωt

−

δ)

=

1 2

cos (2(ωt

−

δ))

+

1 2

.

(2.43)

energy model

76

Reverse Correlation and Visual Receptive Fields

A1

stimulus

s

r (Hz)

r (Hz)

0
-1
B
60 40 20
0
C
60 40 20
0 0

simple

complex

100

200

400

500

600

700

t (ms)

Figure 2.24 Temporal responses of model simple and complex cells to a counter-
phase grating. (A) The stimulus s(x, y, t) at a given point (x, y) plotted as a func-
tion of time. (B) The rectiﬁed linear response estimate of a model simple cell to this grating with a temporal kernel given by equation 2.29 with α = 1/(15 ms). (C)
The frequency-doubled response of a model complex cell with the same temporal
kernel but with the estimated rate given by a squaring operation rather than rectiﬁcation. The background ﬁring rate is r0 = 5 Hz. Note the temporal phase shift of both B and C relative to A.

In addition, the last term on the right side of this equation generates the constant component of the complex cell response to a counterphase grating. Figure 2.24 shows a comparison of model simple and complex cell responses to a counterphase grating, and illustrates this phenomenon.

The description of a complex cell response that we have presented is called an “energy” model because of its resemblance to the equation for the energy of a simple harmonic oscillator. The pair of linear ﬁlters used, with preferred spatial phases separated by π/2, is called a quadrature pair. Because of rectiﬁcation, the terms L21 and L22 cannot be constructed by squaring the outputs of single simple cells. However, they can each be constructed by summing the squares of rectiﬁed outputs from two simple cells with preferred spatial phases separated by π. Thus, we can write the complex cell response as the sum of the squares of four rectiﬁed simple cell responses,

r(t) = r0 + G [L1 ]2+ + [L2 ]2+ + [L3 ]2+ + [L4 ]2+ ,

(2.44)

where the different [L]+ terms represent the responses of simple cells with preferred spatial phases φ, φ + π/2, φ + π, and φ + 3π/2. While such a construction is possible, it should not be interpreted too literally because complex cells receive input from many sources, including the LGN and other complex cells. Rather, this model should be viewed as purely descriptive. Mechanistic models of complex cells are described at the end of this chapter and in chapter 7.

2.6 Receptive Fields in the Retina and LGN

77

2.6 Receptive Fields in the Retina and LGN

We end this discussion of the visual system by returning to the initial stages of the visual pathway and brieﬂy describing the receptive ﬁeld properties of neurons in the retina and LGN. Retinal ganglion cells display a wide variety of response characteristics, including nonlinear and direction-selective responses. However, a class of retinal ganglion cells (X cells in the cat or P cells in the monkey retina and LGN) can be described by a linear model built using reverse-correlation methods. The receptive ﬁelds of this class of retinal ganglion cells and an analogous type of LGN relay neurons are similar, so we do not treat them separately. The spatial structure of the receptive ﬁelds of these neurons has a center-surround structure consisting either of a circular central ON region surrounded by an annular OFF region, or the opposite arrangement of a central OFF region surrounded by an ON region. Such receptive ﬁelds are called ONcenter and OFF-center, respectively. Figure 2.25A shows the spatial receptive ﬁelds of an ON-center cat LGN neuron.

The spatial structure of retinal ganglion and LGN receptive ﬁelds is well captured by a difference-of-Gaussians model in which the spatial receptive ﬁeld is expressed as

Ds(x, y) = ±

1 2πσc2en

exp

−

x2 2

+ y2 σc2en

−

B 2πσs2ur

exp

−

x2 2

+ y2 σs2ur

.

(2.45)

Here the center of the receptive ﬁeld has been placed at x = y = 0. The ﬁrst Gaussian function in equation 2.45 describes the center, and the second, the surround. The size of the central region is determined by the parameter σcen, while σsur, which is greater than σcen, determines the size of the surround. B controls the balance between center and surround contributions. The ± sign allows both ON-center (+) and OFF-center (−) cases to be represented. Figure 2.25B shows a spatial receptive ﬁeld formed from the difference of two Gaussians that approximates the receptive ﬁeld structure in ﬁgure 2.25A.

Figure 2.25C shows that the spatial structure of the receptive ﬁeld reverses over time with, in this case, a central ON region reversing to an OFF region as τ increases. Similarly, the OFF surround region changes to an ON region with increasing τ, although the reversal and the onset are slower for the surround than for the central region. Because of the difference between the time course of the center and of the surround regions, the space-time receptive ﬁeld is not separable, although the center and surround components are individually separable. The basic features of LGN neuron space-time receptive ﬁelds are captured by

D(x, y, τ) = ±

Dtcen (τ ) 2πσc2en

exp

−x22σ+c2eyn2

−

BDtsur (τ ) 2πσs2ur

exp

−x22σ+s2uyr2

.

(2.46)

difference of Gaussians

78
A
3

Reverse Correlation and Visual Receptive Fields
B

Ý ´ Ö ×µ

00
C
0

Ü ´ Ö ×µ

Ds

0
-2
3
D

-1
Ü´

0 Ö

1 ×µ

2

2

0
-2
Ý´

Ö

×µ

´Ñ×µ

Dxt

200

0

Ü ´ Ö ×µ

3

0

200

-2

-1 0

1

Ü ´ Ö ×µ

20

100´Ñ×µ

Figure 2.25 Receptive ﬁelds of LGN neurons. (A) The center-surround spatial
structure of the receptive ﬁeld of a cat LGN X cell. This has a central ON region
(solid contours) and a surrounding OFF region (dashed contours). (B) A ﬁt of the
receptive ﬁeld shown in A using a difference-of-Gaussians function (equation 2.45) with σcen = 0.3◦, σsur = 1.5◦, and B = 5. (C) The space-time receptive ﬁeld of a cat LGN X cell. Note that the center and surround regions both reverse sign as a function of τ and that the temporal evolution is slower for the surround than for the
center. (D) A ﬁt of the space-time receptive ﬁeld in C using equation 2.46 with the
same parameters for the Gaussian functions as in B, and temporal factors given by equation 2.47 with 1/αcen = 16 ms for the center, 1/αsur = 32 ms for the surround, and 1/βcen = 1/βsur = 64 ms. (A and C adapted from DeAngelis et al., 1995.)

Separate functions of time multiply the center and surround, but they can both be described by the same functions, using two sets of parameters,
Dtcen,sur (τ ) = αc2en,surτ exp(−αcen,surτ ) − βc2en,surτ exp(−βcen,surτ ) . (2.47)
The parameters αcen and αsur control the latency of the response in the center and surround regions, respectively, and βcen and βsur affect the time of the reversal. This function has characteristics similar to the function in equation 2.29, but the latency effect is less pronounced. Figure 2.25D shows the space-time receptive ﬁeld of equation 2.46 with parameters chosen to match ﬁgure 2.25C.
Figure 2.26 shows the results of a direct test of a reverse-correlation model of an LGN neuron. The kernel needed to describe a particular LGN cell was ﬁrst extracted by using a white-noise stimulus. This, together with

2.7 Constructing V1 Receptive Fields

79

ÔÖ Ø

ØÙ Ð ´ØÖ Ð ½µ

firing rate (Hz)

ØÙ Ð ´ØÖ Ð ¾µ

time (ms)
Figure 2.26 Comparison of predicted and measured ﬁring rates for a cat LGN neuron responding to a video movie. The top panel is the rate predicted by integrating the product of the video image intensity and a linear ﬁlter obtained for this neuron from a spike-triggered average of a white-noise stimulus. The resulting linear prediction was rectiﬁed. The middle and lower panels are measured ﬁring rates extracted from two different sets of trials. (Adapted from Dan et al., 1996.)
a rectifying static nonlinearity, was used to predict the ﬁring rate of the neuron in response to a video movie. The top panel in ﬁgure 2.26 shows the resulting prediction, and the middle and lower panels show the actual ﬁring rates extracted from two different groups of trials. The correlation coefﬁcient between the predicted and actual ﬁring rates was 0.5, which was very close to the correlation coefﬁcient between ﬁring rates extracted from different groups of trials. This means that the error of the prediction was no worse than the variability of the neural response itself.

2.7 Constructing V1 Receptive Fields

The models of visual receptive ﬁelds we have been discussing are purely descriptive, but they provide an important framework for studying how the circuits of the retina, LGN, and primary visual cortex generate neural responses. In an example of a more mechanistic model, Hubel and Wiesel (1962) proposed that the oriented receptive ﬁelds of cortical neurons could be generated by summing the input from appropriately selected LGN neurons. Their construction, shown in ﬁgure 2.27A, consists of alternating rows of ON-center and OFF-center LGN cells providing convergent input to a cortical simple cell. The left side of ﬁgure 2.27A shows the spatial ar-

Hubel-Wiesel simple cell model

80 A
Off On Off

Reverse Correlation and Visual Receptive Fields

B
½
¾
simple cell
¿

complex cell

LGN receptive fields

simple cells

Figure 2.27 (A) The Hubel-Wiesel model of orientation selectivity. The spatial arrangement of the receptive ﬁelds of nine LGN neurons are shown, with a row of three ON-center ﬁelds ﬂanked on either side by rows of three OFF-center ﬁelds. White areas denote ON ﬁelds and gray areas, OFF ﬁelds. In the model, the converging LGN inputs are summed by the simple cell. This arrangement produces a receptive ﬁeld oriented in the vertical direction. (B) The Hubel-Wiesel model of a complex cell. Inputs from a number of simple cells with similar orientation and spatial frequency preferences (θ and k), but different spatial phase preferences (φ1, φ2, φ3, and φ4), converge on a complex cell and are summed. This produces a complex cell output that is selective for orientation and spatial frequency, but not for spatial phase. The ﬁgure shows four simple cells converging on a complex cell, but additional simple cells can be included to give a more complete coverage of spatial phase.

rangement of LGN receptive ﬁelds that, when summed, form bands of ON and OFF regions resembling the receptive ﬁeld of an oriented simple cell. This model accounts for the selectivity of a simple cell purely on the basis of feedforward input from the LGN. We leave the study of this model as an exercise for the reader. Other models, which we discuss in chapter 7, include the effects of recurrent intracortical connections as well.

Hubel-Wiesel complex cell model

In a previous section, we showed how the properties of complex cell responses could be accounted for by using a squaring static nonlinearity. While this provides a good description of complex cells, there is little indication that complex cells actually square their inputs. Models of complex cells can be constructed without introducing a squaring nonlinearity. One such example is another model proposed by Hubel and Wiesel (1962), which is depicted in ﬁgure 2.27B. Here the phase-invariant response of a complex cell is produced by summing together the responses of several simple cells with similar orientation and spatial frequency tuning, but different preferred spatial phases. In this model, the complex cell inherits its orientation and spatial frequency preference from the simple cells that drive it, but spatial phase selectivity is reduced because the outputs of simple cells with a variety of spatial phase selectivities are summed. Analysis of this model is left as an exercise. While the model generates complex cell responses, there are indications that complex cells in primary visual cortex are not driven exclusively by simple cell input. An alternative model is considered in chapter 7.

2.8 Chapter Summary

81

2.8 Chapter Summary

We continued from chapter 1 our study of the ways that neurons encode information, focusing on reverse-correlation analysis, particularly as applied to neurons in the retina, visual thalamus (LGN), and primary visual cortex. We used the tools of systems identiﬁcation, especially the linear ﬁlter, Wiener kernel, and static nonlinearity, to build descriptive linear and nonlinear models of the transformation from dynamic stimuli to time-dependent ﬁring rates. We discussed the complex logarithmic map governing the way that neighborhood relationships in the retina are transformed into cortex, Nyquist sampling in the retina, and Gabor functions as descriptive models of separable and nonseparable receptive ﬁelds. Models based on Gabor ﬁlters and static nonlinearities were shown to account for the basic response properties of simple and complex cells in primary visual cortex, including selectivity for orientation, spatial frequency and phase, velocity, and direction. Retinal ganglion cell and LGN responses were modeled using a difference-of-Gaussians kernel. We brieﬂy described simple circuit models of simple and complex cells.

2.9 Appendices

A: The Optimal Kernel

Using equation 2.1 for the estimated ﬁring rate, the expression in equation 2.3 to be minimized is

E

=

1 T

T
dt
0

∞

2

r0 + dτ D(τ )s(t − τ ) − r(t) .

0

(2.48)

The minimum is obtained by setting the derivative of E with respect to
the function D to 0. A quantity, such as E, that depends on a function, D
in this case, is called a functional, and the derivative we need is a func-
tional derivative. Finding the extrema of functionals is the subject of a
branch of mathematics called the calculus of variations. A simple way to
deﬁne a functional derivative is to introduce a small time interval t and evaluate all functions at integer multiples of t. We deﬁne ri = r(i t), Dk = D(k t), and si−k = s((i − k) t). If t is small enough, the integrals in equation 2.48 can be approximated by sums, and we can write

E=

t T/ t T i=0

r0 +

∞

2

t Dk si−k − ri .

k=0

(2.49)

E is minimized by setting its derivative with respect to D j for all values of j to 0,

∂E ∂Dj

=

0

=

2t T

T/ t i=0

r0 +

∞
t Dk si−k − ri si− j
k=0

t.

(2.50)

functional derivative

82

Reverse Correlation and Visual Receptive Fields

Rearranging and simplifying this expression gives the condition

∞
t
k=0

 Dk 

t T

T/ t



si−k si−j =

i=0

t T

T/ t i=0

(ri

−

r0 )

si− j

.

(2.51)

If we take the limit t → 0 and make the replacements i t → t, j t → τ, and k t → τ′, the sums in equation 2.51 turn back into integrals, the indexed variables become functions, and we ﬁnd

∞
dτ′ D(τ′)
0

1 T

T
dt s(t − τ′)s(t − τ)
0

=

1 T

T
dt (r(t) − r0 ) s(t − τ ) .
0

(2.52)

The term proportional to r0 on the right side of this equation can be dropped because the time integral of s is 0. The remaining term is the ﬁring rate-stimulus correlation function evaluated at −τ, Qrs (−τ ). The term in large parentheses on the left side of 2.52 is the stimulus autocorrelation function. By shifting the integration variable t → t + τ, we ﬁnd that it is Qss (τ − τ′ ), so 2.52 can be re-expressed in the form of equation 2.4.

Equation 2.6 provides the solution to equation 2.4 only for a white-noise stimulus. For an arbitrary stimulus, equation 2.4 can easily be solved by the method of Fourier transforms if we ignore causality and allow the estimated rate at time t to depend on the stimulus at times later than t, so that

∞
rest(t) = r0 + dτ D(τ )s(t − τ ) .
−∞

(2.53)

The estimate written in this acausal form satisﬁes a slightly modiﬁed version of equation 2.4,

∞
dτ′ Qss (τ − τ′ )D(τ′ ) = Qrs(−τ) .
−∞

(2.54)

We deﬁne the Fourier transforms (see the Mathematical Appendix)

∞

∞

D˜ (ω) = dt D(t) exp(iωt) and Q˜ ss (ω) = dτ Qss (τ ) exp(iωτ ) ,

−∞

−∞

(2.55)

as well as Q˜ rs (ω) deﬁned analogously to Q˜ ss (ω).

Equation 2.54 is solved by taking the Fourier transform of both sides. The integral of the product of two functions that appears on the left side of equation 2.54 is called a convolution. To evaluate its Fourier transform, we make use of an important theorem stating that the Fourier transform of a convolution is the product of the Fourier transforms of the two functions involved (see the Mathematical Appendix),

∞

∞

dτ exp(iωτ ) dτ′ Qss (τ − τ′ )D(τ′ ) = D˜ (ω)Q˜ ss (ω) .

−∞

−∞

(2.56)

2.9 Appendices

83

In terms of the Fourier transforms, equation 2.54 then becomes

D˜ (ω)Q˜ ss (ω) = Q˜ rs (−ω) ,

(2.57)

which can be solved directly to obtain D˜ (ω) = Q˜ rs (−ω)/Q˜ ss (ω). The inverse Fourier transform from which D(τ ) is recovered is (Mathematical
Appendix)

D(τ)

=

1 2π

∞
dω D˜ (ω) exp(−iωτ ) ,
−∞

(2.58)

so the optimal acausal kernel when the stimulus is temporally correlated is given by

D(τ)

=

1 2π

∞
dω
−∞

Q˜ rs (−ω) Q˜ ss (ω)

exp (−iωτ )

.

(2.59)

B: The Most Effective Stimulus

We seek the stimulus that produces the maximum predicted responses at time t subject to the ﬁxed energy constraint

T
dt′

s(t′ ) 2 = constant .

0

(2.60)

We impose this constraint by the method of Lagrange multipliers (see the Mathematical Appendix), which means that we must ﬁnd the unconstrained maximum value with respect to s of

T

∞

T

rest (t) + λ dt′ s2 (t′ ) = r0 + dτ D(τ )s(t − τ ) + λ dt′ s(t′ ) 2 ,

0

0

0

(2.61)

where λ is the Lagrange multiplier. Setting the derivative of this expression with respect to the function s to 0 (using the same methods used in appendix A) gives

D(τ) = −2λs(t − τ) .

(2.62)

The value of λ (which is less than 0) is determined by requiring that condition 2.60 is satisﬁed, but the precise value is not important for our purposes. The essential result is the proportionality between the optimal stimulus and D(τ ).

C: Bussgang’s Theorem
Bussgang (1952, 1975) proved that an estimate based on the optimal kernel for linear estimation can still be self-consistent (although not necessarily

84

Reverse Correlation and Visual Receptive Fields

optimal) when nonlinearities are present. The self-consistency condition is that when the nonlinear estimate rest = r0 + F(L(t)) is substituted into equation 2.6, the relationship between the linear kernel and the ﬁring rate-
stimulus correlation function should still hold. In other words, we require that

D(τ)

=

1 σs2 T

T
dt rest (t)s(t
0

−

τ)

=

1 σs2 T

T
dt F(L(t))s(t − τ) .
0

(2.63)

We have dropped the r0 term because the time integral of s is 0. In general, equation 2.63 does not hold, but if the stimulus used to extract D is Gaussian white noise, equation 2.63 reduces to a simple normalization condition on the function F. This result is based on the identity, valid for a Gaussian white-noise stimulus,

1 σs2 T

T
dt F(L(t))s(t
0

− τ)

=

D(τ) T

T
dt
0

dF(L(t)) dL

.

(2.64)

For the right side of this equation to be D(τ ), the remaining expression, involving the integral of the derivative of F, must be equal to 1. This can be achieved by appropriate scaling of F. The critical identity 2.64 is based on integration by parts for a Gaussian weighted integral. A simpliﬁed proof is presented as a problem on the exercise web site.

2.10 Annotated Bibliography
Marmarelis & Marmarelis (1978), Rieke et al. (1997), and Gabbiani & Koch (1998) provide general discussions of reverse-correlation methods. A useful reference relevant to our presentation of their application to the visual system is Carandini et al. (1996). Volterra and Wiener functional expansions are discussed in Wiener (1958) and Marmarelis & Marmarelis (1978).
General introductions to the visual system include Hubel & Wiesel (1962, 1977), Orban (1984), Hubel (1988), Wandell (1995), and De Valois & De Valois (1990). Our treatment follows Dowling (1987) on processing in the retina, and Schwartz (1977), Van Essen et al. (1984), and Rovamo & Virsu (1984) on aspects of the retinotopic map from the eye to the brain. Properties of this map are used to account for aspects of visual hallucinations in Ermentrout & Cowan (1979). We also follow Movshon et al. (1978a, 1978b) for deﬁnitions of simple and complex cells, Daugman (1985) and Jones & Palmer (1987b) on the use of Gabor functions (Gabor, 1946) to describe visual receptive ﬁelds, and DeAngelis et al. (1995) on space-time receptive ﬁelds. Our description of the energy model of complex cells is based on Adelson & Bergen (1985), which is related to work by Pollen & Ronner (1982), Van Santen & Sperling (1984), and Watson & Ahumada (1985), and to earlier ideas of Reichardt (1961) and Barlow & Levick (1965). Heeger’s (1992, 1993) model of contrast saturation is reviewed in Carandini et al.

